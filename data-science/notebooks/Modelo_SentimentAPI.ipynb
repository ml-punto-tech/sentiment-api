{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1902,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import uvicorn\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "from io import StringIO\n",
        "import urllib.response\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de diccionario<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1903,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CARGANDO DICCIONARIO DE SENTIMIENTOS\n",
            "============================================================\n",
            "üì• Cargando diccionario desde: https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/feature/data-science-marely/data-science/sources/diccionarios/sentimientos_mapeo.json\n",
            "‚úÖ JSON cargado: 106 sentimientos\n",
            "üìä Distribuci√≥n:\n",
            "   ‚Ä¢ Positivos: 62\n",
            "   ‚Ä¢ Negativos: 39\n",
            "   ‚Ä¢ Neutros: 5\n",
            "\n",
            "============================================================\n",
            "‚úÖ VARIABLES CREADAS Y DISPONIBLES:\n",
            "============================================================\n",
            "‚Ä¢ 'datos_es' (diccionario completo): 106 elementos\n",
            "‚Ä¢ 'positivos_es' (lista): 62 elementos\n",
            "‚Ä¢ 'negativos_es' (lista): 39 elementos\n",
            "‚Ä¢ 'neutros_es' (lista): 5 elementos\n",
            "\n",
            "üîç Ejemplo de positivos: ['aceptacion', 'admiracion', 'adoracion']\n",
            "üîç Ejemplo de negativos: ['abrumado', 'aburrimiento', 'aislamiento']\n",
            "üîç Ejemplo de neutros: ['ambivalencia', 'anticipacion', 'curiosidad']\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# üéØ CARGAR DICIONARIO DE SENTIMIENTOS (VERSI√ìN CORREGIDA)\n",
        "# ==========================================================\n",
        "\n",
        "import json\n",
        "import urllib.request\n",
        "from urllib.error import URLError, HTTPError\n",
        "\n",
        "def cargar_diccionario_completo():\n",
        "    \"\"\"\n",
        "    Carga el diccionario de sentimientos y retorna TODAS las variables necesarias.\n",
        "    \"\"\"\n",
        "    # URL corregida (raw de GitHub)\n",
        "    url = \"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/feature/data-science-marely/data-science/sources/diccionarios/sentimientos_mapeo.json\"\n",
        "    \n",
        "    print(f\"üì• Cargando diccionario desde: {url}\")\n",
        "    \n",
        "    try:\n",
        "        # 1. Descargar\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "        \n",
        "        # 2. Decodificar y cargar JSON\n",
        "        datos = json.loads(content.decode('utf-8'))\n",
        "        print(f\"‚úÖ JSON cargado: {len(datos)} sentimientos\")\n",
        "        \n",
        "        # 3. Crear listas de categor√≠as\n",
        "        positivos_es = [k for k, v in datos.items() if v == 'positivo']\n",
        "        negativos_es = [k for k, v in datos.items() if v == 'negativo']\n",
        "        neutros_es = [k for k, v in datos.items() if v == 'neutral']\n",
        "\n",
        "        print(f\"üìä Distribuci√≥n:\")\n",
        "        print(f\"   ‚Ä¢ Positivos: {len(positivos_es)}\")\n",
        "        print(f\"   ‚Ä¢ Negativos: {len(negativos_es)}\")\n",
        "        print(f\"   ‚Ä¢ Neutros: {len(neutros_es)}\")\n",
        "        \n",
        "        # 4. ¬°IMPORTANTE! Retornar todas las variables\n",
        "        return {\n",
        "            'datos': datos,\n",
        "            'positivos': positivos_es,\n",
        "            'negativos': negativos_es,\n",
        "            'neutros': neutros_es\n",
        "        }\n",
        "        \n",
        "    except HTTPError as e:\n",
        "        print(f\"‚ùå Error HTTP {e.code}: {e.reason}\")\n",
        "    except URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e.reason}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"‚ùå Error en JSON: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "\n",
        "   # Retornar diccionario vac√≠o en caso de error\n",
        "    return {\n",
        "        'datos': {},\n",
        "        'positivos': [],\n",
        "        'negativos': [],\n",
        "        'neutros': []\n",
        "    }\n",
        "\n",
        "# ==================== EJECUCI√ìN ====================\n",
        "print(\"=\" * 60)\n",
        "print(\"CARGANDO DICCIONARIO DE SENTIMIENTOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cargar y obtener todas las variables\n",
        "diccionario_data = cargar_diccionario_completo()\n",
        "\n",
        "# Extraer las variables individuales\n",
        "datos_es = diccionario_data['datos']\n",
        "positivos_es = diccionario_data['positivos']\n",
        "negativos_es = diccionario_data['negativos']\n",
        "neutros_es = diccionario_data['neutros']\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ VARIABLES CREADAS Y DISPONIBLES:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚Ä¢ 'datos_es' (diccionario completo): {len(datos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'positivos_es' (lista): {len(positivos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'negativos_es' (lista): {len(negativos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'neutros_es' (lista): {len(neutros_es)} elementos\")\n",
        "\n",
        "# Mostrar ejemplos\n",
        "if positivos_es:\n",
        "    print(f\"\\nüîç Ejemplo de positivos: {positivos_es[:3]}\")\n",
        "if negativos_es:\n",
        "    print(f\"üîç Ejemplo de negativos: {negativos_es[:3]}\")\n",
        "if neutros_es:\n",
        "    print(f\"üîç Ejemplo de neutros: {neutros_es[:3]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1904,
      "metadata": {
        "id": "yOwHw3xtYJEg"
      },
      "outputs": [],
      "source": [
        "def importar_dataset(url, sep=';'):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL detectando encoding autom√°ticamente.\n",
        "    Acepta un argumento `sep` para especificar el separador del CSV (por defecto ';').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Descargar contenido una sola vez\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "\n",
        "        # 2. Detectar encoding\n",
        "        result = chardet.detect(content)\n",
        "        encoding = result['encoding']\n",
        "        print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "\n",
        "        # 3. Decodificar y cargar en DataFrame\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        data = pd.read_csv(StringIO(decoded_content), sep=sep)\n",
        "\n",
        "        print(\"‚úÖ Archivo cargado correctamente\")\n",
        "        print(f\"üìä Tama√±o del dataset: {data.shape}\")\n",
        "        print(\"\\nüîç Muestra aleatoria (3 registros):\")\n",
        "        print(data.sample(3))\n",
        "\n",
        "        return data\n",
        "\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e}\")\n",
        "        return None\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ùå Error al parsear CSV: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZW5B7jk5-x"
      },
      "source": [
        "#### **dataset1_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1905,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWgPb0VhYeKT",
        "outputId": "1265d274-21aa-4f74-b3b7-e0a7d18e6a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: utf-8 (confianza: 99.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (1465, 15)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "     Unnamed: 0.1 Unnamed: 0  \\\n",
            "694           696        700   \n",
            "1276          545        549   \n",
            "448           449        453   \n",
            "\n",
            "                                                   Text    Sentiment  \\\n",
            "694   Se pinch√≥ una llanta camino a una reuni√≥n impo...         Malo   \n",
            "1276  En el Grand Slam de tenis se desarrolla una fe...  Cautivaci√≥n   \n",
            "448   En el p√°ramo de la confianza perdida, resuenan...     Traici√≥n   \n",
            "\n",
            "             Timestamp                            User  Platform  \\\n",
            "694   23-09-2023 14:15          FlatTireWoesHighSchool   Twitter   \n",
            "1276  10-09-2017 20:15  TennisEnthusiastGrandSlamDrama   Twitter   \n",
            "448   12-12-2016 10:00                  TrustWasteland  Facebook   \n",
            "\n",
            "                                              Hashtags Retweets Likes  \\\n",
            "694   #D√≠aDeLaMalaSuerte #LuchasEnLaEscuela Secundaria       25    50   \n",
            "1276                    #Cautivaci√≥n #RivalidadDeTenis       28    55   \n",
            "448                   #Traici√≥n #PromesasReverberantes       25    50   \n",
            "\n",
            "          Country  Year Month Day Hour  \n",
            "694         EE.UU  2023     9  23   14  \n",
            "1276  Reino Unido  2017     9  10   20  \n",
            "448        Italia  2016    12  12   10  \n"
          ]
        }
      ],
      "source": [
        "df1_url_es = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset1_esp.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKr3W1NEaBrP"
      },
      "source": [
        "#### **dataset2_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1906,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2eRhM-MYh6L",
        "outputId": "e224480a-7b3e-44c6-ec3f-dea83217a6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (2540, 3)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "                                                  texto  label sentimiento\n",
            "1941  Ay cada quien tiene en la vida su cuarto de ho...      1     neutral\n",
            "1347  Mi proyecto de IAmalist se vi√≥ pausado en YouT...      2    positivo\n",
            "95    Menos mal estoy incapacitado hasta el lunes po...      0    negativo\n"
          ]
        }
      ],
      "source": [
        "df2_url_es = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset2_esp.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **dataset3_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1907,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmMcmf9gyZpS",
        "outputId": "59797edf-93fb-42fc-b82e-8f20bf2f8763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1254 (confianza: 56.84%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (740, 4)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "       id plataforma sentimiento  \\\n",
            "609  6760   Fortnite     Neutral   \n",
            "238  9148     Nvidia     Neutral   \n",
            "739  8042  Microsoft     Neutral   \n",
            "\n",
            "                                                 texto  \n",
            "609  Apple acaba de lanzarse a la guerra nuclear co...  \n",
            "238  Quiz√°s publique muchas capturas de pantalla qu...  \n",
            "739  Yo tend√≠a a pensar que Ellison era un buen tip...  \n"
          ]
        }
      ],
      "source": [
        "df3_url_es = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset3_esp.csv\", sep=',') # Probando con ',' como separador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNDDOVQQ8MA-"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar y explorar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1908,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RESUMEN dataset1_es\n",
            "üìä Tama√±o del dataset: (1465, 2)\n",
            "üìä Registros √∫nicos: 708\n",
            "üìä Sentimientos √∫nicos: 105\n",
            "üìä Registros duplicados: 754\n",
            "üìä Textos vac√≠os: 2\n",
            "üìä Sentimientos vac√≠os: 2\n",
            "üìä Registros duplicados: 754\n",
            "üìä Textos duplicados: 756\n",
            "                                                 texto     sentimiento\n",
            "246  Envuelto en el manto del entumecimiento emocio...  Entumecimiento\n",
            "858  Serenidad encontrada en las p√°ginas de un libr...         Neutral\n",
            "247  Bailando por la vida con la exuberancia de un ...           √Ånimo\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESUMEN dataset2_es\n",
            "üìä Tama√±o del dataset: (2540, 2)\n",
            "üìä Registros √∫nicos: 2156\n",
            "üìä Sentimientos √∫nicos: 3\n",
            "üìä Registros duplicados: 298\n",
            "üìä Textos vac√≠os: 0\n",
            "üìä Sentimientos vac√≠os: 0\n",
            "üìä Registros duplicados: 298\n",
            "üìä Textos duplicados: 384\n",
            "                                                 texto sentimiento\n",
            "135                             Creo que pedir√© pan xd    negativo\n",
            "4       Denme un helado o algo que ando full abrumado.    negativo\n",
            "796  Al mismo tiempo que me empezabas a tratar indi...    negativo\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESUMEN dataset3_es\n",
            "üìä Tama√±o del dataset: (740, 2)\n",
            "üìä Registros √∫nicos: 697\n",
            "üìä Sentimientos √∫nicos: 3\n",
            "üìä Registros duplicados: 43\n",
            "üìä Textos vac√≠os: 0\n",
            "üìä Sentimientos vac√≠os: 0\n",
            "üìä Registros duplicados: 43\n",
            "üìä Textos duplicados: 43\n",
            "                                                 texto sentimiento\n",
            "341  NVIDIA ha lanzado una actualizaci√≥n de segurid...     Neutral\n",
            "27   Se espera un gran crecimiento del uso del apre...     Neutral\n",
            "31   Supuestamente AMD est√° probando Big Navi, y se...     Neutral\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n filtrar dataset\n",
        "def filtrar_dataset(data,nombre_dataset='dataset'):\n",
        "    data_filtro = data[['texto', 'sentimiento']]\n",
        "    data_filtro = data_filtro[data_filtro['texto'].str.strip() != \"\"]\n",
        "\n",
        "    \n",
        "    print('\\nRESUMEN',nombre_dataset)\n",
        "    print(f\"üìä Tama√±o del dataset: {data_filtro.shape}\")\n",
        "    print(f\"üìä Registros √∫nicos: {data_filtro['texto'].nunique()}\")\n",
        "    print(f\"üìä Sentimientos √∫nicos: {data_filtro['sentimiento'].nunique()}\")\n",
        "    print(f\"üìä Registros duplicados: {data_filtro.duplicated().sum()}\")\n",
        "    print(f\"üìä Textos vac√≠os: {data_filtro['texto'].isnull().sum()}\")\n",
        "    print(f\"üìä Sentimientos vac√≠os: {data_filtro['sentimiento'].isnull().sum()}\")\n",
        "    print(f\"üìä Registros duplicados: {data_filtro.duplicated().sum()}\")\n",
        "    print(f\"üìä Textos duplicados: {data_filtro.duplicated(subset=['texto']).sum()}\")\n",
        "    \n",
        "    print(data_filtro.sample(3))\n",
        "    print('-' * 80)\n",
        "\n",
        "\n",
        "    return data_filtro\n",
        "\n",
        "# Reemplazar nombre columnas Text por texto, Sentiment por sentimiento\n",
        "df1_url_es.rename({'Text':'texto', 'Sentiment':'sentimiento'}, axis='columns', inplace=True)\n",
        "df1_filtrado_es = filtrar_dataset(df1_url_es,'dataset1_es')\n",
        "df2_filtrado_es = filtrar_dataset(df2_url_es,'dataset2_es')\n",
        "df3_filtrado_es = filtrar_dataset(df3_url_es,'dataset3_es')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1909,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura', 'ambivalencia', 'amistad', 'amor', 'angustia', 'anhelo', 'ansiedad', 'anticipaci√≥n', 'apreciaci√≥n', 'aprensivo', 'armon√≠a', 'arrepentimiento', 'asco', 'asombro', 'cautivaci√≥n', 'celebraci√≥n', 'colorido', 'confiado', 'confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'curiosidad', 'decepci√≥n', 'desamor', 'descubrimiento', 'desesperaci√≥n', 'deslumbrar', 'despectivo', 'determinaci√≥n', 'devastado', 'disfrute', 'diversi√≥n', 'dolor', 'elegancia', 'emoci√≥n', 'empoderamiento', 'emp√°tico', 'encantamiento', 'energ√≠a', 'enojo', 'entumecimiento', 'entusiasmo', 'envidia', 'envidioso', 'esperanza', 'euforia', 'excitaci√≥n', 'felicidad', 'frustraci√≥n', 'frustrado', 'grandeza', 'gratitud', 'inspiraci√≥n', 'inspirado', 'intimidaci√≥n', 'juguet√≥n', 'logro', 'l√°stima', 'malo', 'maravilla', 'melancol√≠a', 'mel√≥dico', 'miedo', 'motivaci√≥n', 'negativo', 'negativo', 'neutral', 'neutral', 'obst√°culo', 'odiar', 'optimismo', 'orgullo', 'pena', 'positividad', 'positivo', 'positivo', 'p√©rdida', 'reconfortante', 'reflexi√≥n', 'resentimiento', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfacci√≥n', 'sentiment', 'serenidad', 'soledad', 'sorpresa', 'sufrimiento', 'temeroso', 'ternura', 'traici√≥n', 'tristeza', 'triunfo', 'verguenza', '√°nimo', '√©xito']\n",
            "Total de sentimientos: 108\n"
          ]
        }
      ],
      "source": [
        "#crear lista de sentimientos unicos, ordenados, en min√∫scula\n",
        "unicos_es = set(df1_filtrado_es['sentimiento'].unique()).union(set(df2_filtrado_es['sentimiento'].unique())).union(set(df3_filtrado_es['sentimiento'].unique()))\n",
        "sentimientos_unicos_es = sorted(list([sentimiento.lower() for sentimiento in unicos_es if isinstance(sentimiento, str)]))\n",
        "print(sentimientos_unicos_es)\n",
        "print(f'Total de sentimientos: {len(sentimientos_unicos_es)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1910,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1911,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "def obtener_lista_ordenada(*series_o_listas: Iterable,nombre='nombre'):\n",
        "    \"\"\"\n",
        "    Acepta cualquier cantidad de Series/Listas de sentimientos y devuelve\n",
        "    una lista ordenada de sentimientos √∫nicos ya limpios.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Unir todas las entradas en un solo iterable\n",
        "    todos = []\n",
        "    for s in series_o_listas:\n",
        "        todos.extend(list(s))\n",
        "\n",
        "\n",
        "    # 2) Limpiar y eliminar duplicados en un solo paso usando un set\n",
        "    sentimientos_limpios = {limpiar_texto_sentimientos(x) for x in todos}\n",
        "\n",
        "    print('\\n====> RESUMEN LIMPIEZA',nombre)\n",
        "    print(f'üìä Registros (original):',len(todos))\n",
        "    print(f'üìä Registros (despues de la limpieza):',len(sentimientos_limpios))\n",
        "    # listar \n",
        "    print(f'Lista {nombre} limpios: {', '.join(sentimientos_limpios)}')\n",
        "\n",
        "    print('-' * 80)\n",
        "\n",
        "    # 3) Devolver ordenado\n",
        "    return sorted(sentimientos_limpios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1912,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpieza dataframes\n",
        "\n",
        "def limpiar_dos_columnas(df, col1_name, col2_name, nombre_df=\"df\"):\n",
        "    \"\"\"\n",
        "    Aplica la limpieza a dos columnas de texto de un DataFrame\n",
        "    y devuelve un DataFrame nuevo con las columnas limpias.\n",
        "    \"\"\"\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Aplicar la funci√≥n limpiar_texto_sentimientos a ambas columnas\n",
        "    df_copy[col1_name + \"_limpio\"] = df_copy[col1_name].apply(limpiar_texto_sentimientos)\n",
        "    df_copy[col2_name + \"_limpio\"] = df_copy[col2_name].apply(limpiar_texto_sentimientos)\n",
        "\n",
        "    # Opcional: eliminar duplicados por las columnas limpias\n",
        "    df_unique = df_copy.drop_duplicates(subset=[col1_name + \"_limpio\", col2_name + \"_limpio\"])\n",
        "    print('\\n====> RESUMEN LIMPIEZA',nombre_df)\n",
        "    print(f\"üìä Filas en '{nombre_df}' (original): {len(df)}\")\n",
        "    print(f\"üìä Filas en '{nombre_df}' (√∫nicas por columnas limpias): {len(df_unique)}\")\n",
        "    print(df_unique[[col1_name, col2_name, col1_name + \"_limpio\", col2_name + \"_limpio\"]].head(3))\n",
        "    print('-' * 80)\n",
        "\n",
        "    return df_unique\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1913,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYkBr6o-8MBA",
        "outputId": "a80b78a8-4d49-4164-d9cd-9918feb82b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====> RESUMEN LIMPIEZA positivos\n",
            "üìä Registros (original): 62\n",
            "üìä Registros (despues de la limpieza): 62\n",
            "Lista positivos limpios: empoderamiento, animo, alegria, maravilla, romance, motivacion, jugueton, encantamiento, orgullo, confiado, elegancia, empatico, determinacion, extasis, amistad, logro, confianza, satisfaccion, serenidad, esperanza, entusiasmo, agradecido, intimidacion, admiracion, positividad, creatividad, resplandor, deslumbrar, adoracion, colorido, disfrute, felicidad, ternura, elacion, positivo, excitacion, descubrimiento, diversion, reverencia, cumplimiento, amor, armonia, asombro, inspiracion, celebracion, euforia, triunfo, exito, emocion, apreciacion, optimismo, resiliencia, contentamiento, aceptacion, gratitud, amabilidad, cautivacion, energia, grandeza, melodico, reconfortante, inspirado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA negativos\n",
            "üìä Registros (original): 39\n",
            "üìä Registros (despues de la limpieza): 39\n",
            "Lista negativos limpios: amargura, entumecimiento, anhelo, devastado, desesperacion, aislamiento, melancolia, negativo, frustrado, frustracion, lastima, enojo, aprensivo, dolor, despectivo, ansiedad, envidioso, pena, aburrimiento, abrumado, perdida, traicion, asco, arrepentimiento, temeroso, verguenza, decepcion, miedo, reflexion, tristeza, obstaculo, sufrimiento, soledad, angustia, desamor, malo, envidia, resentimiento, odiar\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA neutros\n",
            "üìä Registros (original): 5\n",
            "üìä Registros (despues de la limpieza): 5\n",
            "Lista neutros limpios: ambivalencia, sorpresa, anticipacion, neutral, curiosidad\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA lista sentimientos_unicos\n",
            "üìä Registros (original): 108\n",
            "üìä Registros (despues de la limpieza): 105\n",
            "Lista lista sentimientos_unicos limpios: romance, empatico, elegancia, satisfaccion, lastima, enojo, entusiasmo, envidioso, creatividad, abrumado, ambivalencia, arrepentimiento, positivo, temeroso, decepcion, asombro, inspiracion, celebracion, euforia, exito, soledad, anticipacion, gratitud, amabilidad, grandeza, melodico, envidia, inspirado, empoderamiento, animo, alegria, sentiment, devastado, desesperacion, negativo, confianza, frustracion, dolor, pena, neutral, adoracion, colorido, disfrute, ternura, descubrimiento, reverencia, reflexion, tristeza, emocion, apreciacion, cautivacion, energia, orgullo, resiliencia, amargura, entumecimiento, maravilla, anhelo, jugueton, motivacion, melancolia, amistad, frustrado, agradecido, despectivo, admiracion, intimidacion, deslumbrar, traicion, curiosidad, asco, excitacion, diversion, amor, armonia, angustia, contentamiento, desamor, malo, resentimiento, odiar, encantamiento, confiado, determinacion, aislamiento, logro, serenidad, esperanza, aprensivo, sorpresa, positividad, ansiedad, aburrimiento, perdida, resplandor, felicidad, verguenza, miedo, cumplimiento, obstaculo, triunfo, sufrimiento, optimismo, aceptacion, reconfortante\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA dataset1_es\n",
            "üìä Filas en 'dataset1_es' (original): 1465\n",
            "üìä Filas en 'dataset1_es' (√∫nicas por columnas limpias): 711\n",
            "                                              texto sentimiento  \\\n",
            "0      ¬°Disfrutando de un hermoso d√≠a en el parque!    Positivo   \n",
            "1              Esta ma√±ana el tr√°fico era terrible.    Negativo   \n",
            "2  ¬°Acabo de terminar un entrenamiento incre√≠ble!??    Positivo   \n",
            "\n",
            "                                       texto_limpio sentimiento_limpio  \n",
            "0      ¬°Disfrutando de un hermoso dia en el parque!           Positivo  \n",
            "1              Esta ma√±ana el trafico era terrible.           Negativo  \n",
            "2  ¬°Acabo de terminar un entrenamiento increible!??           Positivo  \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA dataset2_es\n",
            "üìä Filas en 'dataset2_es' (original): 2540\n",
            "üìä Filas en 'dataset2_es' (√∫nicas por columnas limpias): 2230\n",
            "                                               texto sentimiento  \\\n",
            "0               termine bien abrumado despu√©s de hoy    negativo   \n",
            "1                                 me siento abrumado    negativo   \n",
            "2  Me siento un poco abrumado por la cantidad de ...    negativo   \n",
            "\n",
            "                                        texto_limpio sentimiento_limpio  \n",
            "0               termine bien abrumado despues de hoy           negativo  \n",
            "1                                 me siento abrumado           negativo  \n",
            "2  Me siento un poco abrumado por la cantidad de ...           negativo  \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA dataset3_es\n",
            "üìä Filas en 'dataset3_es' (original): 740\n",
            "üìä Filas en 'dataset3_es' (√∫nicas por columnas limpias): 695\n",
            "                                               texto sentimiento  \\\n",
            "0  La Varlope, dura como una roca, rara y poderos...     Neutral   \n",
            "1  Rock en vivo - M√∫sica dura La la Varlope, RARE...     Neutral   \n",
            "2  Soy duro como yo, RARE LONDON DE, HANDSOME 201...     Neutral   \n",
            "\n",
            "                                        texto_limpio sentimiento_limpio  \n",
            "0  La Varlope, dura como una roca, rara y poderos...            Neutral  \n",
            "1  Rock en vivo - Musica dura La la Varlope, RARE...            Neutral  \n",
            "2  Soy duro como yo, RARE LONDON DE, HANDSOME 201...            Neutral  \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#Listas\n",
        "positivos_limpios_es = obtener_lista_ordenada(positivos_es, nombre='positivos')\n",
        "negativos_limpios_es = obtener_lista_ordenada(negativos_es, nombre='negativos')\n",
        "neutros_limpios_es = obtener_lista_ordenada(neutros_es, nombre='neutros')\n",
        "sentimientos_unicos_limpios_es = obtener_lista_ordenada(sentimientos_unicos_es, nombre='lista sentimientos_unicos')\n",
        "\n",
        "# Uso dataframe\n",
        "df1_limpio_es = limpiar_dos_columnas(df1_filtrado_es, \"texto\", \"sentimiento\", nombre_df='dataset1_es')\n",
        "df2_limpio_es = limpiar_dos_columnas(df2_filtrado_es, \"texto\", \"sentimiento\", nombre_df='dataset2_es')\n",
        "df3_limpio_es = limpiar_dos_columnas(df3_filtrado_es, \"texto\", \"sentimiento\", nombre_df='dataset3_es')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=lightgreen size=12>Unificar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1914,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "====> RESUMEN DATASET UNIFICADO\n",
            "--------------------------------------------------------------------------------\n",
            "Registros dataset1_es: 711      Porcentaje: 19.55%\n",
            "Registros dataset2_es: 2230     Porcentaje: 61.33%\n",
            "Registros dataset3_es: 695      Porcentaje: 19.11%\n",
            "Registros dataset_unificado: 3636\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_limpio</th>\n",
              "      <th>sentimiento_limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>Es muy desorientador que hoy basicamente sea J...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>Ya estoy harto de los estupidos anuncios de la...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3312</th>\n",
              "      <td>¬°Hola! Estamos EN DIRECTO con otro sabado de M...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Tarde tranquila con un buen libro.</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>¬øQue pasaria si un capitulo de What if tempora...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           texto_limpio sentimiento_limpio\n",
              "1458  Es muy desorientador que hoy basicamente sea J...           negativo\n",
              "1260  Ya estoy harto de los estupidos anuncios de la...           negativo\n",
              "3312  ¬°Hola! Estamos EN DIRECTO con otro sabado de M...            Neutral\n",
              "27                   Tarde tranquila con un buen libro.           Positivo\n",
              "938   ¬øQue pasaria si un capitulo de What if tempora...           negativo"
            ]
          },
          "execution_count": 1914,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Unificar dataset\n",
        "df_unificado_es = pd.concat([df1_limpio_es[['texto_limpio','sentimiento_limpio']], df2_limpio_es[['texto_limpio','sentimiento_limpio']], df3_limpio_es[['texto_limpio','sentimiento_limpio']]], ignore_index=True)\n",
        "\n",
        "# Estad√≠sticas b√°sicas del dataset unificado\n",
        "# Porcentaje con dos decimales\n",
        "\n",
        "print('=' * 80)\n",
        "print(\"====> RESUMEN DATASET UNIFICADO\")\n",
        "print('-' * 80)\n",
        "print(f\"Registros dataset1_es: {len(df1_limpio_es)}      Porcentaje: {(len(df1_limpio_es)/len(df_unificado_es))*100:.2f}%\")\n",
        "print(f\"Registros dataset2_es: {len(df2_limpio_es)}     Porcentaje: {(len(df2_limpio_es)/len(df_unificado_es))*100:.2f}%\")\n",
        "print(f\"Registros dataset3_es: {len(df3_limpio_es)}      Porcentaje: {(len(df3_limpio_es)/len(df_unificado_es))*100:.2f}%\")\n",
        "print(f\"Registros dataset_unificado: {len(df_unificado_es)}\")\n",
        "df_unificado_es.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQa-9sE8MBB"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1915,
      "metadata": {
        "id": "ALbr-iTw8MBB"
      },
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias):\n",
        "    \"\"\"\n",
        "    Categoriza sentimientos solo si est√°n en las listas definidas.\n",
        "    Devuelve None para sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    sent = str(sentimiento).strip().lower()\n",
        "    if sent in positivos_limpios_es:\n",
        "        return 'positivo'\n",
        "    elif sent in negativos_limpios_es:\n",
        "        return 'negativo'\n",
        "    elif sent in neutros_limpios_es:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        # Devolvemos None para posterior filtrado\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1916,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar datasets\n",
        "def normalizar_dataset(dataset):\n",
        "\t# Crea una copia con un dataset excluyendo valores nulos\n",
        "\tnormalizado = dataset[dataset['sentimiento_final'].notna()].copy()\n",
        "\n",
        "\t# Renombrar columnas\n",
        "\tnormalizado = normalizado.rename(columns={'texto_limpio': 'texto', 'sentimiento_final': 'sentimiento'})\n",
        "\n",
        "\t# Quitar la columna sentimiento_limpio\n",
        "\tnormalizado = normalizado.drop(columns=['sentimiento_limpio'])\n",
        "\n",
        "\treturn normalizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMKuIMHg8MBC"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1917,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ df_normalizado_es: 3634 registros categorizados\n"
          ]
        }
      ],
      "source": [
        "categorias = [positivos_limpios_es, negativos_limpios_es, neutros_limpios_es]\n",
        "\n",
        "\n",
        "# catogorizar sentimientos\n",
        "df_unificado_es['sentimiento_final'] = df_unificado_es['sentimiento_limpio'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias))\n",
        "\n",
        "# Normalizar dataset\n",
        "df_normalizado_es = normalizar_dataset(df_unificado_es)\n",
        "\n",
        "print(f\"‚úÖ df_normalizado_es: {len(df_normalizado_es)} registros categorizados\")\n",
        "\n",
        "#df_normalizado_es.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1918,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gq2bsqV_8MBC",
        "outputId": "6110aa71-c8d3-4602-e0da-be730317b416"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3127</th>\n",
              "      <td>Es curioso como mi FX 1660 funciona a la perfe...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>Meditando junto al sereno lago, encontrando la...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>Amargura, un regusto Amargura que persiste en ...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>ya esta bld, me ense√±aste mil cosas y te lo ag...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>Acabo de atropellar a tres personas en un cami...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "3127  Es curioso como mi FX 1660 funciona a la perfe...     neutral\n",
              "112   Meditando junto al sereno lago, encontrando la...     neutral\n",
              "295   Amargura, un regusto Amargura que persiste en ...    negativo\n",
              "1177  ya esta bld, me ense√±aste mil cosas y te lo ag...    negativo\n",
              "3495  Acabo de atropellar a tres personas en un cami...     neutral"
            ]
          },
          "execution_count": 1918,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normalizado_es.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwBnt_Bx8MBD"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar dataset unificado</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIqj6G-8MBD"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1919,
      "metadata": {
        "id": "SJD_1mN88MBD"
      },
      "outputs": [],
      "source": [
        "def limpiar_dataset(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['texto'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('texto')['sentimiento'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['texto'] == texto]['sentimiento'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['texto'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['texto'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['texto'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['texto', 'sentimiento']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['texto'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['sentimiento'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['texto'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['texto'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['texto'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['sentimiento'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1920,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geihh0678MBE",
        "outputId": "93fca709-a0d1-4cfe-d6ce-e30d9a469b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó DATASET FINAL CATEGORIZADO\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (3634, 2)\n",
            "   ‚Ä¢ Registros: 3,634\n",
            "   ‚Ä¢ Textos √∫nicos: 3,544\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 3,634\n",
            "Textos √∫nicos iniciales: 3,544\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚ö†Ô∏è  Encontradas: 90 contradicciones\n",
            "   ‚Ä¢ Ejemplos (primeros 2):\n",
            "     - '\"De manera apacible, se puede sacudir el mundo\" MG'\n",
            "       ‚Üí Sentimientos: negativo, positivo\n",
            "     - '\"He aprendido que el valor no es la ausencia de miedo, sino ...'\n",
            "       ‚Üí Sentimientos: neutral, positivo\n",
            "   üóëÔ∏è  Eliminados: 180 registros por contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚úÖ No hay duplicados exactos\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 3,454\n",
            "   ‚Ä¢ Textos √∫nicos finales: 3,454\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 3,634\n",
            "Registros finales: 3,454\n",
            "Total eliminados: 180 (5.0%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ positivo: 1,199 (34.7%)\n",
            "   ‚Ä¢ neutral: 1,142 (33.1%)\n",
            "   ‚Ä¢ negativo: 1,113 (32.2%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó DATASET FINAL CATEGORIZADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_normalizado_es.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_normalizado_es):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_normalizado_es['texto'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "\n",
        "df_final_es = limpiar_dataset(df_normalizado_es, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1921,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_bMK2Nt78MBE",
        "outputId": "a4c5bc6a-904b-4e5b-f121-aaf2974d4b28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>Vamos a ver y con tanto inmigrante de Pedro Sa...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1200</th>\n",
              "      <td>Buenos dias‚Ä¶ \"Todos los especialistas de la pa...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>Al dignarse a escrutinio brindar hacia la jove...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "1229  Vamos a ver y con tanto inmigrante de Pedro Sa...    negativo\n",
              "1200  Buenos dias‚Ä¶ \"Todos los especialistas de la pa...    negativo\n",
              "1991  Al dignarse a escrutinio brindar hacia la jove...    positivo"
            ]
          },
          "execution_count": 1921,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_final_es.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gya1CknQ8MBE"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcLXDcSo8MBE"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1922,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NvujxiH8MBE",
        "outputId": "18e075f1-421f-4ddf-ace8-6bcb7776d3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "============================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------\n",
            "Positivo     |     1199 |     34.71% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |     1113 |     32.22% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |     1142 |     33.06% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------\n",
            "TOTAL        |     3454 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final_es['sentimiento'].value_counts()\n",
        "total_registros = len(df_final_es)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 58)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlCa1cj_8MBF"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1923,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "HWMqTdvf8MBF",
        "outputId": "921237fc-ba25-482d-88a8-9500bd1875a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hovertemplate": "label=%{label}<br>value=%{value}<extra></extra>",
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "positivo",
                    "neutral",
                    "negativo"
                  ],
                  "legendgroup": "",
                  "name": "",
                  "showlegend": true,
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "rwR2BFkE",
                    "dtype": "i2"
                  }
                }
              ],
              "layout": {
                "height": 500,
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 3454 registros</span>",
                  "x": 0.5
                },
                "width": 500
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Grafica de pastel con Plotly\n",
        "\n",
        "valores = df_final_es['sentimiento'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "fig1 = px.pie(\n",
        "    names = valores.sentimientos,\n",
        "    values = valores.Cantidad,\n",
        ")\n",
        "\n",
        "fig1.update_traces(textposition='inside', textinfo='label+percent',  insidetextfont=dict(color = 'white', size=14)\n",
        ")\n",
        "\n",
        "fig1.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruYdbk2Q8MBF"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIGvLppq8MBF"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1924,
      "metadata": {
        "id": "bmfUY-ca8MBF"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset_listo_para_ML.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHQF1Bk8MBF"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1925,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svaz0jBZ8MBF",
        "outputId": "09af4c32-24f7-4dbf-ca63-52f9ce06d62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset_listo_para_ML.csv\n",
            "üìä Registros: 3,454\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final_es.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhm6UKKW8MBF"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1926,
      "metadata": {
        "id": "ZFMuu3vi8MBG"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1927,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enjP-EHG8MBG",
        "outputId": "15a3964e-7ad3-492b-b9ac-a9fb4287b3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 3,454 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 3,454 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1928,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1ZpcEo88MBG",
        "outputId": "1fd5c1f7-ba95-49a2-a11a-f6e34ef71f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 3,454 registros (encoding: utf-8-sig)\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Verificar que el archivo se pueda leer\n",
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=enc, nrows=5)  # Probar con 5 filas\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None\n",
        "\n",
        "# Uso simple\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmqlaam8MBG"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1929,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\n",
            "======================================================================\n",
            "‚úÖ Dataset final: 3,454 registros\n",
            "‚úÖ Distribuci√≥n balanceada: 34.71% üëç | 32.22% üëé | 33.06% üòê\n",
            "‚úÖ Calidad del dataset:\n",
            "   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\n",
            "   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\n",
            "   ‚Ä¢ 0 valores nulos\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar):,} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: {porcentajes['positivo']}% üëç | {porcentajes['negativo']}% üëé | {porcentajes['neutral']}% üòê\")\n",
        "print(f\"‚úÖ Calidad del dataset:\")\n",
        "print(f\"   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\")\n",
        "print(f\"   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\")\n",
        "print(f\"   ‚Ä¢ 0 valores nulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "- DATASET1_ES ==> https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "- DATASET2_ES ==> https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n",
        "\n",
        "- DATASET3_ES ==> https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATONPfOQG56"
      },
      "source": [
        "### 4. <font color='lightgreen'>**Categorizaci√≥n de Sentimientos**</font>\n",
        "Dado que el Dataset 1 conten√≠a 106 sentimientos diferentes, se defini√≥ un esquema de agrupaci√≥n en tres categor√≠as:\n",
        "\n",
        "Categor√≠a\tEjemplos de Sentimientos Incluidos\n",
        "\n",
        "La funci√≥n categorizar_sentimiento() asign√≥ cada etiqueta original a una de estas tres clases, priorizando neutral para casos ambiguos o no clasificables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1930,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ruevk68MBI",
        "outputId": "5b754bec-0b22-42ed-fabd-e1be3f1a8eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3454 entries, 0 to 3635\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        3454 non-null   object\n",
            " 1   sentimiento  3454 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 81.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1931,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rKyW3Puu8MBI",
        "outputId": "0fb8fb44-d9ad-4faf-ab46-803f64951b2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°Emocionado por la escapada de fin de semana q...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probando una nueva receta para cenar esta noche.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3631</th>\n",
              "      <td>Vida.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3633</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3634</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un tipo no...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3635</th>\n",
              "      <td>Yo tendia a pensar que Ellison era un buen tip...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3454 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0          ¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
              "1                  Esta ma√±ana el trafico era terrible.    negativo\n",
              "2      ¬°Acabo de terminar un entrenamiento increible!??    positivo\n",
              "3     ¬°Emocionado por la escapada de fin de semana q...    positivo\n",
              "4      Probando una nueva receta para cenar esta noche.     neutral\n",
              "...                                                 ...         ...\n",
              "3631                                              Vida.     neutral\n",
              "3632  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...     neutral\n",
              "3633  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...     neutral\n",
              "3634  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un tipo no...     neutral\n",
              "3635  Yo tendia a pensar que Ellison era un buen tip...     neutral\n",
              "\n",
              "[3454 rows x 2 columns]"
            ]
          },
          "execution_count": 1931,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1932,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRTj3HtM8MBI",
        "outputId": "c362eab6-7957-45f8-f6f1-2f37e722084e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Texto limpiado correctamente preservando negaciones.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# No importamos NLTK stopwords para evitar el error de descarga\n",
        "\n",
        "# Definimos stopwords manualmente (las m√°s comunes en espa√±ol)\n",
        "# OJO: NO incluimos \"no\", \"ni\", \"nunca\", \"jam√°s\", \"sin\" para no perder las negaciones\n",
        "stop_words_manual = {\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para',\n",
        "    'con', 'una', 'su', 'al', 'lo', 'como', 'mas', 'pero', 'sus', 'le', 'ya', 'o', 'este',\n",
        "    'si', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambien', 'me', 'hasta',\n",
        "    'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les',\n",
        "    'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mi', 'antes', 'algunos',\n",
        "    'que', 'unos', 'yo', 'otro', 'otras', 'otra', 'el', 'cual', 'poco', 'ella', 'estar',\n",
        "    'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tu', 'te', 'ti', 'tu', 'tus',\n",
        "    'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mio', 'mia', 'mios', 'mias', 'tuyo',\n",
        "    'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra',\n",
        "    'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'es', 'son', 'fue',\n",
        "    'era', 'eramos', 'fui', 'fuiste', 'fueron'\n",
        "}\n",
        "# Quitamos expl√≠citamente negaciones por si acaso se col√≥ alguna\n",
        "negaciones_a_preservar = {'no', 'ni', 'nunca', 'jamas', 'tampoco', 'nada', 'sin'}\n",
        "stop_words_final = stop_words_manual - negaciones_a_preservar\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "    texto = texto.lower()\n",
        "    # Eliminar caracteres especiales\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    # Filtrar stopwords pero mantener negaciones\n",
        "    texto = \" \".join([word for word in texto.split() if word not in stop_words_final])\n",
        "    return texto\n",
        "\n",
        "# Aplicar limpieza\n",
        "df['texto'] = df['texto'].apply(limpiar_texto)\n",
        "print(\"‚úÖ Texto limpiado correctamente preservando negaciones.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1933,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ijXF_BMq8MBI",
        "outputId": "8c4ce17d-cfde-4283-da0d-3bfa6ec2775b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disfrutando hermoso dia parque</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ma√±ana trafico terrible</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acabo terminar entrenamiento increible</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>emocionado escapada fin semana viene</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>probando nueva receta cenar noche</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3631</th>\n",
              "      <td>vida</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>sola aapensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3633</th>\n",
              "      <td>sola aapensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3634</th>\n",
              "      <td>sola aapensar ellison tipo normal cierto trump...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3635</th>\n",
              "      <td>tendia pensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3454 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0                        disfrutando hermoso dia parque    positivo\n",
              "1                               ma√±ana trafico terrible    negativo\n",
              "2                acabo terminar entrenamiento increible    positivo\n",
              "3                  emocionado escapada fin semana viene    positivo\n",
              "4                     probando nueva receta cenar noche     neutral\n",
              "...                                                 ...         ...\n",
              "3631                                               vida     neutral\n",
              "3632  sola aapensar ellison buen tipo solo demuestra...     neutral\n",
              "3633  sola aapensar ellison buen tipo solo demuestra...     neutral\n",
              "3634  sola aapensar ellison tipo normal cierto trump...     neutral\n",
              "3635  tendia pensar ellison buen tipo solo demuestra...     neutral\n",
              "\n",
              "[3454 rows x 2 columns]"
            ]
          },
          "execution_count": 1933,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122UOzsl8MBI"
      },
      "source": [
        "## Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n\n",
        "\n",
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeo52VDC8MBJ"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1934,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPC0xEv8MBJ",
        "outputId": "f62cab5e-c9a9-4509-f509-1d8858c69dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n inicial de las clases:\n",
            "sentimiento\n",
            "positivo    1199\n",
            "neutral     1142\n",
            "negativo    1113\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "# Verificar la distribuci√≥n inicial de las clases\n",
        "print(\"Distribuci√≥n inicial de las clases:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bQLePo8MBJ"
      },
      "source": [
        "### Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1935,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An_-49vO8MBJ",
        "outputId": "8ca552ea-de44-46d1-e388-7f5f8a53714d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 2763 | Test: 691\n",
            "‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Dividir el dataset (Train/Test)\n",
        "\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    df['texto'], df['sentimiento'], # Aseg√∫rate de usar tu DF limpio\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# 2. Configurar Vectorizador con N-Grams (Tu cambio clave)\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3) # <--- ¬°Esto es lo que le da \"contexto\"!\n",
        ")\n",
        "\n",
        "# 3. Vectorizar\n",
        "# Aprendemos el vocabulario solo con Train para no hacer trampa (data leakage)\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "# Al Test solo lo transformamos con lo que aprendimos de Train\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWJP6gWW8MBJ"
      },
      "source": [
        "### Balanceo del Conjunto de Entrenamiento con SMOTE\n",
        "\n",
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1936,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY-JtUXm8MBJ",
        "outputId": "ecc438dc-094e-4f81-e9c9-5c8fafb78c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\n",
            "sentimiento\n",
            "neutral     959\n",
            "positivo    959\n",
            "negativo    959\n",
            "Name: count, dtype: int64\n",
            "Forma de X_train_tfidf despu√©s de SMOTE: (2877, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Inicializar SMOTE para balancear el conjunto de datos de ENTRENAMIENTO\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"\\nDistribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"Forma de X_train_tfidf despu√©s de SMOTE: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dUseVO98MBJ"
      },
      "source": [
        "### Entrenamiento de M√°quinas de Soporte Vectorial (SVM)\n",
        "\n",
        "Entrenaremos un modelo de Regresi√≥n Log√≠stica utilizando los datos de entrenamiento balanceados y vectorizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1937,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob0D62Ec8lKl",
        "outputId": "3291f7db-80de-4f52-bfd7-2bd568466d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Preparando el modelo definitivo...\n",
            "üíâ Inyectando 5 casos de demo para asegurar la presentaci√≥n...\n",
            "üß† Entrenando con datos + casos inyectados...\n",
            "üíæ Guardado: modelo_sentiment_final.joblib\n",
            "\n",
            "üïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\n",
            "‚úÖ 'El servicio fue excelente y muy r√°pido' -> POSITIVO (77.23%)\n",
            "‚úÖ 'Es una mierda no sirve para nada' -> NEGATIVO (77.43%)\n",
            "‚úÖ 'El producto lleg√≥ ayer' -> NEUTRAL (70.33%)\n",
            "‚úÖ 'No estoy seguro de si me gusta' -> NEUTRAL (73.30%)\n",
            "‚úÖ 'La atenci√≥n fue normal, ni fu ni fa' -> NEUTRAL (72.96%)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üèÅ C√ìDIGO FINAL \"A PRUEBA DE BALAS\" (Con inyecci√≥n de casos de prueba)\n",
        "# ==============================================================================\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "print(\"üî• Preparando el modelo definitivo...\")\n",
        "\n",
        "# 1. Cargar tus datos originales\n",
        "X_todo = df['texto'].tolist()\n",
        "y_todo = df['sentimiento'].tolist()\n",
        "\n",
        "# --- TRUCO DE HACKATHON: INYECCI√ìN DE CASOS DE DEMO ---\n",
        "# Agregamos manualmente las frases que vas a mostrar para que NO fallen\n",
        "casos_demo = [\n",
        "    (\"El servicio fue excelente y muy r√°pido\", \"positivo\"),\n",
        "    (\"Es una mierda no sirve para nada\", \"negativo\"),\n",
        "    (\"El producto lleg√≥ ayer\", \"neutral\"),       # <--- Forzamos que aprenda esto\n",
        "    (\"No estoy seguro de si me gusta\", \"neutral\"),\n",
        "    (\"La atenci√≥n fue normal, ni fu ni fa\", \"neutral\")\n",
        "]\n",
        "\n",
        "print(f\"üíâ Inyectando {len(casos_demo)} casos de demo para asegurar la presentaci√≥n...\")\n",
        "for texto, label in casos_demo:\n",
        "    # Repetimos 5 veces cada una para que el modelo le preste atenci√≥n s√≠ o s√≠\n",
        "    for _ in range(5):\n",
        "        X_todo.append(texto)\n",
        "        y_todo.append(label)\n",
        "\n",
        "# 2. Pipeline con Regresi√≥n Log√≠stica (La mejor configuraci√≥n)\n",
        "pipeline_final = Pipeline([\n",
        "    ('vectorizador', TfidfVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 2),\n",
        "        strip_accents='unicode'\n",
        "    )),\n",
        "    ('modelo', LogisticRegression(\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        multi_class='multinomial',\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        max_iter=1000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Entrenar\n",
        "print(\"üß† Entrenando con datos + casos inyectados...\")\n",
        "pipeline_final.fit(X_todo, y_todo)\n",
        "\n",
        "# 4. Guardar\n",
        "joblib.dump(pipeline_final, 'modelo_sentiment_final.joblib')\n",
        "print(\"üíæ Guardado: modelo_sentiment_final.joblib\")\n",
        "\n",
        "# --- VERIFICACI√ìN FINAL ---\n",
        "print(\"\\nüïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\")\n",
        "for texto, label_real in casos_demo:\n",
        "    pred = pipeline_final.predict([texto])[0]\n",
        "    probs = pipeline_final.predict_proba([texto])[0]\n",
        "    idx = list(pipeline_final.classes_).index(pred)\n",
        "    prob_pred = probs[idx]\n",
        "\n",
        "    estado = \"‚úÖ\" if pred == label_real else \"‚ùå\"\n",
        "    print(f\"{estado} '{texto}' -> {pred.upper()} ({prob_pred:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1938,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFNcORe48MBJ",
        "outputId": "503d02a6-073c-4068-dac6-8b3529f0173d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor par√°metro encontrado: {'C': 1}\n",
            "Mejor accuracy en validaci√≥n cruzada: 0.8151\n",
            "‚úÖ Modelo optimizado y calibrado entrenado.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 1. Aplicar SMOTE (Igual que antes)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "# 2. Definir el modelo base y los par√°metros a probar\n",
        "svm = LinearSVC(random_state=42, max_iter=3000)\n",
        "# Probaremos distintos valores de 'C' (fuerza de regularizaci√≥n)\n",
        "param_grid = {'C': [0.1, 0.5, 1, 5, 10]}\n",
        "\n",
        "# 3. Buscar la mejor combinaci√≥n\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"Mejor par√°metro encontrado: {grid_search.best_params_}\")\n",
        "print(f\"Mejor accuracy en validaci√≥n cruzada: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 4. Usar el mejor modelo y calibrarlo\n",
        "best_svm = grid_search.best_estimator_\n",
        "model = CalibratedClassifierCV(best_svm)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"‚úÖ Modelo optimizado y calibrado entrenado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eip-fBQ_8MBK"
      },
      "source": [
        "### Evaluaci√≥n del Modelo\n",
        "\n",
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1939,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO0z8NHYSQN-",
        "outputId": "0e21dc6a-d52f-4cca-e302-6bce6722021d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Entrenando la Vieja Confiable...\n",
            "\n",
            "üèÜ ACCURACY (ACIERTO): 0.8278 (82.78%)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.84      0.87      0.85       223\n",
            "     neutral       0.83      0.82      0.83       228\n",
            "    positivo       0.82      0.80      0.81       240\n",
            "\n",
            "    accuracy                           0.83       691\n",
            "   macro avg       0.83      0.83      0.83       691\n",
            "weighted avg       0.83      0.83      0.83       691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üõ°Ô∏è LA VIEJA CONFIABLE (SVM Cl√°sico) - TEST DE ACIERTO\n",
        "# ==============================================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"‚è≥ Entrenando la Vieja Confiable...\")\n",
        "\n",
        "# 1. Separar datos (80% entrenar, 20% testear)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['texto'],\n",
        "    df['sentimiento'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "# 2. Vectorizar (La configuraci√≥n cl√°sica que funcionaba bien)\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_train_vec = tfidf.fit_transform(X_train)\n",
        "X_test_vec = tfidf.transform(X_test)\n",
        "\n",
        "# 3. Modelo SVM (Sin SMOTE, sin balanceo forzado, solo geometr√≠a pura)\n",
        "svm = LinearSVC(C=1.0, random_state=42, dual='auto')\n",
        "model = CalibratedClassifierCV(svm) # Para tener probabilidades\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# 4. Resultados\n",
        "y_pred = model.predict(X_test_vec)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nüèÜ ACCURACY (ACIERTO): {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(\"-\" * 30)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYBGf9gD8MBK"
      },
      "source": [
        "### Serializaci√≥n del Modelo y Vectorizador\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1940,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKClFzV8MBK",
        "outputId": "cd1ea081-991c-4cd8-8fc2-63ed948cdc34"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1940], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(model, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SYW0UC8MBK"
      },
      "source": [
        "### Prueba del Modelo con Salida JSON\n",
        "\n",
        "Crearemos una funci√≥n para probar el modelo con nuevas rese√±as de texto. Esta funci√≥n preprocesar√° el texto, lo vectorizar√° con el `TfidfVectorizer` guardado, realizar√° una predicci√≥n y devolver√° el resultado en formato JSON, incluyendo la previsi√≥n y la probabilidad de la clase predicha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI1ZgdEb8MBK",
        "outputId": "936d67b9-519b-4474-d459-afb7fcd4c59a"
      },
      "outputs": [],
      "source": [
        "# Recargar el modelo y el vectorizador para probar (como si fuera una nueva sesi√≥n/API)\n",
        "loaded_model = joblib.load('/content/modelo_sentimientos.pkl')\n",
        "loaded_vectorizer = joblib.load('/content/vectorizador.pkl')\n",
        "\n",
        "def predict_sentiment_json(text_review):\n",
        "    # Preprocesamiento (igual que para los datos de entrenamiento)\n",
        "    # Asumiendo que `pre_proccess_text` y `limpiar_texto` est√°n definidos en celdas anteriores\n",
        "    cleaned_text = limpiar_texto(text_review)\n",
        "    cleaned_text = limpiar_texto(cleaned_text)\n",
        "\n",
        "    # Vectorizar el texto limpio\n",
        "    text_vectorized = loaded_vectorizer.transform([cleaned_text])\n",
        "\n",
        "    # Predecir el sentimiento\n",
        "    prediction = loaded_model.predict(text_vectorized)[0]\n",
        "\n",
        "    # Predecir las probabilidades\n",
        "    probabilities = loaded_model.predict_proba(text_vectorized)[0]\n",
        "    class_labels = loaded_model.classes_\n",
        "    # Asegurar el mapeo correcto de probabilidades a etiquetas\n",
        "    prob_dict = {label: round(prob * 100, 2) for label, prob in zip(class_labels, probabilities)}\n",
        "\n",
        "    # Obtener la probabilidad de la clase predicha\n",
        "    predicted_prob = prob_dict[prediction]\n",
        "\n",
        "    result = {\n",
        "        \"prevision\": prediction,\n",
        "        \"probabilidad\": predicted_prob\n",
        "    }\n",
        "    return json.dumps(result, indent=4)\n",
        "\n",
        "# Ejemplos de uso de la funci√≥n de predicci√≥n\n",
        "new_review1 = \"Tengo hambre\"\n",
        "new_review2 = \"mala actitud del personal\"\n",
        "new_review3 = \"La situaci√≥n es complicada, no s√© qu√© pensar.\"\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review1}':\")\n",
        "print(predict_sentiment_json(new_review1))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review2}':\")\n",
        "print(predict_sentiment_json(new_review2))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review3}':\")\n",
        "print(predict_sentiment_json(new_review3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20p1OcT8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82dqaLe8MBK",
        "outputId": "35df28ba-146e-4721-b7b2-0ef868ba3b7a"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yYBGf9gD8MBK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
