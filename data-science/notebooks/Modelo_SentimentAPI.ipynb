{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from _plotly_utils.basevalidators import SubplotidValidator\n",
        "from pathlib import Path\n",
        "import urllib.response\n",
        "import urllib.request\n",
        "from datetime import datetime\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import unicodedata\n",
        "from io import StringIO\n",
        "import uvicorn\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "from urllib.error import URLError, HTTPError\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de diccionario<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CARGANDO DICCIONARIO DE SENTIMIENTOS\n",
            "============================================================\n",
            "üì• Cargando diccionario desde: https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/feature/data-science-marely/data-science/sources/diccionarios/sentimientos_mapeo.json\n",
            "‚úÖ JSON cargado: 106 sentimientos\n",
            "üìä Distribuci√≥n:\n",
            "   ‚Ä¢ Positivos: 62\n",
            "   ‚Ä¢ Negativos: 39\n",
            "   ‚Ä¢ Neutros: 5\n",
            "\n",
            "============================================================\n",
            "‚úÖ VARIABLES CREADAS Y DISPONIBLES:\n",
            "============================================================\n",
            "‚Ä¢ 'datos_es' (diccionario completo): 106 elementos\n",
            "‚Ä¢ 'positivos_es' (lista): 62 elementos\n",
            "‚Ä¢ 'negativos_es' (lista): 39 elementos\n",
            "‚Ä¢ 'neutros_es' (lista): 5 elementos\n",
            "\n",
            "üîç Ejemplo de positivos: ['aceptacion', 'admiracion', 'adoracion']\n",
            "üîç Ejemplo de negativos: ['abrumado', 'aburrimiento', 'aislamiento']\n",
            "üîç Ejemplo de neutros: ['ambivalencia', 'anticipacion', 'curiosidad']\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# üéØ CARGAR DICIONARIO DE SENTIMIENTOS (VERSI√ìN CORREGIDA)\n",
        "# ==========================================================\n",
        "\n",
        "import json\n",
        "import urllib.request\n",
        "from urllib.error import URLError, HTTPError\n",
        "\n",
        "def cargar_diccionario_completo():\n",
        "    \"\"\"\n",
        "    Carga el diccionario de sentimientos y retorna TODAS las variables necesarias.\n",
        "    \"\"\"\n",
        "    # URL corregida (raw de GitHub)\n",
        "    url = \"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/feature/data-science-marely/data-science/sources/diccionarios/sentimientos_mapeo.json\"\n",
        "    \n",
        "    print(f\"üì• Cargando diccionario desde: {url}\")\n",
        "    \n",
        "    try:\n",
        "        # 1. Descargar\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "        \n",
        "        # 2. Decodificar y cargar JSON\n",
        "        datos = json.loads(content.decode('utf-8'))\n",
        "        print(f\"‚úÖ JSON cargado: {len(datos)} sentimientos\")\n",
        "        \n",
        "        # 3. Crear listas de categor√≠as\n",
        "        positivos_es = [k for k, v in datos.items() if v == 'positivo']\n",
        "        negativos_es = [k for k, v in datos.items() if v == 'negativo']\n",
        "        neutros_es = [k for k, v in datos.items() if v == 'neutral']\n",
        "\n",
        "        print(f\"üìä Distribuci√≥n:\")\n",
        "        print(f\"   ‚Ä¢ Positivos: {len(positivos_es)}\")\n",
        "        print(f\"   ‚Ä¢ Negativos: {len(negativos_es)}\")\n",
        "        print(f\"   ‚Ä¢ Neutros: {len(neutros_es)}\")\n",
        "        \n",
        "        # 4. Retornar todas las variables en un diccionario\n",
        "        return {\n",
        "            'datos': datos,\n",
        "            'positivos': positivos_es,\n",
        "            'negativos': negativos_es,\n",
        "            'neutros': neutros_es\n",
        "        }\n",
        "        \n",
        "    except HTTPError as e:\n",
        "        print(f\"‚ùå Error HTTP {e.code}: {e.reason}\")\n",
        "    except URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e.reason}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"‚ùå Error en JSON: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "\n",
        "   # Retornar diccionario vac√≠o en caso de error\n",
        "    return {\n",
        "        'datos': {},\n",
        "        'positivos': [],\n",
        "        'negativos': [],\n",
        "        'neutros': []\n",
        "    }\n",
        "\n",
        "# ==================== EJECUCI√ìN ====================\n",
        "print(\"=\" * 60)\n",
        "print(\"CARGANDO DICCIONARIO DE SENTIMIENTOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cargar y obtener todas las variables\n",
        "diccionario_data = cargar_diccionario_completo()\n",
        "\n",
        "# Extraer las variables individuales\n",
        "datos_es = diccionario_data['datos']\n",
        "positivos_es = diccionario_data['positivos']\n",
        "negativos_es = diccionario_data['negativos']\n",
        "neutros_es = diccionario_data['neutros']\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ VARIABLES CREADAS Y DISPONIBLES:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚Ä¢ 'datos_es' (diccionario completo): {len(datos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'positivos_es' (lista): {len(positivos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'negativos_es' (lista): {len(negativos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'neutros_es' (lista): {len(neutros_es)} elementos\")\n",
        "\n",
        "# Mostrar ejemplos\n",
        "if positivos_es:\n",
        "    print(f\"\\nüîç Ejemplo de positivos: {positivos_es[:3]}\")\n",
        "if negativos_es:\n",
        "    print(f\"üîç Ejemplo de negativos: {negativos_es[:3]}\")\n",
        "if neutros_es:\n",
        "    print(f\"üîç Ejemplo de neutros: {neutros_es[:3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "#============================================================================\n",
        "#FUNCI√ìN AUXILIAR - PROCESAR DICCIONARIO Y NOMBRES DE VARIABLES\n",
        "# ============================================================================\n",
        "def procesar_dic(dict, funcion_proceso, sufijo=''):\n",
        "    \"\"\"\n",
        "    Procesa todos los elementos de un diccionario seg√∫n su idioma\n",
        "    Funci√≥n auxiliar para iteraci√≥n de diccionarios y creaci√≥n de nombres actualizados.\n",
        "    Args:\n",
        "        dict: Diccionario {nombre_df: dataframe}\n",
        "        funcion_proceso: Funci√≥n que procesa un dataframe\n",
        "        sufijo: Sufijo para el nuevo nombre\n",
        "\n",
        "    Returns:\n",
        "        Nuevo diccionario con nombres actualizados\n",
        "    \"\"\"\n",
        "    nuevo_dict = {}\n",
        "\n",
        "    for nombre, item in dict.items():\n",
        "        # Extraer partes del nombre\n",
        "        partes = nombre.split('_')\n",
        "\n",
        "        if len(partes) >= 2:\n",
        "            nombre_base = partes[0]          # 'df1'\n",
        "\n",
        "            # Aplicar funci√≥n de procesamiento\n",
        "            df_proc = funcion_proceso(item, nombre)\n",
        "\n",
        "            # Crear nuevo nombre\n",
        "            nuevo_nombre = f\"{nombre_base}{sufijo}\"\n",
        "            nuevo_dict[nuevo_nombre] = df_proc\n",
        "\n",
        "            print(f\"‚úÖ {nombre} ‚Üí {nuevo_nombre}\")\n",
        "            print('-' * 80)\n",
        "\n",
        "    return nuevo_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Url Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = {\n",
        "    \"df1_es\":\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset1_esp.csv,sep=;\",\n",
        "    \"df2_es\":\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset2_esp.csv,sep=;\",\n",
        "    \"df3_es\":\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset3_esp.csv,sep=,\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando carga de datasets...\n",
            "============================================================\n",
            ">>> INFORME DE CARGA DATASETS\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "üì• PROCESANDO: df1_es\n",
            "==================================================\n",
            "üîó URL: https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/d...\n",
            "üìù Separador detectado: ';'\n",
            "‚è¨ Descargando contenido...\n",
            "üîç Detectando encoding autom√°ticamente...\n",
            "üîç Encoding detectado: utf-8 (confianza: 99.00%)\n",
            "üíæ Cargando DataFrame...\n",
            "‚úÖ df1_es: Cargado exitosamente\n",
            "üìä Dimensiones: 1465 filas √ó 15 columnas\n",
            "üìã Columnas (15):\n",
            "   1. Unnamed: 0.1\n",
            "   2. Unnamed: 0\n",
            "   3. Text\n",
            "   4. Sentiment\n",
            "   5. Timestamp\n",
            "   ... y 10 columnas m√°s\n",
            "üîç Muestra (3 filas aleatorias):\n",
            "Unnamed: 0.1 Unnamed: 0                                                              Text    Sentiment        Timestamp         User  Platform                       Hashtags Retweets Likes Country Year Month Day Hour\n",
            "         183        185    El aburrimiento se asienta como polvo, la vida parece mundana. Aburrimiento 28-11-2016 19:00 MundaneHeart Instagram       #Aburrimiento #Monoton√≠a        7    15  Canad√° 2016    11  28   19\n",
            "           6          6 Los d√≠as de lluvia requieren mantas c√≥modas y chocolate caliente.     Positivo 16-01-2023 14:45    RainyDays  Facebook       #D√≠aslluviosos #Acogedor       10    20  Canad√° 2023     1  16   14\n",
            "         374        378            Envuelto en serenidad mientras practica junto al lago.      Neutral  20-10-2017 8:15    ZenSeeker Instagram #Mindfulness #LagoTranquilidad       35    70  Canad√° 2017    10  20    8\n",
            "‚úÖ df1_es ‚Üí df1_cargado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "üì• PROCESANDO: df2_es\n",
            "==================================================\n",
            "üîó URL: https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/d...\n",
            "üìù Separador detectado: ';'\n",
            "‚è¨ Descargando contenido...\n",
            "üîç Detectando encoding autom√°ticamente...\n",
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "üíæ Cargando DataFrame...\n",
            "‚úÖ df2_es: Cargado exitosamente\n",
            "üìä Dimensiones: 2540 filas √ó 3 columnas\n",
            "üìã Columnas (3):\n",
            "   1. texto\n",
            "   2. label\n",
            "   3. sentimiento\n",
            "üîç Muestra (3 filas aleatorias):\n",
            "                                                                                                                                                                                                                                                             texto  label sentimiento\n",
            "A pesar de la inestabilidad pol√≠tica Peru logro mantener la estabilidad econ√≥mica y el crecimiento gracias a un Presidente del Banco Central capaz e independiente. La Asamblea Legislativa deber√≠a cumplir su deber y presentar una terna competente para el BCB.      1     neutral\n",
            "                                                                                                                                                                                                                                                           Q calor      2    positivo\n",
            "                                                                                    yo creo q michael jackson tiene pose√≠do al jung kook loco cuando lo veo bailando standing next ti you solo pienso en michael hace las mismas caras se mueve muy parecido basta      0    negativo\n",
            "‚úÖ df2_es ‚Üí df2_cargado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "üì• PROCESANDO: df3_es\n",
            "==================================================\n",
            "üîó URL: https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/d...\n",
            "üìù Separador detectado: ';'\n",
            "‚è¨ Descargando contenido...\n",
            "üîç Detectando encoding autom√°ticamente...\n",
            "üîç Encoding detectado: Windows-1254 (confianza: 56.84%)\n",
            "üíæ Cargando DataFrame...\n",
            "‚ö†Ô∏è  Error con separador ';'. Probando alternativas...\n",
            "‚úÖ df3_es: Cargado con separador alternativo ','\n",
            "üìä Dimensiones: 740 filas √ó 4 columnas\n",
            "üìã Columnas (4):\n",
            "   1. id\n",
            "   2. plataforma\n",
            "   3. sentimiento\n",
            "   4. texto\n",
            "üîç Muestra (3 filas aleatorias):\n",
            "  id         plataforma sentimiento                                                                                                                                                                                                                                              texto\n",
            "9179             Nvidia     Neutral                                                                                                                                   ¬°Descubre nuestra hermosa CSS y RTX 3090 MASTER! ¬øY qu√© te parece el dise√±o? M√°s informaci√≥n en At.com/rtx30/...\n",
            "5284 Plataformas Online     Neutral                                                                                                                                                                                             El paquete fue entregado en la recepci√≥n del edificio.\n",
            "9192             Nvidia     Neutral Ahorra $500 en la AERO 15 OLED: dise√±o galardonado, impresionante panel OLED 4K, colores precisos desde el primer momento, n√∫cleo i7 y GPU Nvidia GTX. ¬°Una laptop fant√°stica para trabajar desde casa y crear en cualquier lugar! buff.ly/3kd6oRQ\n",
            "‚úÖ df3_es ‚Üí df3_cargado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            ">>> RESUMEN DE CARGA\n",
            "============================================================\n",
            "üìä Datasets cargados exitosamente: 3/3\n",
            "  ‚úÖ df1_es ‚Üí df1_cargado: (1465, 15)\n",
            "  ‚úÖ df2_es ‚Üí df2_cargado: (2540, 3)\n",
            "  ‚úÖ df3_es ‚Üí df3_cargado: (740, 4)\n",
            "\n",
            "üéØ DATASETS CARGADOS DISPONIBLES:\n",
            "  ‚Ä¢ df1_cargado: DataFrame con forma (1465, 15)\n",
            "  ‚Ä¢ df2_cargado: DataFrame con forma (2540, 3)\n",
            "  ‚Ä¢ df3_cargado: DataFrame con forma (740, 4)\n"
          ]
        }
      ],
      "source": [
        "# IMPORTAR DATASETS\n",
        "\n",
        "def importar_dataset(url_param, nombre):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL que incluye par√°metros en el string.\n",
        "    Formato: \"url,sep=X\" o \"url,encoding=Y,sep=Z\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"üì• PROCESANDO: {nombre}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        # 1. Parsear URL y par√°metros usando regex para mayor robustez\n",
        "        if ',' in url_param:\n",
        "            # Encontrar la URL (todo antes del primer par√°metro)\n",
        "            match = re.match(r'^([^,]+)(,.+)?$', url_param)\n",
        "            if match:\n",
        "                url = match.group(1).strip()\n",
        "                parametros_str = match.group(2) or \"\"\n",
        "            else:\n",
        "                url = url_param\n",
        "                parametros_str = \"\"\n",
        "        else:\n",
        "            url = url_param\n",
        "            parametros_str = \"\"\n",
        "        \n",
        "        print(f\"üîó URL: {url[:80]}...\" if len(url) > 80 else f\"üîó URL: {url}\")\n",
        "        \n",
        "        # 2. Extraer par√°metros con valores por defecto\n",
        "        sep = ';'  # separador por defecto\n",
        "        encoding_param = None\n",
        "        \n",
        "        if parametros_str:\n",
        "            # Extraer todos los par√°metros tipo \"key=value\"\n",
        "            parametros = re.findall(r'(\\w+)=([^,]+)', parametros_str)\n",
        "            parametros_dict = dict(parametros)\n",
        "            \n",
        "            # Obtener separador\n",
        "            if 'sep' in parametros_dict:\n",
        "                sep = parametros_dict['sep']\n",
        "                # Si sep es literal 'comma', convertirlo a ','\n",
        "                if sep.lower() == 'comma':\n",
        "                    sep = ','\n",
        "            \n",
        "            # Obtener encoding si est√° especificado\n",
        "            if 'encoding' in parametros_dict:\n",
        "                encoding_param = parametros_dict['encoding']\n",
        "        \n",
        "        print(f\"üìù Separador detectado: '{sep}'\")\n",
        "        if encoding_param:\n",
        "            print(f\"üìù Encoding especificado: {encoding_param}\")\n",
        "        \n",
        "        # 3. Descargar contenido\n",
        "        print(\"‚è¨ Descargando contenido...\")\n",
        "        req = urllib.request.Request(\n",
        "            url, \n",
        "            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
        "        )\n",
        "        \n",
        "        with urllib.request.urlopen(req, timeout=30) as response:\n",
        "            content = response.read()\n",
        "        \n",
        "        # 4. Determinar encoding\n",
        "        if encoding_param and encoding_param.lower() != 'auto':\n",
        "            # Usar encoding especificado\n",
        "            encoding = encoding_param\n",
        "            print(f\"üîç Usando encoding especificado: {encoding}\")\n",
        "        else:\n",
        "            # Detectar encoding autom√°ticamente\n",
        "            print(\"üîç Detectando encoding autom√°ticamente...\")\n",
        "            result = chardet.detect(content)\n",
        "            encoding = result['encoding'] or 'utf-8'\n",
        "            print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "        \n",
        "        # 5. Decodificar y cargar\n",
        "        print(\"üíæ Cargando DataFrame...\")\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        \n",
        "        # Intentar cargar con el separador detectado\n",
        "        try:\n",
        "            data = pd.read_csv(StringIO(decoded_content), sep=sep)\n",
        "            print(f\"‚úÖ {nombre}: Cargado exitosamente\")\n",
        "            \n",
        "        except pd.errors.ParserError:\n",
        "            print(f\"‚ö†Ô∏è  Error con separador '{sep}'. Probando alternativas...\")\n",
        "            # Probar separadores alternativos comunes\n",
        "            separadores_alternativos = [',', ';', '\\t', '|']\n",
        "            \n",
        "            for alt_sep in separadores_alternativos:\n",
        "                if alt_sep != sep:  # No probar el mismo\n",
        "                    try:\n",
        "                        data = pd.read_csv(StringIO(decoded_content), sep=alt_sep)\n",
        "                        print(f\"‚úÖ {nombre}: Cargado con separador alternativo '{alt_sep}'\")\n",
        "                        break\n",
        "                    except:\n",
        "                        continue\n",
        "            else:\n",
        "                # Si ning√∫n separador funciona, intentar sin especificar\n",
        "                print(\"üîÑ Intentando con separador autom√°tico...\")\n",
        "                data = pd.read_csv(StringIO(decoded_content), sep=None, engine='python')\n",
        "                print(f\"‚úÖ {nombre}: Cargado con separador autom√°tico\")\n",
        "        \n",
        "        # 6. Mostrar informaci√≥n del dataset\n",
        "        print(f\"üìä Dimensiones: {data.shape[0]} filas √ó {data.shape[1]} columnas\")\n",
        "        print(f\"üìã Columnas ({len(data.columns)}):\")\n",
        "        for i, col in enumerate(data.columns[:5]):  # Mostrar primeras 5 columnas\n",
        "            print(f\"   {i+1}. {col}\")\n",
        "        if len(data.columns) > 5:\n",
        "            print(f\"   ... y {len(data.columns)-5} columnas m√°s\")\n",
        "        \n",
        "        print(f\"üîç Muestra (3 filas aleatorias):\")\n",
        "        print(data.sample(min(3, len(data))).to_string(index=False))\n",
        "        \n",
        "        return data\n",
        "        \n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de conexi√≥n en {nombre}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado en {nombre}: {type(e).__name__}: {str(e)[:100]}...\")\n",
        "        return None\n",
        "\n",
        "# Tu c√≥digo original SIN MODIFICAR\n",
        "def fase_carga_datasets(datasets):\n",
        "    print('=' * 60)\n",
        "    print('>>> INFORME DE CARGA DATASETS')\n",
        "    print('=' * 60)\n",
        "    \n",
        "    nuevo_diccionario = procesar_dic(\n",
        "        dict=datasets,\n",
        "        funcion_proceso=importar_dataset,\n",
        "        sufijo='_cargado'\n",
        "    )\n",
        "    \n",
        "    # Resumen final\n",
        "    print('\\n' + '=' * 60)\n",
        "    print('>>> RESUMEN DE CARGA')\n",
        "    print('=' * 60)\n",
        "    \n",
        "    cargados = sum(1 for df in nuevo_diccionario.values() if df is not None)\n",
        "    print(f\"üìä Datasets cargados exitosamente: {cargados}/{len(datasets)}\")\n",
        "    \n",
        "    for nombre_original, df in zip(datasets.keys(), nuevo_diccionario.values()):\n",
        "        nombre_nuevo = nombre_original.split('_')[0] + '_cargado'\n",
        "        if df is not None:\n",
        "            print(f\"  ‚úÖ {nombre_original} ‚Üí {nombre_nuevo}: {df.shape}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå {nombre_original} ‚Üí {nombre_nuevo}: FALL√ì\")\n",
        "    \n",
        "    return nuevo_diccionario\n",
        "\n",
        "\n",
        "# Ejecutar\n",
        "print(\"üöÄ Iniciando carga de datasets...\")\n",
        "dfs_originales = fase_carga_datasets(datasets)\n",
        "\n",
        "# Verificar resultados\n",
        "if dfs_originales:\n",
        "    print(\"\\nüéØ DATASETS CARGADOS DISPONIBLES:\")\n",
        "    for nombre, df in dfs_originales.items():\n",
        "        if df is not None:\n",
        "            print(f\"  ‚Ä¢ {nombre}: {type(df).__name__} con forma {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['df1_cargado', 'df2_cargado', 'df3_cargado']\n"
          ]
        }
      ],
      "source": [
        "# Mostrar las claves del diccionario de dataframes cargados\n",
        "print(list(dfs_originales.keys()))\n",
        "df1_cargado = dfs_originales.get('df1_cargado')\n",
        "df2_cargado = dfs_originales.get('df2_cargado')\n",
        "df3_cargado = dfs_originales.get('df3_cargado')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNDDOVQQ8MA-"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar y explorar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalizar_columnas(df):\n",
        "    df_copia = df.copy()\n",
        "\n",
        "    col_texto_encontrada = None\n",
        "    # Buscar una columna que pueda contener el texto\n",
        "    for nombre_columna in ['texto', 'Text', 'contenido']:\n",
        "        if nombre_columna in df_copia.columns:\n",
        "            col_texto_encontrada = nombre_columna\n",
        "            break\n",
        "\n",
        "    col_sentimiento_encontrada = None\n",
        "    # Buscar una columna que pueda contener el sentimiento\n",
        "    for nombre_columna in ['sentimiento', 'Sentiment', 'etiqueta']:\n",
        "        if nombre_columna in df_copia.columns:\n",
        "            # Si la columna 'sentimiento' ya existe y es de tipo string (ej., 'positivo', 'negativo'), priorizarla.\n",
        "            if nombre_columna == 'sentimiento' and df_copia[nombre_columna].dtype == 'object':\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "                break\n",
        "            # De lo contrario, si 'Sentiment' existe y es de tipo objeto\n",
        "            elif nombre_columna == 'Sentiment' and df_copia[nombre_columna].dtype == 'object':\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "                break\n",
        "            # Si 'etiqueta' existe (a menudo num√©rica para sentimiento)\n",
        "            elif nombre_columna == 'etiqueta' and pd.api.types.is_numeric_dtype(df_copia[nombre_columna]):\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "                # No salir inmediatamente, ya que una columna 'sentimiento' de tipo string podr√≠a existir y ser preferible.\n",
        "                # Continuar buscando 'sentimiento' o 'Sentiment' primero.\n",
        "            # Caso general para cualquier otra columna de sentimiento encontrada\n",
        "            elif col_sentimiento_encontrada is None: # Solo asignar si no se ha asignado ya una de mayor prioridad.\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "\n",
        "    if col_texto_encontrada is None or col_sentimiento_encontrada is None:\n",
        "        # Si las columnas esenciales faltan, retornar un DataFrame vac√≠o con las columnas esperadas.\n",
        "        return pd.DataFrame(columns=['texto', 'sentimiento'])\n",
        "\n",
        "    # Renombrar si es necesario\n",
        "    if col_texto_encontrada != 'texto':\n",
        "        df_copia.rename(columns={col_texto_encontrada: 'texto'}, inplace=True)\n",
        "    if col_sentimiento_encontrada != 'sentimiento':\n",
        "        df_copia.rename(columns={col_sentimiento_encontrada: 'sentimiento'}, inplace=True)\n",
        "\n",
        "    # Retornar solo las dos columnas requeridas.\n",
        "    return df_copia[['texto', 'sentimiento']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filtrar_dataframe(df,nombre):\n",
        "    # A√±adir una verificaci√≥n al inicio para DataFrame nulo\n",
        "    if df is None:\n",
        "        print(f\"Advertencia: DataFrame '{nombre}' es None, saltando filtrado.\")\n",
        "        return None\n",
        "\n",
        "    # Paso 1: Normalizar nombres de columnas\n",
        "    # normalizar_columnas ahora devuelve solo 'texto' y 'sentimiento' o un df vac√≠o.\n",
        "    df = normalizar_columnas(df)\n",
        "\n",
        "    # Paso 2: Verificar que las columnas necesarias existan despu√©s de la normalizaci√≥n\n",
        "    columnas_requeridas = ['texto', 'sentimiento']\n",
        "    if not all(col in df.columns for col in columnas_requeridas) or df.empty:\n",
        "        # Si la normalizaci√≥n fall√≥ o devolvi√≥ un df vac√≠o, df estar√° vac√≠o aqu√≠.\n",
        "        print(f\"Advertencia: No se encontraron las columnas requeridas o el DataFrame est√° vac√≠o despu√©s de normalizar en {nombre}.\")\n",
        "        return None\n",
        "\n",
        "    # Paso 3: La l√≥gica actual de filtrado (ahora se garantiza que df tiene 'texto', 'sentimiento')\n",
        "    df_filtrado = df[columnas_requeridas].copy()\n",
        "\n",
        "    # Mostrar estad√≠sticas\n",
        "    print(f'\\nRESUMEN {nombre}')\n",
        "    print(f\"üìä Tama√±o del dataframe: {df_filtrado.shape}\")\n",
        "    print(f\"üìä Registros √∫nicos: {df_filtrado['texto'].nunique()}\")\n",
        "    print(f\"üìä Sentimientos √∫nicos: {df_filtrado['sentimiento'].nunique()}\")\n",
        "    print(f\"üìä Textos vac√≠os: {df_filtrado['texto'].isnull().sum()}\")\n",
        "    print(f\"üìä Sentimientos vac√≠os: {df_filtrado['sentimiento'].isnull().sum()}\")\n",
        "    print(f\"üìä Registros duplicados: {df_filtrado.duplicated().sum()}\")\n",
        "    print(f\"üìä Textos duplicados: {df_filtrado.duplicated(subset=['texto']).sum()}\")\n",
        "\n",
        "    print(df_filtrado.sample(3))\n",
        "\n",
        "    return df_filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RESUMEN df1_cargado\n",
            "üìä Tama√±o del dataframe: (1465, 2)\n",
            "üìä Registros √∫nicos: 708\n",
            "üìä Sentimientos √∫nicos: 105\n",
            "üìä Textos vac√≠os: 2\n",
            "üìä Sentimientos vac√≠os: 2\n",
            "üìä Registros duplicados: 754\n",
            "üìä Textos duplicados: 756\n",
            "                                                  texto    sentimiento\n",
            "1191  En el tapiz de la desesperaci√≥n, se desenredan...  Desesperaci√≥n\n",
            "548   Al presenciar un conmovedor regreso en la fina...  Reconfortante\n",
            "555   Al experimentar una serie de derrotas en la te...        Neutral\n",
            "‚úÖ df1_cargado ‚Üí df1_filtrado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESUMEN df2_cargado\n",
            "üìä Tama√±o del dataframe: (2540, 2)\n",
            "üìä Registros √∫nicos: 2156\n",
            "üìä Sentimientos √∫nicos: 3\n",
            "üìä Textos vac√≠os: 0\n",
            "üìä Sentimientos vac√≠os: 0\n",
            "üìä Registros duplicados: 298\n",
            "üìä Textos duplicados: 384\n",
            "                                                  texto sentimiento\n",
            "1993  Admito que un momento muy veneco de mi parte a...     neutral\n",
            "1319  Ayer sin querer recib√≠ de color azul mis calzo...    positivo\n",
            "738   El prejuicio es una carga que confunde el pasa...    negativo\n",
            "‚úÖ df2_cargado ‚Üí df2_filtrado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESUMEN df3_cargado\n",
            "üìä Tama√±o del dataframe: (740, 2)\n",
            "üìä Registros √∫nicos: 697\n",
            "üìä Sentimientos √∫nicos: 3\n",
            "üìä Textos vac√≠os: 0\n",
            "üìä Sentimientos vac√≠os: 0\n",
            "üìä Registros duplicados: 43\n",
            "üìä Textos duplicados: 43\n",
            "                                                 texto sentimiento\n",
            "44   Pero... el nuevo hardware de Nvidia, la serie ...     Neutral\n",
            "125  ¬°Dios m√≠o! ¬°Encontr√© una empresa de dise√±o 3D ...     Neutral\n",
            "697  Nos enorgullece anunciar que recientemente hem...     Neutral\n",
            "‚úÖ df3_cargado ‚Üí df3_filtrado\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def fase_filtrado(dfs_originarios):\n",
        "    # Solo orquesta: delega el recorrido a procesar_dict\n",
        "    dfs_filtrados = procesar_dic(\n",
        "        dict=dfs_originales,\n",
        "        funcion_proceso=filtrar_dataframe,\n",
        "        sufijo='_filtrado'\n",
        "    )\n",
        "    return dfs_filtrados\n",
        "\n",
        "# Uso\n",
        "dfs_filtrados = fase_filtrado(dfs_originales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['df1_filtrado', 'df2_filtrado', 'df3_filtrado']\n"
          ]
        }
      ],
      "source": [
        "print(list(dfs_filtrados.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "    \n",
        "    # Elimina los caracteres '#' que est√°n directamente seguidos por una palabra (hashtags).\n",
        "    resultado = re.sub(r'#(?=\\S)', '', resultado)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "def obtener_lista_ordenada(*series_o_listas: Iterable,nombre='nombre'):\n",
        "    \"\"\"\n",
        "    Acepta cualquier cantidad de Series/Listas de sentimientos y devuelve\n",
        "    una lista ordenada de sentimientos √∫nicos ya limpios.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Unir todas las entradas en un solo iterable\n",
        "    todos = []\n",
        "    for s in series_o_listas:\n",
        "        todos.extend(list(s))\n",
        "\n",
        "\n",
        "    # 2) Limpiar y eliminar duplicados en un solo paso usando un set\n",
        "    sentimientos_limpios = {limpiar_texto_sentimientos(x) for x in todos}\n",
        "\n",
        "    print('\\n====> RESUMEN LIMPIEZA',nombre)\n",
        "    print(f'üìä Registros (original):',len(todos))\n",
        "    print(f'üìä Registros (despues de la limpieza):',len(sentimientos_limpios))\n",
        "    # listar \n",
        "    print(f'Lista {nombre} limpios: {', '.join(sentimientos_limpios)}')\n",
        "\n",
        "    print('-' * 80)\n",
        "\n",
        "    # 3) Devolver ordenado\n",
        "    return sorted(sentimientos_limpios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpieza dataframe\n",
        "\n",
        "def limpiar_columnas(df, col1_name, col2_name, nombre_df):\n",
        "    df_copy = df.copy()\n",
        "    \n",
        "    print(f\"üîÑ Procesando {nombre_df}...\")\n",
        "    print(f\"  Antes: {df_copy.shape}\")\n",
        "    \n",
        "    df_copy[col1_name + \"_limpio\"] = df_copy[col1_name].apply(limpiar_texto_sentimientos)\n",
        "    df_copy[col2_name + \"_limpio\"] = df_copy[col2_name].apply(limpiar_texto_sentimientos)\n",
        "    \n",
        "    print(f\"  Despu√©s: {df_copy.shape}, nuevas cols: {col1_name}_limpio, {col2_name}_limpio\")\n",
        "    \n",
        "    return df_copy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ FASE 1: LIMPIEZA B√ÅSICA (COM√öN A TODOS)\n",
            "======================================================================\n",
            "üîÑ Procesando df1_filtrado...\n",
            "  Antes: (1465, 2)\n",
            "  Despu√©s: (1465, 4), nuevas cols: texto_limpio, sentimiento_limpio\n",
            "‚úÖ df1_filtrado ‚Üí df1_limpio\n",
            "--------------------------------------------------------------------------------\n",
            "üîÑ Procesando df2_filtrado...\n",
            "  Antes: (2540, 2)\n",
            "  Despu√©s: (2540, 4), nuevas cols: texto_limpio, sentimiento_limpio\n",
            "‚úÖ df2_filtrado ‚Üí df2_limpio\n",
            "--------------------------------------------------------------------------------\n",
            "üîÑ Procesando df3_filtrado...\n",
            "  Antes: (740, 2)\n",
            "  Despu√©s: (740, 4), nuevas cols: texto_limpio, sentimiento_limpio\n",
            "‚úÖ df3_filtrado ‚Üí df3_limpio\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úÖ LIMPIEZA B√ÅSICA COMPLETADA\n",
            "‚Ä¢ Entrada: 3 datasets\n",
            "‚Ä¢ Salida: 3 datasets procesados\n",
            "['df1_limpio', 'df2_limpio', 'df3_limpio']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# FUNCI√ìN 3: Fase de limpieza b√°sica (ORQUESTADOR)\n",
        "# ============================================================================\n",
        "def fase_limpieza_texto(dfs_filtrados):\n",
        "    \"\"\"\n",
        "    Orquesta la limpieza b√°sica de todos los datasets\n",
        "\n",
        "    Args:\n",
        "        dfs_originales: Diccionario con datasets filtrados\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con datasets despu√©s de limpieza b√°sica\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üöÄ FASE 1: LIMPIEZA B√ÅSICA (COM√öN A TODOS)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Usar procesar_dict_con_idioma para recorrer todos\n",
        "    dfs_limpios_resultado = procesar_dic(\n",
        "        dict=dfs_filtrados, # Corrected: should use dfs_filtrados here\n",
        "        funcion_proceso=lambda df, nombre: limpiar_columnas(\n",
        "            df,\n",
        "            col1_name=\"texto\",\n",
        "            col2_name=\"sentimiento\",\n",
        "            nombre_df=nombre\n",
        "        ),\n",
        "        sufijo='_limpio'\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ LIMPIEZA B√ÅSICA COMPLETADA\")\n",
        "    print(f\"‚Ä¢ Entrada: {len(dfs_filtrados)} datasets\")\n",
        "    print(f\"‚Ä¢ Salida: {len(dfs_limpios_resultado)} datasets procesados\")\n",
        "\n",
        "    return dfs_limpios_resultado\n",
        "\n",
        "# Call the function and assign its result to the global dfs_limpios\n",
        "dfs_limpios = fase_limpieza_texto(dfs_filtrados)\n",
        "print(list(dfs_limpios.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=lightgreen size=12>Unificar dfs</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä ESTAD√çSTICAS ANTES DE UNIFICAR:\n",
            "==================================================\n",
            "df1_limpio: 1465 filas, 4 cols\n",
            "  Columnas: ['texto', 'sentimiento', 'texto_limpio', 'sentimiento_limpio']\n",
            "df2_limpio: 2540 filas, 4 cols\n",
            "  Columnas: ['texto', 'sentimiento', 'texto_limpio', 'sentimiento_limpio']\n",
            "df3_limpio: 740 filas, 4 cols\n",
            "  Columnas: ['texto', 'sentimiento', 'texto_limpio', 'sentimiento_limpio']\n",
            "\n",
            "‚úÖ UNIFICACI√ìN COMPLETADA:\n",
            "==================================================\n",
            "df_unificado: 4745 filas, 4 cols\n",
            "Total filas originales: 4745 ‚úì\n",
            "\n",
            "Primeras 3 filas:\n",
            "                                              texto sentimiento  \\\n",
            "0      ¬°Disfrutando de un hermoso d√≠a en el parque!    Positivo   \n",
            "1              Esta ma√±ana el tr√°fico era terrible.    Negativo   \n",
            "2  ¬°Acabo de terminar un entrenamiento incre√≠ble!??    Positivo   \n",
            "\n",
            "                                       texto_limpio sentimiento_limpio  \n",
            "0      ¬°Disfrutando de un hermoso dia en el parque!           Positivo  \n",
            "1              Esta ma√±ana el trafico era terrible.           Negativo  \n",
            "2  ¬°Acabo de terminar un entrenamiento increible!??           Positivo  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def unificar_dfs_limpios(dfs_limpios):\n",
        "    \"\"\"\n",
        "    Une todos los DataFrames del diccionario dfs_limpios en df_unificado.\n",
        "    Valida columnas iguales y muestra estad√≠sticas detalladas.\n",
        "    \"\"\"\n",
        "    # Validaciones\n",
        "    if not dfs_limpios:\n",
        "        print(\"‚ùå Error: dfs_limpios est√° vac√≠o\")\n",
        "        return None\n",
        "    \n",
        "    dfs_list = list(dfs_limpios.values())\n",
        "    columnas_esperadas = ['texto_limpio', 'sentimiento_limpio']  # De tu workflow\n",
        "    \n",
        "    # Estad√≠sticas antes de unir\n",
        "    print(\"üìä ESTAD√çSTICAS ANTES DE UNIFICAR:\")\n",
        "    print(\"=\" * 50)\n",
        "    total_filas = 0\n",
        "    for nombre, df in dfs_limpios.items():\n",
        "        print(f\"{nombre}: {df.shape[0]} filas, {df.shape[1]} cols\")\n",
        "        print(f\"  Columnas: {list(df.columns)}\")\n",
        "        if not all(col in df.columns for col in columnas_esperadas):\n",
        "            print(f\"  ‚ö†Ô∏è  {nombre} falta columnas esperadas\")\n",
        "        total_filas += df.shape[0]\n",
        "    \n",
        "    # Verificar columnas iguales\n",
        "    columnas_set = {frozenset(df.columns) for df in dfs_list}\n",
        "    if len(columnas_set) > 1:\n",
        "        print(\"‚ùå Error: Columnas no coinciden entre DataFrames\")\n",
        "        return None\n",
        "    \n",
        "    # Unificar\n",
        "    df_unificado = pd.concat(dfs_list, ignore_index=True)\n",
        "    \n",
        "    # Estad√≠sticas despu√©s\n",
        "    print(\"\\n‚úÖ UNIFICACI√ìN COMPLETADA:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"df_unificado: {df_unificado.shape[0]} filas, {df_unificado.shape[1]} cols\")\n",
        "    print(f\"Total filas originales: {total_filas} ‚úì\")\n",
        "    print(\"\\nPrimeras 3 filas:\")\n",
        "    print(df_unificado.head(3))\n",
        "    \n",
        "    return df_unificado\n",
        "\n",
        "# Uso:\n",
        "df_unificado = unificar_dfs_limpios(dfs_limpios)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwBnt_Bx8MBD"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar df unificado</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîó df_unificado creado: 4,745 filas\n",
            "\n",
            "üßπ LIMPIEZA R√ÅPIDA CON ESTAD√çSTICAS Y AUDITOR√çA\n",
            "======================================================================\n",
            "\n",
            "üìä INICIAL: 4,745 registros\n",
            "üîç Textos contradictorios √∫nicos: 90\n",
            "üìà Registros afectados: 180 (todos se eliminar√°n)\n",
            "   Ejemplos:\n",
            "     ‚ùå '\"De manera apacible, se puede sacudir el mundo\" MG...' ‚Üí ['negativo', 'positivo'] (3 regs)\n",
            "     ‚ùå '\"He aprendido que el valor no es la ausencia de mi...' ‚Üí ['neutral', 'positivo'] (2 regs)\n",
            "     ‚ùå '\"La soledad es peligrosa. Es muy adictiva. Se conv...' ‚Üí ['negativo', 'positivo'] (6 regs)\n",
            "     ... y 87 m√°s\n",
            "\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS CONTRADICTORIOS: 216\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS DUPLICADOS:     1,073\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS NULOS/VAC√çOS:  1\n",
            "\n",
            "üìä FINAL: 3,455 registros\n",
            "üìä ELIMINADOS TOTAL: 1,290 (27.2%)\n"
          ]
        }
      ],
      "source": [
        "def limpieza_rapida_con_estadisticas(df, col_texto='texto_limpio', col_sentimiento='sentimiento_limpio'):\n",
        "    \"\"\"\n",
        "    Versi√≥n MEJORADA de TU funci√≥n original + visualizaci√≥n contradicciones\n",
        "    \"\"\"\n",
        "    print(\"üßπ LIMPIEZA R√ÅPIDA CON ESTAD√çSTICAS Y AUDITOR√çA\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    df_original = df.copy()\n",
        "    registros_iniciales = len(df)\n",
        "    \n",
        "    # AUDITOR√çA CONTRADICCIONES (nueva funcionalidad)\n",
        "    print(f\"\\nüìä INICIAL: {registros_iniciales:,} registros\")\n",
        "    grupos = df.groupby(col_texto)[col_sentimiento].nunique()\n",
        "    contradictorios = grupos[grupos > 1]\n",
        "    print(f\"üîç Textos contradictorios √∫nicos: {len(contradictorios):,}\")\n",
        "    print(f\"üìà Registros afectados: {contradictorios.sum():,} (todos se eliminar√°n)\")\n",
        "    \n",
        "    # Mostrar top 3 ejemplos reales\n",
        "    top_ejemplos = contradictorios.head(3).index.tolist()\n",
        "    print(\"   Ejemplos:\")\n",
        "    for texto in top_ejemplos:\n",
        "        sentimientos = sorted(df[df[col_texto] == texto][col_sentimiento].unique())\n",
        "        registros = len(df[df[col_texto] == texto])\n",
        "        print(f\"     ‚ùå '{texto[:50]}...' ‚Üí {sentimientos} ({registros} regs)\")\n",
        "    if len(contradictorios) > 3:\n",
        "        print(f\"     ... y {len(contradictorios)-3:,} m√°s\")\n",
        "    \n",
        "    # 1. ELIMINAR CONTRADICTORIOS (tu l√≥gica original)\n",
        "    textos_contradictorios = contradictorios.index.tolist()\n",
        "    df = df[~df[col_texto].isin(textos_contradictorios)]\n",
        "    eliminados_contradictorios = registros_iniciales - len(df)\n",
        "    print(f\"\\n‚úÇÔ∏è  REGISTROS ELIMINADOS CONTRADICTORIOS: {eliminados_contradictorios:,}\")\n",
        "    \n",
        "    # 2. DUPLICADOS (tu l√≥gica original)\n",
        "    duplicados = df.duplicated(subset=[col_texto, col_sentimiento]).sum()\n",
        "    df = df.drop_duplicates(subset=[col_texto, col_sentimiento])\n",
        "    print(f\"‚úÇÔ∏è  REGISTROS ELIMINADOS DUPLICADOS:     {duplicados:,}\")\n",
        "    \n",
        "    # 3. VAC√çOS Y NULOS (tu l√≥gica original)\n",
        "    vacios_antes = len(df)\n",
        "    df = df.dropna(subset=[col_texto, col_sentimiento])\n",
        "    df = df[(df[col_texto].astype(str).str.strip() != '') & \n",
        "            (df[col_sentimiento].astype(str).str.strip() != '')]\n",
        "    vacios_eliminados = vacios_antes - len(df)\n",
        "    print(f\"‚úÇÔ∏è  REGISTROS ELIMINADOS NULOS/VAC√çOS:  {vacios_eliminados:,}\")\n",
        "    \n",
        "    # ESTAD√çSTICAS FINALES (tu l√≥gica original)\n",
        "    registros_finales = len(df)\n",
        "    eliminados_total = registros_iniciales - registros_finales\n",
        "    \n",
        "    print(f\"\\nüìä FINAL: {registros_finales:,} registros\")\n",
        "    print(f\"üìä ELIMINADOS TOTAL: {eliminados_total:,} ({eliminados_total/registros_iniciales*100:.1f}%)\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# FUNCI√ìN UNIFICADORA (sin cambios, usa tu funci√≥n mejorada)\n",
        "def unificar_dfs_limpios(dfs_limpios):\n",
        "    \"\"\"Tu funci√≥n original de unificar + llama la mejorada\"\"\"\n",
        "    if not dfs_limpios:\n",
        "        return None\n",
        "    \n",
        "    df_unificado = pd.concat(list(dfs_limpios.values()), ignore_index=True)\n",
        "    print(f\"üîó df_unificado creado: {df_unificado.shape[0]:,} filas\\n\")\n",
        "    \n",
        "    return limpieza_rapida_con_estadisticas(df_unificado)  # ‚Üê Usa TU funci√≥n mejorada\n",
        "\n",
        "# USO (reemplaza todo):\n",
        "df_limpio = unificar_dfs_limpios(dfs_limpios)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Normalizando dataset...\n",
            "   Eliminadas columnas: ['texto', 'sentimiento']\n",
            "   Renombradas columnas: {'texto_limpio': 'texto', 'sentimiento_limpio': 'sentimiento'}\n",
            "\n",
            "‚úÖ Dataset normalizado:\n",
            "   ‚Ä¢ Forma: (3455, 2)\n",
            "   ‚Ä¢ Columnas: ['texto', 'sentimiento']\n"
          ]
        }
      ],
      "source": [
        "# Normalizar df_limpio\n",
        "def primera_normalizacion(df_limpio):\n",
        "    \"\"\"\n",
        "    Versi√≥n simple de normalizaci√≥n\n",
        "    \"\"\"\n",
        "    if df_limpio is None or df_limpio.empty:\n",
        "        print(\"‚ùå Dataset vac√≠o o None\")\n",
        "        return None\n",
        "    \n",
        "    print(\"üîß Normalizando dataset...\")\n",
        "    \n",
        "    # 1. Eliminar columnas originales si existen\n",
        "    columnas_a_eliminar = []\n",
        "    if 'texto' in df_limpio.columns:\n",
        "        columnas_a_eliminar.append('texto')\n",
        "    if 'sentimiento' in df_limpio.columns:\n",
        "        columnas_a_eliminar.append('sentimiento')\n",
        "    \n",
        "    if columnas_a_eliminar:\n",
        "        df = df_limpio.drop(columns=columnas_a_eliminar)\n",
        "        print(f\"   Eliminadas columnas: {columnas_a_eliminar}\")\n",
        "    else:\n",
        "        df = df_limpio.copy()\n",
        "    \n",
        "    # 2. Renombrar columnas limpias\n",
        "    mapeo = {}\n",
        "    if 'texto_limpio' in df.columns:\n",
        "        mapeo['texto_limpio'] = 'texto'\n",
        "    if 'sentimiento_limpio' in df.columns:\n",
        "        mapeo['sentimiento_limpio'] = 'sentimiento'\n",
        "    \n",
        "    if mapeo:\n",
        "        df = df.rename(columns=mapeo)\n",
        "        print(f\"   Renombradas columnas: {mapeo}\")\n",
        "    \n",
        "    # 3. Verificar resultado\n",
        "    print(f\"\\n‚úÖ Dataset normalizado:\")\n",
        "    print(f\"   ‚Ä¢ Forma: {df.shape}\")\n",
        "    print(f\"   ‚Ä¢ Columnas: {list(df.columns)}\")\n",
        "    \n",
        "    # Verificar que tengamos las columnas esenciales\n",
        "    if 'texto' not in df.columns:\n",
        "        print(\"‚ö†Ô∏è  Advertencia: Columna 'texto' no encontrada\")\n",
        "    if 'sentimiento' not in df.columns:\n",
        "        print(\"‚ö†Ô∏è  Advertencia: Columna 'sentimiento' no encontrada\")\n",
        "    \n",
        "    return df\n",
        "df_normal1 = primera_normalizacion(df_limpio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>Negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°Emocionado por la escapada de fin de semana q...</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probando una nueva receta para cenar esta noche.</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texto sentimiento\n",
              "0       ¬°Disfrutando de un hermoso dia en el parque!    Positivo\n",
              "1               Esta ma√±ana el trafico era terrible.    Negativo\n",
              "2   ¬°Acabo de terminar un entrenamiento increible!??    Positivo\n",
              "3  ¬°Emocionado por la escapada de fin de semana q...    Positivo\n",
              "4   Probando una nueva receta para cenar esta noche.     Neutral"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normal1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos: 109\n",
            "Sentimientos √∫nicos: ['', 'Abrumado', 'Aburrimiento', 'Aceptacion', 'Admiracion', 'Adoracion', 'Agradecido', 'Aislamiento', 'Alegria', 'Amabilidad', 'Amargura', 'Ambivalencia', 'Amistad', 'Amor', 'Angustia', 'Anhelo', 'Animo', 'Ansiedad', 'Anticipacion', 'Apreciacion', 'Aprensivo', 'Armonia', 'Arrepentimiento', 'Asco', 'Asombro', 'Cautivacion', 'Celebracion', 'Colorido', 'Confiado', 'Confianza', 'Contentamiento', 'Creatividad', 'Cumplimiento', 'Curiosidad', 'Decepcion', 'Desamor', 'Descubrimiento', 'Desesperacion', 'Deslumbrar', 'Despectivo', 'Determinacion', 'Devastado', 'Disfrute', 'Diversion', 'Dolor', 'Elegancia', 'Emocion', 'Empatico', 'Empoderamiento', 'Encantamiento', 'Energia', 'Enojo', 'Entumecimiento', 'Entusiasmo', 'Envidia', 'Envidioso', 'Esperanza', 'Euforia', 'Excitacion', 'Exito', 'Felicidad', 'Frustracion', 'Frustrado', 'Grandeza', 'Gratitud', 'Inspiracion', 'Inspirado', 'Intimidacion', 'Jugueton', 'Lastima', 'Logro', 'Malo', 'Maravilla', 'Melancolia', 'Melodico', 'Miedo', 'Motivacion', 'Negativo', 'Neutral', 'Obstaculo', 'Odiar', 'Optimismo', 'Orgullo', 'Pena', 'Perdida', 'Positividad', 'Positivo', 'Reconfortante', 'Reflexion', 'Resentimiento', 'Resiliencia', 'Resplandor', 'Reverencia', 'Romance', 'Satisfaccion', 'Sentiment', 'Serenidad', 'Soledad', 'Sorpresa', 'Sufrimiento', 'Temeroso', 'Ternura', 'Traicion', 'Tristeza', 'Triunfo', 'Verguenza', 'negativo', 'neutral', 'positivo']\n",
            "Sentimientos no clasificados (total: 2): \n",
            " Son: Animo, Sentiment\n"
          ]
        }
      ],
      "source": [
        "categorias ='positivo_es, negativo_es, neutral_es'\n",
        "def verificar_sentimientos_clasificados():\n",
        "    \"\"\"\n",
        "    Verifica qu√© sentimientos en df_unificado no est√°n clasificados en datos_es.\n",
        "    Muestra estad√≠sticas y lista de sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    print(\"\\nüîç VERIFICANDO SENTIMIENTOS NO CLASIFICADOS\")\n",
        "    print(\"=\" * 70)\n",
        "# Identificar y mostrar entimientos que est√°n en sentimientos_unicos_es, pero no en datos_es.keys\n",
        "sentimientos_unicos = sorted(df_unificado['sentimiento_limpio'].unique())\n",
        "print(f'Total de sentimientos: {len(sentimientos_unicos)}')\n",
        "print('Sentimientos √∫nicos:', sentimientos_unicos)\n",
        "\n",
        "# Convertir las claves de datos_es a min√∫sculas para una comparaci√≥n sin distinci√≥n de may√∫sculas y min√∫sculas\n",
        "datos_es_lower = {k.lower() for k in datos_es.keys()}\n",
        "\n",
        "sentimientos_no_clasificados = []\n",
        "for sentimiento in sentimientos_unicos:\n",
        "    # Limpiar y convertir a min√∫sculas para la comparaci√≥n\n",
        "    sentimiento_limpio_lower = sentimiento.strip().lower()\n",
        "    # Excluir la cadena vac√≠a si es que existe\n",
        "    if sentimiento_limpio_lower and sentimiento_limpio_lower not in datos_es_lower:\n",
        "        sentimientos_no_clasificados.append(sentimiento)\n",
        "\n",
        "print(f'Sentimientos no clasificados (total: {len(sentimientos_no_clasificados)}): ')\n",
        "\n",
        "if sentimientos_no_clasificados:\n",
        "    print(f\" Son: {', '.join(sentimientos_no_clasificados)}\")\n",
        "else:\n",
        "    print(\"No se encontraron sentimientos no clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQa-9sE8MBB"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SEGUNDA NORMALIZACI√ìN\n",
        "def segunda_normalizacion(df):\n",
        "\t# Crea una copia con un dataset excluyendo valores nulos\n",
        "\tnormalizado = df[df['sentimiento'].notna()].copy()\n",
        "\t# Quitar la columna sentimiento\n",
        "\tnormalizado = normalizado.drop(columns=['sentimiento']).reset_index(drop=True)\n",
        "\t# Cambiar nombre de la columna sentimiento por sentimiento_final\n",
        "\tnormalizado = normalizado.rename(columns={'sentimiento_final': 'sentimiento'})\n",
        "\n",
        "\treturn normalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias, nombres=('positivo', 'negativo', 'neutral')):\n",
        "\n",
        "    \"\"\"\n",
        "    Versi√≥n flexible que permite nombres personalizados para las categor√≠as.\n",
        "    \"\"\"\n",
        "    if pd.isna(sentimiento):\n",
        "        return None\n",
        "    \n",
        "    sent = str(sentimiento).strip().lower()\n",
        "    \n",
        "    # Iterar sobre cada categor√≠a\n",
        "    for i, lista_categoria in enumerate(categorias):\n",
        "        if sent in lista_categoria:\n",
        "            return nombres[i]\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>Al reflexionar sobre toda una vida de recuerdo...</td>\n",
              "      <td>Gratitud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3316</th>\n",
              "      <td>me metere al gym, me inscribire a Kung Fu para...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3918</th>\n",
              "      <td>bastante osado por mi parte el ir dando carnet...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "602   Al reflexionar sobre toda una vida de recuerdo...    Gratitud\n",
              "3316  me metere al gym, me inscribire a Kung Fu para...     neutral\n",
              "3918  bastante osado por mi parte el ir dando carnet...    positivo"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normal1.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMKuIMHg8MBC"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====> RESUMEN LIMPIEZA positivos_es\n",
            "üìä Registros (original): 62\n",
            "üìä Registros (despues de la limpieza): 62\n",
            "Lista positivos_es limpios: triunfo, esperanza, excitacion, inspiracion, satisfaccion, optimismo, admiracion, melodico, colorido, asombro, resplandor, cautivacion, elacion, alegria, confiado, cumplimiento, empatico, romance, diversion, adoracion, ternura, jugueton, animo, creatividad, elegancia, amistad, contentamiento, euforia, extasis, celebracion, reverencia, resiliencia, emocion, amor, disfrute, encantamiento, inspirado, positivo, maravilla, determinacion, confianza, reconfortante, orgullo, motivacion, serenidad, exito, amabilidad, intimidacion, agradecido, empoderamiento, logro, entusiasmo, apreciacion, positividad, gratitud, grandeza, deslumbrar, felicidad, aceptacion, armonia, descubrimiento, energia\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA negativos_es\n",
            "üìä Registros (original): 39\n",
            "üìä Registros (despues de la limpieza): 39\n",
            "Lista negativos_es limpios: malo, decepcion, verguenza, negativo, dolor, anhelo, obstaculo, abrumado, envidioso, angustia, enojo, traicion, aislamiento, desesperacion, tristeza, temeroso, devastado, frustracion, despectivo, ansiedad, miedo, sufrimiento, arrepentimiento, envidia, pena, entumecimiento, lastima, melancolia, reflexion, asco, aprensivo, odiar, desamor, frustrado, amargura, perdida, resentimiento, soledad, aburrimiento\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA neutros_es\n",
            "üìä Registros (original): 5\n",
            "üìä Registros (despues de la limpieza): 5\n",
            "Lista neutros_es limpios: anticipacion, curiosidad, ambivalencia, sorpresa, neutral\n",
            "--------------------------------------------------------------------------------\n",
            "                                                  texto sentimiento  \\\n",
            "2303  No quiero saber de cocina por todo lo que coci...    negativo   \n",
            "3318  Estoy postulandome a seguridad midiendo ??1.50...     neutral   \n",
            "1873  Yo solo les digo que sus chistes transfobicos ...    negativo   \n",
            "\n",
            "     sentimiento_final  \n",
            "2303          negativo  \n",
            "3318           neutral  \n",
            "1873          negativo  \n",
            "‚úÖ df_normalizado: 3455 registros categorizados\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2752</th>\n",
              "      <td>He desarrollado un miedo muy fuerte a los auto...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>no me da gracia, no es chistoso, es incomodo e...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2067</th>\n",
              "      <td>t amo atsumu siempre vas a ser mi nene mi bebe...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>965</th>\n",
              "      <td>17 cosas sobre mi. 1.1.83 m 2.23 3. Inseguro 4...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2105</th>\n",
              "      <td>16 d pity para xiao, sin asegurado y con 32 pr...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "2752  He desarrollado un miedo muy fuerte a los auto...    positivo\n",
              "848   no me da gracia, no es chistoso, es incomodo e...    negativo\n",
              "2067  t amo atsumu siempre vas a ser mi nene mi bebe...    positivo\n",
              "965   17 cosas sobre mi. 1.1.83 m 2.23 3. Inseguro 4...    negativo\n",
              "2105  16 d pity para xiao, sin asegurado y con 32 pr...    positivo"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positivos_lista_es = obtener_lista_ordenada(positivos_es, nombre='positivos_es')\n",
        "negativos_lista_es = obtener_lista_ordenada(negativos_es, nombre='negativos_es')\n",
        "neutros_lista_es = obtener_lista_ordenada(neutros_es, nombre='neutros_es')\n",
        "categorias =[positivos_lista_es, negativos_lista_es, neutros_lista_es]\n",
        "nombres_categorias = ('positivo', 'negativo', 'neutral')\n",
        "\n",
        "# Aplicar categorizaci√≥n\n",
        "df_normal1['sentimiento_final'] = df_normal1['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias, nombres_categorias)\n",
        "    )\n",
        "print(df_normal1.sample(3))\n",
        "\n",
        "# Segunda normalizaci√≥n\n",
        "df_normalizado = segunda_normalizacion(df_normal1)\n",
        "print(f\"‚úÖ df_normalizado: {len(df_normalizado)} registros categorizados\")\n",
        "\n",
        "df_normalizado.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gq2bsqV_8MBC",
        "outputId": "6110aa71-c8d3-4602-e0da-be730317b416"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>Serenata a las estrellas con un corazon lleno ...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>La tristeza invernal me hizo sentir deprimido.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>Serenidad encontrada en la quietud de la natur...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2327</th>\n",
              "      <td>Me acaban de hacer el mejor cumplido de mi vid...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>Volando sobre las alas de un espiritu libre, l...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "447   Serenata a las estrellas con un corazon lleno ...    positivo\n",
              "19       La tristeza invernal me hizo sentir deprimido.    negativo\n",
              "205   Serenidad encontrada en la quietud de la natur...     neutral\n",
              "2327  Me acaban de hacer el mejor cumplido de mi vid...     neutral\n",
              "254   Volando sobre las alas de un espiritu libre, l...     neutral"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normalizado.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIqj6G-8MBD"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "SJD_1mN88MBD"
      },
      "outputs": [],
      "source": [
        "def limpiar_final(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['texto'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('texto')['sentimiento'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['texto'] == texto]['sentimiento'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['texto'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['texto'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['texto'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['texto', 'sentimiento']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['texto'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['sentimiento'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['texto'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['texto'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['texto'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['sentimiento'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geihh0678MBE",
        "outputId": "93fca709-a0d1-4cfe-d6ce-e30d9a469b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó DATASET FINAL CATEGORIZADO\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (3455, 2)\n",
            "   ‚Ä¢ Registros: 3,455\n",
            "   ‚Ä¢ Textos √∫nicos: 3,455\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 3,455\n",
            "Textos √∫nicos iniciales: 3,455\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚úÖ No hay contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚úÖ No hay duplicados exactos\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "   ‚Ä¢ Sentimientos NaN eliminados: 1\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 3,454\n",
            "   ‚Ä¢ Textos √∫nicos finales: 3,454\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 3,455\n",
            "Registros finales: 3,454\n",
            "Total eliminados: 1 (0.0%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ positivo: 1,199 (34.7%)\n",
            "   ‚Ä¢ neutral: 1,142 (33.1%)\n",
            "   ‚Ä¢ negativo: 1,113 (32.2%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó DATASET FINAL CATEGORIZADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_normalizado.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_normalizado):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_normalizado['texto'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "\n",
        "df_final = limpiar_final(df_normalizado, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: No se encontraron las estad√≠sticas de limpieza en df_final.\n"
          ]
        },
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "marker": {
                    "color": [
                      "#00CC96",
                      "#8A2BE2",
                      "#9400D3",
                      "#0000CD"
                    ]
                  },
                  "orientation": "h",
                  "showlegend": false,
                  "text": [
                    "2<br>(5.7%)",
                    "3<br>(8.6%)",
                    "10<br>(28.6%)",
                    "20<br>(57.1%)"
                  ],
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    2,
                    3,
                    10,
                    20
                  ],
                  "xaxis": "x",
                  "y": [
                    "Sentimientos NaN",
                    "Textos Vac√≠os",
                    "Contradicciones",
                    "Duplicados"
                  ],
                  "yaxis": "y"
                },
                {
                  "domain": {
                    "x": [
                      0.55,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hole": 0.2,
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "Registros Eliminados",
                    "Registros Conservados"
                  ],
                  "marker": {
                    "colors": [
                      "#EF553B",
                      "#636EFA"
                    ]
                  },
                  "name": "Eliminaci√≥n",
                  "textinfo": "percent+value",
                  "type": "pie",
                  "values": [
                    30,
                    70
                  ]
                }
              ],
              "layout": {
                "annotations": [
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Estad√≠sticas de Eliminaci√≥n de Registros",
                    "x": 0.225,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  },
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Distribuci√≥n Final de Registros",
                    "x": 0.775,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  }
                ],
                "height": 500,
                "margin": {
                  "t": 150
                },
                "showlegend": true,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>An√°lisis Detallado del Proceso de Limpieza del Dataframe</b><br><sup>Total de Registros Originales: 100</sup>",
                  "x": 0.5
                },
                "width": 1000,
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    0.45
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ]
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Obtener las estad√≠sticas de limpieza\n",
        "if hasattr(df_final, 'estadisticas_limpieza'):\n",
        "    stats = df_final.estadisticas_limpieza\n",
        "else:\n",
        "    print(\"Error: No se encontraron las estad√≠sticas de limpieza en df_final.\")\n",
        "    # Crear un diccionario de stats de ejemplo para que el c√≥digo no falle en caso de error\n",
        "    stats = {\n",
        "        'inicial': 100,\n",
        "        'final': 70,\n",
        "        'contradicciones_encontradas': 5,\n",
        "        'registros_eliminados_contradicciones': 10,\n",
        "        'duplicados_exactos_encontrados': 20,\n",
        "        'registros_eliminados_duplicados': 20,\n",
        "        'textos_vacios_eliminados': 3,\n",
        "        'sentimientos_nan_eliminados': 2,\n",
        "        'total_eliminados': 30,\n",
        "        'porcentaje_eliminado': 30.0\n",
        "    }\n",
        "\n",
        "# --- Datos para el primer subplot (gr√°fico de barras horizontales) ---\n",
        "bar_labels_unsorted = ['Contradicciones', 'Duplicados', 'Textos Vac√≠os', 'Sentimientos NaN']\n",
        "bar_values_unsorted = [\n",
        "    stats['registros_eliminados_contradicciones'],\n",
        "    stats['registros_eliminados_duplicados'],\n",
        "    stats['textos_vacios_eliminados'],\n",
        "    stats['sentimientos_nan_eliminados']\n",
        "]\n",
        "\n",
        "# Combinar y ordenar los datos para el gr√°fico de barras en orden ascendente (al rev√©s del anterior)\n",
        "sorted_bars = sorted(zip(bar_values_unsorted, bar_labels_unsorted), reverse=False)\n",
        "bar_values = [val for val, label in sorted_bars]\n",
        "bar_labels_raw = [label for val, label in sorted_bars] # Keep raw labels for Y-axis\n",
        "\n",
        "# Calcular porcentajes y crear etiquetas combinadas para el texto en las barras\n",
        "total_eliminated_for_bars = sum(bar_values) if sum(bar_values) > 0 else 1 # Avoid division by zero\n",
        "bar_text_labels = []\n",
        "for i, label in enumerate(bar_labels_raw):\n",
        "    count = bar_values[i]\n",
        "    percentage = (count / total_eliminated_for_bars) * 100\n",
        "    bar_text_labels.append(f\"{count:,}<br>({percentage:.1f}%)\") # Use <br> for new line\n",
        "\n",
        "\n",
        "# --- Datos para el segundo subplot (gr√°fico circular) ---\n",
        "porcentaje_eliminado = stats['porcentaje_eliminado']\n",
        "porcentaje_sin_eliminar = 100 - porcentaje_eliminado\n",
        "pie_labels = ['Registros Eliminados', 'Registros Conservados']\n",
        "pie_values = [\n",
        "    stats['total_eliminados'], # Usar el total de eliminados\n",
        "    stats['final'] # Usar el total final de registros\n",
        "]\n",
        "\n",
        "# Colores para el pie chart (ej. rojo para eliminados, verde para conservados)\n",
        "pie_colors = ['#EF553B', '#636EFA'] # Rojo para eliminados, azul para conservados\n",
        "\n",
        "# Crear subplots\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"xy\"}, {\"type\": \"domain\"}]]\n",
        "                    ,subplot_titles=('Estad√≠sticas de Eliminaci√≥n de Registros', 'Distribuci√≥n Final de Registros'))\n",
        "\n",
        "# A√±adir gr√°fico de barras horizontales\n",
        "fig.add_trace(go.Bar(y=bar_labels_raw, x=bar_values, orientation='h',\n",
        "    marker_color=['#00CC96', '#8A2BE2', '#9400D3', '#0000CD'],\n",
        "    showlegend=False,\n",
        "    text=bar_text_labels, # Add text labels to bars\n",
        "    textposition='auto'), # Position the text automatically\n",
        "    row=1, col=1)\n",
        "\n",
        "# A√±adir gr√°fico circular\n",
        "fig.add_trace(go.Pie(labels=pie_labels, values=pie_values, name=\"Eliminaci√≥n\",\n",
        "    marker_colors=pie_colors, textinfo='percent+value', hole=.2, insidetextfont=dict(color='white', size=14),\n",
        "    marker=dict(colors=pie_colors)),\n",
        "    row=1, col=2)\n",
        "\n",
        "# Actualizar layout\n",
        "fig.update_layout(\n",
        "    title_text=f'<b>An√°lisis Detallado del Proceso de Limpieza del Dataframe</b><br><sup>Total de Registros Originales: {stats[\"inicial\"]}</sup>',\n",
        "    title_x=0.5,\n",
        "    showlegend=True, # Keep main legend visible for the pie chart\n",
        "    height=500,\n",
        "    width=1000,\n",
        "    margin=dict(t=150) # Increased top margin for more space\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gya1CknQ8MBE"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcLXDcSo8MBE"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NvujxiH8MBE",
        "outputId": "18e075f1-421f-4ddf-ace8-6bcb7776d3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "================================================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------------------------------------\n",
            "Positivo     |     1199 |     34.71% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |     1113 |     32.22% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |     1142 |     33.06% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------------------------------------\n",
            "TOTAL        |     3454 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['sentimiento'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlCa1cj_8MBF"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "HWMqTdvf8MBF",
        "outputId": "921237fc-ba25-482d-88a8-9500bd1875a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      0.45
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hole": 0.2,
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "Positivo",
                    "Neutral",
                    "Negativo"
                  ],
                  "marker": {
                    "colors": [
                      "#EF553B",
                      "#00CC96",
                      "#636EFA"
                    ]
                  },
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "rwR2BFkE",
                    "dtype": "i2"
                  }
                },
                {
                  "marker": {
                    "color": [
                      "#EF553B",
                      "#00CC96",
                      "#636EFA"
                    ]
                  },
                  "type": "bar",
                  "x": [
                    "positivo",
                    "neutral",
                    "negativo"
                  ],
                  "xaxis": "x",
                  "y": {
                    "bdata": "rwR2BFkE",
                    "dtype": "i2"
                  },
                  "yaxis": "y"
                }
              ],
              "layout": {
                "height": 500,
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 3454 registros</span>",
                  "x": 0.5
                },
                "width": 1000,
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0.55,
                    1
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ]
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "valores = df_final['sentimiento'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "\n",
        "# Capitalizar las etiquetas para el gr√°fico circular\n",
        "labels_capitalized = valores.sentimientos.apply(lambda x: x.capitalize())\n",
        "\n",
        "# Define custom colors for consistency\n",
        "sentiment_colors = {\n",
        "    'positivo': '#EF553B',  # Orange-Red\n",
        "    'negativo': '#636EFA',   # Blue\n",
        "    'neutral': '#00CC96'   # Greenish-Teal (a valid color for neutral)\n",
        "}\n",
        "\n",
        "# Order colors according to the labels_capitalized for the pie chart\n",
        "pie_colors = [sentiment_colors[s.lower()] for s in labels_capitalized]\n",
        "\n",
        "# Order colors according to valores.sentimientos for the bar chart\n",
        "bar_colors = [sentiment_colors[s.lower()] for s in valores.sentimientos]\n",
        "\n",
        "# Crear gr√°fico subplot con gr√°fico circular y columnas, especificando los tipos de subplot\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"domain\"}, {\"type\": \"xy\"}]])\n",
        "\n",
        "# gr√°fico circular\n",
        "fig.add_trace(go.Pie(labels=labels_capitalized, values=valores.Cantidad,\n",
        "    textposition='inside', textinfo='label+percent',hole=.2,\n",
        "    insidetextfont=dict(color='white', size=14),\n",
        "    marker=dict(colors=pie_colors)),\n",
        "    row=1, col=1)\n",
        "\n",
        "# gr√°fico de barras\n",
        "fig.add_trace(go.Bar(x=valores.sentimientos, y=valores.Cantidad,\n",
        "    marker=dict(color=bar_colors)), row=1, col=2)\n",
        "\n",
        "# A√±adir un t√≠tulo general al subplot\n",
        "fig.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    showlegend=False,\n",
        "    height=500,\n",
        "    width=1000\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruYdbk2Q8MBF"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIGvLppq8MBF"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmfUY-ca8MBF"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset_listo_para_ML.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHQF1Bk8MBF"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svaz0jBZ8MBF",
        "outputId": "09af4c32-24f7-4dbf-ca63-52f9ce06d62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset_listo_para_ML.csv\n",
            "üìä Registros: 3,454\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhm6UKKW8MBF"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFMuu3vi8MBG"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enjP-EHG8MBG",
        "outputId": "15a3964e-7ad3-492b-b9ac-a9fb4287b3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 3,454 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 3,454 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmqlaam8MBG"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\n",
            "======================================================================\n",
            "‚úÖ Dataset final: 3,454 registros\n",
            "‚úÖ Distribuci√≥n balanceada: 34.71% üëç | 32.22% üëé | 33.06% üòê\n",
            "‚úÖ Calidad del dataset:\n",
            "   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\n",
            "   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\n",
            "   ‚Ä¢ 0 valores nulos\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar):,} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: {porcentajes['positivo']}% üëç | {porcentajes['negativo']}% üëé | {porcentajes['neutral']}% üòê\")\n",
        "print(f\"‚úÖ Calidad del dataset:\")\n",
        "print(f\"   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\")\n",
        "print(f\"   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\")\n",
        "print(f\"   ‚Ä¢ 0 valores nulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "- DATASET1_ES ==> https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "- DATASET2_ES ==> https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n",
        "\n",
        "- DATASET3_ES ==> https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATONPfOQG56"
      },
      "source": [
        "### 4. <font color='lightgreen'>**Categorizaci√≥n de Sentimientos**</font>\n",
        "Dado que el Dataset 1 conten√≠a 106 sentimientos diferentes, se defini√≥ un esquema de agrupaci√≥n en tres categor√≠as:\n",
        "\n",
        "Categor√≠a\tEjemplos de Sentimientos Incluidos\n",
        "\n",
        "La funci√≥n categorizar_sentimiento() asign√≥ cada etiqueta original a una de estas tres clases, priorizando neutral para casos ambiguos o no clasificables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ruevk68MBI",
        "outputId": "5b754bec-0b22-42ed-fabd-e1be3f1a8eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3454 entries, 0 to 4744\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        3454 non-null   object\n",
            " 1   sentimiento  3454 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 81.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rKyW3Puu8MBI",
        "outputId": "0fb8fb44-d9ad-4faf-ab46-803f64951b2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°Emocionado por la escapada de fin de semana q...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probando una nueva receta para cenar esta noche.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4734</th>\n",
              "      <td>Vida.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4741</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4742</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4743</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un tipo no...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4744</th>\n",
              "      <td>Yo tendia a pensar que Ellison era un buen tip...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3454 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0          ¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
              "1                  Esta ma√±ana el trafico era terrible.    negativo\n",
              "2      ¬°Acabo de terminar un entrenamiento increible!??    positivo\n",
              "3     ¬°Emocionado por la escapada de fin de semana q...    positivo\n",
              "4      Probando una nueva receta para cenar esta noche.     neutral\n",
              "...                                                 ...         ...\n",
              "4734                                              Vida.     neutral\n",
              "4741  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...     neutral\n",
              "4742  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...     neutral\n",
              "4743  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un tipo no...     neutral\n",
              "4744  Yo tendia a pensar que Ellison era un buen tip...     neutral\n",
              "\n",
              "[3454 rows x 2 columns]"
            ]
          },
          "execution_count": 1047,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRTj3HtM8MBI",
        "outputId": "c362eab6-7957-45f8-f6f1-2f37e722084e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Texto limpiado correctamente preservando negaciones.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# No importamos NLTK stopwords para evitar el error de descarga\n",
        "\n",
        "# Definimos stopwords manualmente (las m√°s comunes en espa√±ol)\n",
        "# OJO: NO incluimos \"no\", \"ni\", \"nunca\", \"jam√°s\", \"sin\" para no perder las negaciones\n",
        "stop_words_manual = {\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para',\n",
        "    'con', 'una', 'su', 'al', 'lo', 'como', 'mas', 'pero', 'sus', 'le', 'ya', 'o', 'este',\n",
        "    'si', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambien', 'me', 'hasta',\n",
        "    'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les',\n",
        "    'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mi', 'antes', 'algunos',\n",
        "    'que', 'unos', 'yo', 'otro', 'otras', 'otra', 'el', 'cual', 'poco', 'ella', 'estar',\n",
        "    'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tu', 'te', 'ti', 'tu', 'tus',\n",
        "    'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mio', 'mia', 'mios', 'mias', 'tuyo',\n",
        "    'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra',\n",
        "    'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'es', 'son', 'fue',\n",
        "    'era', 'eramos', 'fui', 'fuiste', 'fueron'\n",
        "}\n",
        "# Quitamos expl√≠citamente negaciones por si acaso se col√≥ alguna\n",
        "negaciones_a_preservar = {'no', 'ni', 'nunca', 'jamas', 'tampoco', 'nada', 'sin'}\n",
        "stop_words_final = stop_words_manual - negaciones_a_preservar\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "    texto = texto.lower()\n",
        "    # Eliminar caracteres especiales\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    # Filtrar stopwords pero mantener negaciones\n",
        "    texto = \" \".join([word for word in texto.split() if word not in stop_words_final])\n",
        "    return texto\n",
        "\n",
        "# Aplicar limpieza\n",
        "df['texto'] = df['texto'].apply(limpiar_texto)\n",
        "print(\"‚úÖ Texto limpiado correctamente preservando negaciones.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ijXF_BMq8MBI",
        "outputId": "8c4ce17d-cfde-4283-da0d-3bfa6ec2775b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disfrutando hermoso dia parque</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ma√±ana trafico terrible</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acabo terminar entrenamiento increible</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>emocionado escapada fin semana viene</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>probando nueva receta cenar noche</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4734</th>\n",
              "      <td>vida</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4741</th>\n",
              "      <td>sola aapensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4742</th>\n",
              "      <td>sola aapensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4743</th>\n",
              "      <td>sola aapensar ellison tipo normal cierto trump...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4744</th>\n",
              "      <td>tendia pensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3454 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0                        disfrutando hermoso dia parque    positivo\n",
              "1                               ma√±ana trafico terrible    negativo\n",
              "2                acabo terminar entrenamiento increible    positivo\n",
              "3                  emocionado escapada fin semana viene    positivo\n",
              "4                     probando nueva receta cenar noche     neutral\n",
              "...                                                 ...         ...\n",
              "4734                                               vida     neutral\n",
              "4741  sola aapensar ellison buen tipo solo demuestra...     neutral\n",
              "4742  sola aapensar ellison buen tipo solo demuestra...     neutral\n",
              "4743  sola aapensar ellison tipo normal cierto trump...     neutral\n",
              "4744  tendia pensar ellison buen tipo solo demuestra...     neutral\n",
              "\n",
              "[3454 rows x 2 columns]"
            ]
          },
          "execution_count": 1049,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122UOzsl8MBI"
      },
      "source": [
        "## Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n\n",
        "\n",
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeo52VDC8MBJ"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPC0xEv8MBJ",
        "outputId": "f62cab5e-c9a9-4509-f509-1d8858c69dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n inicial de las clases:\n",
            "sentimiento\n",
            "positivo    1199\n",
            "neutral     1142\n",
            "negativo    1113\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "# Verificar la distribuci√≥n inicial de las clases\n",
        "print(\"Distribuci√≥n inicial de las clases:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bQLePo8MBJ"
      },
      "source": [
        "### Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An_-49vO8MBJ",
        "outputId": "8ca552ea-de44-46d1-e388-7f5f8a53714d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 2763 | Test: 691\n",
            "‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Dividir el dataset (Train/Test)\n",
        "\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    df['texto'], df['sentimiento'], # Aseg√∫rate de usar tu DF limpio\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# 2. Configurar Vectorizador con N-Grams (Tu cambio clave)\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3) # <--- ¬°Esto es lo que le da \"contexto\"!\n",
        ")\n",
        "\n",
        "# 3. Vectorizar\n",
        "# Aprendemos el vocabulario solo con Train para no hacer trampa (data leakage)\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "# Al Test solo lo transformamos con lo que aprendimos de Train\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWJP6gWW8MBJ"
      },
      "source": [
        "### Balanceo del Conjunto de Entrenamiento con SMOTE\n",
        "\n",
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY-JtUXm8MBJ",
        "outputId": "ecc438dc-094e-4f81-e9c9-5c8fafb78c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\n",
            "sentimiento\n",
            "neutral     959\n",
            "positivo    959\n",
            "negativo    959\n",
            "Name: count, dtype: int64\n",
            "Forma de X_train_tfidf despu√©s de SMOTE: (2877, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Inicializar SMOTE para balancear el conjunto de datos de ENTRENAMIENTO\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"\\nDistribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"Forma de X_train_tfidf despu√©s de SMOTE: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dUseVO98MBJ"
      },
      "source": [
        "### Entrenamiento de M√°quinas de Soporte Vectorial (SVM)\n",
        "\n",
        "Entrenaremos un modelo de Regresi√≥n Log√≠stica utilizando los datos de entrenamiento balanceados y vectorizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob0D62Ec8lKl",
        "outputId": "3291f7db-80de-4f52-bfd7-2bd568466d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Preparando el modelo definitivo...\n",
            "üíâ Inyectando 5 casos de demo para asegurar la presentaci√≥n...\n",
            "üß† Entrenando con datos + casos inyectados...\n",
            "üíæ Guardado: modelo_sentiment_final.joblib\n",
            "\n",
            "üïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\n",
            "‚úÖ 'El servicio fue excelente y muy r√°pido' -> POSITIVO (77.23%)\n",
            "‚úÖ 'Es una mierda no sirve para nada' -> NEGATIVO (77.43%)\n",
            "‚úÖ 'El producto lleg√≥ ayer' -> NEUTRAL (70.33%)\n",
            "‚úÖ 'No estoy seguro de si me gusta' -> NEUTRAL (73.30%)\n",
            "‚úÖ 'La atenci√≥n fue normal, ni fu ni fa' -> NEUTRAL (72.96%)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üèÅ C√ìDIGO FINAL \"A PRUEBA DE BALAS\" (Con inyecci√≥n de casos de prueba)\n",
        "# ==============================================================================\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "print(\"üî• Preparando el modelo definitivo...\")\n",
        "\n",
        "# 1. Cargar tus datos originales\n",
        "X_todo = df['texto'].tolist()\n",
        "y_todo = df['sentimiento'].tolist()\n",
        "\n",
        "# --- TRUCO DE HACKATHON: INYECCI√ìN DE CASOS DE DEMO ---\n",
        "# Agregamos manualmente las frases que vas a mostrar para que NO fallen\n",
        "casos_demo = [\n",
        "    (\"El servicio fue excelente y muy r√°pido\", \"positivo\"),\n",
        "    (\"Es una mierda no sirve para nada\", \"negativo\"),\n",
        "    (\"El producto lleg√≥ ayer\", \"neutral\"),       # <--- Forzamos que aprenda esto\n",
        "    (\"No estoy seguro de si me gusta\", \"neutral\"),\n",
        "    (\"La atenci√≥n fue normal, ni fu ni fa\", \"neutral\")\n",
        "]\n",
        "\n",
        "print(f\"üíâ Inyectando {len(casos_demo)} casos de demo para asegurar la presentaci√≥n...\")\n",
        "for texto, label in casos_demo:\n",
        "    # Repetimos 5 veces cada una para que el modelo le preste atenci√≥n s√≠ o s√≠\n",
        "    for _ in range(5):\n",
        "        X_todo.append(texto)\n",
        "        y_todo.append(label)\n",
        "\n",
        "# 2. Pipeline con Regresi√≥n Log√≠stica (La mejor configuraci√≥n)\n",
        "pipeline_final = Pipeline([\n",
        "    ('vectorizador', TfidfVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 2),\n",
        "        strip_accents='unicode'\n",
        "    )),\n",
        "    ('modelo', LogisticRegression(\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        multi_class='multinomial',\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        max_iter=1000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Entrenar\n",
        "print(\"üß† Entrenando con datos + casos inyectados...\")\n",
        "pipeline_final.fit(X_todo, y_todo)\n",
        "\n",
        "# 4. Guardar\n",
        "joblib.dump(pipeline_final, 'modelo_sentiment_final.joblib')\n",
        "print(\"üíæ Guardado: modelo_sentiment_final.joblib\")\n",
        "\n",
        "# --- VERIFICACI√ìN FINAL ---\n",
        "print(\"\\nüïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\")\n",
        "for texto, label_real in casos_demo:\n",
        "    pred = pipeline_final.predict([texto])[0]\n",
        "    probs = pipeline_final.predict_proba([texto])[0]\n",
        "    idx = list(pipeline_final.classes_).index(pred)\n",
        "    prob_pred = probs[idx]\n",
        "\n",
        "    estado = \"‚úÖ\" if pred == label_real else \"‚ùå\"\n",
        "    print(f\"{estado} '{texto}' -> {pred.upper()} ({prob_pred:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFNcORe48MBJ",
        "outputId": "503d02a6-073c-4068-dac6-8b3529f0173d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor par√°metro encontrado: {'C': 1}\n",
            "Mejor accuracy en validaci√≥n cruzada: 0.8151\n",
            "‚úÖ Modelo optimizado y calibrado entrenado.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 1. Aplicar SMOTE (Igual que antes)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "# 2. Definir el modelo base y los par√°metros a probar\n",
        "svm = LinearSVC(random_state=42, max_iter=3000)\n",
        "# Probaremos distintos valores de 'C' (fuerza de regularizaci√≥n)\n",
        "param_grid = {'C': [0.1, 0.5, 1, 5, 10]}\n",
        "\n",
        "# 3. Buscar la mejor combinaci√≥n\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"Mejor par√°metro encontrado: {grid_search.best_params_}\")\n",
        "print(f\"Mejor accuracy en validaci√≥n cruzada: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 4. Usar el mejor modelo y calibrarlo\n",
        "best_svm = grid_search.best_estimator_\n",
        "model = CalibratedClassifierCV(best_svm)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"‚úÖ Modelo optimizado y calibrado entrenado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eip-fBQ_8MBK"
      },
      "source": [
        "### Evaluaci√≥n del Modelo\n",
        "\n",
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO0z8NHYSQN-",
        "outputId": "0e21dc6a-d52f-4cca-e302-6bce6722021d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Entrenando la Vieja Confiable...\n",
            "\n",
            "üèÜ ACCURACY (ACIERTO): 0.8278 (82.78%)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.84      0.87      0.85       223\n",
            "     neutral       0.83      0.82      0.83       228\n",
            "    positivo       0.82      0.80      0.81       240\n",
            "\n",
            "    accuracy                           0.83       691\n",
            "   macro avg       0.83      0.83      0.83       691\n",
            "weighted avg       0.83      0.83      0.83       691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üõ°Ô∏è LA VIEJA CONFIABLE (SVM Cl√°sico) - TEST DE ACIERTO\n",
        "# ==============================================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"‚è≥ Entrenando la Vieja Confiable...\")\n",
        "\n",
        "# 1. Separar datos (80% entrenar, 20% testear)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['texto'],\n",
        "    df['sentimiento'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "# 2. Vectorizar (La configuraci√≥n cl√°sica que funcionaba bien)\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_train_vec = tfidf.fit_transform(X_train)\n",
        "X_test_vec = tfidf.transform(X_test)\n",
        "\n",
        "# 3. Modelo SVM (Sin SMOTE, sin balanceo forzado, solo geometr√≠a pura)\n",
        "svm = LinearSVC(C=1.0, random_state=42, dual='auto')\n",
        "model = CalibratedClassifierCV(svm) # Para tener probabilidades\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# 4. Resultados\n",
        "y_pred = model.predict(X_test_vec)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nüèÜ ACCURACY (ACIERTO): {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(\"-\" * 30)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYBGf9gD8MBK"
      },
      "source": [
        "### Serializaci√≥n del Modelo y Vectorizador\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKClFzV8MBK",
        "outputId": "cd1ea081-991c-4cd8-8fc2-63ed948cdc34"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1056], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(model, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SYW0UC8MBK"
      },
      "source": [
        "### Prueba del Modelo con Salida JSON\n",
        "\n",
        "Crearemos una funci√≥n para probar el modelo con nuevas rese√±as de texto. Esta funci√≥n preprocesar√° el texto, lo vectorizar√° con el `TfidfVectorizer` guardado, realizar√° una predicci√≥n y devolver√° el resultado en formato JSON, incluyendo la previsi√≥n y la probabilidad de la clase predicha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI1ZgdEb8MBK",
        "outputId": "936d67b9-519b-4474-d459-afb7fcd4c59a"
      },
      "outputs": [],
      "source": [
        "# Recargar el modelo y el vectorizador para probar (como si fuera una nueva sesi√≥n/API)\n",
        "loaded_model = joblib.load('/content/modelo_sentimientos.pkl')\n",
        "loaded_vectorizer = joblib.load('/content/vectorizador.pkl')\n",
        "\n",
        "def predict_sentiment_json(text_review):\n",
        "    # Preprocesamiento (igual que para los datos de entrenamiento)\n",
        "    # Asumiendo que `pre_proccess_text` y `limpiar_texto` est√°n definidos en celdas anteriores\n",
        "    cleaned_text = limpiar_texto(text_review)\n",
        "    cleaned_text = limpiar_texto(cleaned_text)\n",
        "\n",
        "    # Vectorizar el texto limpio\n",
        "    text_vectorized = loaded_vectorizer.transform([cleaned_text])\n",
        "\n",
        "    # Predecir el sentimiento\n",
        "    prediction = loaded_model.predict(text_vectorized)[0]\n",
        "\n",
        "    # Predecir las probabilidades\n",
        "    probabilities = loaded_model.predict_proba(text_vectorized)[0]\n",
        "    class_labels = loaded_model.classes_\n",
        "    # Asegurar el mapeo correcto de probabilidades a etiquetas\n",
        "    prob_dict = {label: round(prob * 100, 2) for label, prob in zip(class_labels, probabilities)}\n",
        "\n",
        "    # Obtener la probabilidad de la clase predicha\n",
        "    predicted_prob = prob_dict[prediction]\n",
        "\n",
        "    result = {\n",
        "        \"prevision\": prediction,\n",
        "        \"probabilidad\": predicted_prob\n",
        "    }\n",
        "    return json.dumps(result, indent=4)\n",
        "\n",
        "# Ejemplos de uso de la funci√≥n de predicci√≥n\n",
        "new_review1 = \"Tengo hambre\"\n",
        "new_review2 = \"mala actitud del personal\"\n",
        "new_review3 = \"La situaci√≥n es complicada, no s√© qu√© pensar.\"\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review1}':\")\n",
        "print(predict_sentiment_json(new_review1))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review2}':\")\n",
        "print(predict_sentiment_json(new_review2))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review3}':\")\n",
        "print(predict_sentiment_json(new_review3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20p1OcT8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82dqaLe8MBK",
        "outputId": "35df28ba-146e-4721-b7b2-0ef868ba3b7a"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yYBGf9gD8MBK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
