{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>**Sentiment API**<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "## <font size=6 color=#00FFFF>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "* **`plotly.express`**\n",
        "    * Permite la creaci√≥n de gr√°ficos interactivos y din√°micos.\n",
        "    * Utilizado para generar gr√°ficos de pastel (pie charts) que permiten explorar la distribuci√≥n de sentimientos de forma interactiva.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "* **`unicodedata`**\n",
        "    * Facilita la normalizaci√≥n de caracteres Unicode.\n",
        "    * Crucial para eliminar tildes y diacr√≠ticos manteniendo la integridad de letras como la \"√±\".\n",
        "* **`nltk`**\n",
        "    * Toolkit esencial para el procesamiento de lenguaje natural.\n",
        "    * Proporciona recursos l√©xicos y herramientas para el filtrado de palabras irrelevantes (stopwords).\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`LinearSVC`**: Implementaci√≥n de SVM para clasificaci√≥n lineal, optimizada para grandes vol√∫menes de texto.\n",
        "    * **`CalibratedClassifierCV`**: Calibra las predicciones para obtener probabilidades de confianza (0-100%).\n",
        "    * **`GridSearchCV`**: Optimizaci√≥n autom√°tica de hiperpar√°metros mediante b√∫squeda en malla.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "* **`imblearn (SMOTE)`**\n",
        "    * T√©cnica de sobremuestreo sint√©tico para balancear las clases del dataset.\n",
        "    * Ayuda a que el modelo no se sesgue hacia la clase m√°s frecuente, mejorando la detecci√≥n de minor√≠as.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`chardet`**\n",
        "    * Detecci√≥n autom√°tica de la codificaci√≥n de archivos (encoding).\n",
        "* **`urllib.request`** & **`json`**\n",
        "    * Utilidades para realizar peticiones HTTP y procesar datos en formato JSON desde fuentes externas como GitHub.\n",
        "* **`pathlib`** & **`os`**\n",
        "    * Gesti√≥n de rutas de archivos y directorios de forma independiente al sistema operativo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "# Procesamiento y manipulaci√≥n\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Visualizaci√≥n y analisis exploratorio\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from _plotly_utils.basevalidators import SubplotidValidator\n",
        "from pathlib import Path\n",
        "import urllib.response\n",
        "import urllib.request\n",
        "from datetime import datetime\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import unicodedata\n",
        "from io import StringIO\n",
        "import uvicorn\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import os\n",
        "import warnings\n",
        "import json\n",
        "from urllib.error import URLError, HTTPError\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# 1. Crear contador global al principio\n",
        "CONTADOR_GLOBAL = {\n",
        "    'contradicciones': 0,\n",
        "    'duplicados': 0,\n",
        "    'vacios_nulos': 0,\n",
        "    'sentimientos_nan': 0,\n",
        "    'total_eliminados' : 0\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crrSq9UG35NE"
      },
      "source": [
        "## <font size=12 color=#00FFFF> Extracci√≥n, Transformaci√≥n y Limpieza</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i93KZduPGFWZ"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de diccionario<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "CARGANDO DICCIONARIO DE SENTIMIENTOS\n",
            "============================================================\n",
            "üì• Cargando diccionario desde: https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/feature/data-science-marely/data-science/sources/diccionarios/sentimientos_mapeo.json\n",
            "‚úÖ JSON cargado: 104 sentimientos\n",
            "üìä Distribuci√≥n:\n",
            "   ‚Ä¢ Positivos: 60\n",
            "   ‚Ä¢ Negativos: 39\n",
            "   ‚Ä¢ Neutros: 5\n",
            "\n",
            "============================================================\n",
            "‚úÖ VARIABLES CREADAS Y DISPONIBLES:\n",
            "============================================================\n",
            "‚Ä¢ 'datos_es' (diccionario completo): 104 elementos\n",
            "‚Ä¢ 'positivos_es' (lista): 60 elementos\n",
            "‚Ä¢ 'negativos_es' (lista): 39 elementos\n",
            "‚Ä¢ 'neutros_es' (lista): 5 elementos\n",
            "\n",
            "üîç Ejemplo de positivos: ['aceptacion', 'admiracion', 'adoracion']\n",
            "üîç Ejemplo de negativos: ['abrumado', 'aburrimiento', 'aislamiento']\n",
            "üîç Ejemplo de neutros: ['ambivalencia', 'anticipacion', 'curiosidad']\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# üéØ CARGAR DICIONARIO DE SENTIMIENTOS (VERSI√ìN CORREGIDA)\n",
        "# ==========================================================\n",
        "\n",
        "import json\n",
        "import urllib.request\n",
        "from urllib.error import URLError, HTTPError\n",
        "\n",
        "def cargar_diccionario_completo():\n",
        "    \"\"\"\n",
        "    Carga el diccionario de sentimientos y retorna TODAS las variables necesarias.\n",
        "    \"\"\"\n",
        "    # URL corregida (raw de GitHub)\n",
        "    url = \"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/feature/data-science-marely/data-science/sources/diccionarios/sentimientos_mapeo.json\"\n",
        "    \n",
        "    print(f\"üì• Cargando diccionario desde: {url}\")\n",
        "    \n",
        "    try:\n",
        "        # 1. Descargar\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "        \n",
        "        # 2. Decodificar y cargar JSON\n",
        "        datos = json.loads(content.decode('utf-8'))\n",
        "        print(f\"‚úÖ JSON cargado: {len(datos)} sentimientos\")\n",
        "        \n",
        "        # 3. Crear listas de categor√≠as\n",
        "        positivos_es = [k for k, v in datos.items() if v == 'positivo']\n",
        "        negativos_es = [k for k, v in datos.items() if v == 'negativo']\n",
        "        neutros_es = [k for k, v in datos.items() if v == 'neutral']\n",
        "\n",
        "        print(f\"üìä Distribuci√≥n:\")\n",
        "        print(f\"   ‚Ä¢ Positivos: {len(positivos_es)}\")\n",
        "        print(f\"   ‚Ä¢ Negativos: {len(negativos_es)}\")\n",
        "        print(f\"   ‚Ä¢ Neutros: {len(neutros_es)}\")\n",
        "        \n",
        "        # 4. Retornar todas las variables en un diccionario\n",
        "        return {\n",
        "            'datos': datos,\n",
        "            'positivos': positivos_es,\n",
        "            'negativos': negativos_es,\n",
        "            'neutros': neutros_es\n",
        "        }\n",
        "        \n",
        "    except HTTPError as e:\n",
        "        print(f\"‚ùå Error HTTP {e.code}: {e.reason}\")\n",
        "    except URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e.reason}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"‚ùå Error en JSON: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "\n",
        "   # Retornar diccionario vac√≠o en caso de error\n",
        "    return {\n",
        "        'datos': {},\n",
        "        'positivos': [],\n",
        "        'negativos': [],\n",
        "        'neutros': []\n",
        "    }\n",
        "\n",
        "# ==================== EJECUCI√ìN ====================\n",
        "print(\"=\" * 60)\n",
        "print(\"CARGANDO DICCIONARIO DE SENTIMIENTOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cargar y obtener todas las variables\n",
        "diccionario_data = cargar_diccionario_completo()\n",
        "\n",
        "# Extraer las variables individuales\n",
        "datos_es = diccionario_data['datos']\n",
        "positivos_es = diccionario_data['positivos']\n",
        "negativos_es = diccionario_data['negativos']\n",
        "neutros_es = diccionario_data['neutros']\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ VARIABLES CREADAS Y DISPONIBLES:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚Ä¢ 'datos_es' (diccionario completo): {len(datos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'positivos_es' (lista): {len(positivos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'negativos_es' (lista): {len(negativos_es)} elementos\")\n",
        "print(f\"‚Ä¢ 'neutros_es' (lista): {len(neutros_es)} elementos\")\n",
        "\n",
        "# Mostrar ejemplos\n",
        "if positivos_es:\n",
        "    print(f\"\\nüîç Ejemplo de positivos: {positivos_es[:3]}\")\n",
        "if negativos_es:\n",
        "    print(f\"üîç Ejemplo de negativos: {negativos_es[:3]}\")\n",
        "if neutros_es:\n",
        "    print(f\"üîç Ejemplo de neutros: {neutros_es[:3]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "#============================================================================\n",
        "#FUNCI√ìN AUXILIAR - PROCESAR DICCIONARIO Y NOMBRES DE VARIABLES\n",
        "# ============================================================================\n",
        "def procesar_dic(dict, funcion_proceso, sufijo=''):\n",
        "    \"\"\"\n",
        "    Procesa todos los elementos de un diccionario seg√∫n su idioma\n",
        "    Funci√≥n auxiliar para iteraci√≥n de diccionarios y creaci√≥n de nombres actualizados.\n",
        "    Args:\n",
        "        dict: Diccionario {nombre_df: dataframe}\n",
        "        funcion_proceso: Funci√≥n que procesa un dataframe\n",
        "        sufijo: Sufijo para el nuevo nombre\n",
        "\n",
        "    Returns:\n",
        "        Nuevo diccionario con nombres actualizados\n",
        "    \"\"\"\n",
        "    nuevo_dict = {}\n",
        "\n",
        "    for nombre, item in dict.items():\n",
        "        # Extraer partes del nombre\n",
        "        partes = nombre.split('_')\n",
        "\n",
        "        if len(partes) >= 2:\n",
        "            nombre_base = partes[0]          # 'df1'\n",
        "\n",
        "            # Aplicar funci√≥n de procesamiento\n",
        "            df_proc = funcion_proceso(item, nombre)\n",
        "\n",
        "            # Crear nuevo nombre\n",
        "            nuevo_nombre = f\"{nombre_base}{sufijo}\"\n",
        "            nuevo_dict[nuevo_nombre] = df_proc\n",
        "\n",
        "            print(f\"‚úÖ {nombre} ‚Üí {nuevo_nombre}\")\n",
        "            print('-' * 80)\n",
        "\n",
        "    return nuevo_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Url Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = {\n",
        "    \"df1_es\":\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset1_esp.csv,sep=;\",\n",
        "    \"df2_es\":\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset2_esp.csv,sep=;\",\n",
        "    \"df3_es\":\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset3_esp.csv,sep=,\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Iniciando carga de datasets...\n",
            "============================================================\n",
            ">>> INFORME DE CARGA DATASETS\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "üì• PROCESANDO: df1_es\n",
            "==================================================\n",
            "üîó URL: https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/d...\n",
            "üìù Separador detectado: ';'\n",
            "‚è¨ Descargando contenido...\n",
            "üîç Detectando encoding autom√°ticamente...\n",
            "üîç Encoding detectado: utf-8 (confianza: 99.00%)\n",
            "üíæ Cargando DataFrame...\n",
            "‚úÖ df1_es: Cargado exitosamente\n",
            "üìä Dimensiones: 1465 filas √ó 15 columnas\n",
            "üìã Columnas (15):\n",
            "   1. Unnamed: 0.1\n",
            "   2. Unnamed: 0\n",
            "   3. Text\n",
            "   4. Sentiment\n",
            "   5. Timestamp\n",
            "   ... y 10 columnas m√°s\n",
            "üîç Muestra (3 filas aleatorias):\n",
            "Unnamed: 0.1 Unnamed: 0                                                                                                                    Text Sentiment        Timestamp                User  Platform                        Hashtags Retweets Likes     Country Year Month Day Hour\n",
            "         256        260 Volando sobre las alas de un esp√≠ritu libre, libre de las cadenas del conformismo, pintando el cielo con independencia.   Neutral 15-08-2021 11:10          SkyPainter Instagram #Esp√≠rituLibre #PintandoElCielo       20    40       India 2021     8  15   11\n",
            "         669        673                  Intent√≥ un truco de magia para impresionar a sus compa√±eros.Fallo de magia: ¬øAd√≥nde se fue ese conejo? Verguenza 27-08-2023 20:45 MagicFailHighSchool Instagram  #MagiaFalla #MagiaDeSecundaria       22    45 Reino Unido 2023     8  27   20\n",
            "         415        419                                            Perdido en las p√°ginas de una novela cautivadora, transportado a otro mundo.   Neutral 28-09-2019 19:45            Bookworm   Twitter   #Inmersi√≥n #NovelaCautivadora       20    40 Reino Unido 2019     9  28   19\n",
            "‚úÖ df1_es ‚Üí df1_cargado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "üì• PROCESANDO: df2_es\n",
            "==================================================\n",
            "üîó URL: https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/d...\n",
            "üìù Separador detectado: ';'\n",
            "‚è¨ Descargando contenido...\n",
            "üîç Detectando encoding autom√°ticamente...\n",
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "üíæ Cargando DataFrame...\n",
            "‚úÖ df2_es: Cargado exitosamente\n",
            "üìä Dimensiones: 2540 filas √ó 3 columnas\n",
            "üìã Columnas (3):\n",
            "   1. texto\n",
            "   2. label\n",
            "   3. sentimiento\n",
            "üîç Muestra (3 filas aleatorias):\n",
            "                                                                                                                                                                                                                                                                                  texto  label sentimiento\n",
            "                                                                                                                                                                                                                                                 Soy un so√±ador, pero dormido no estoy!      0    negativo\n",
            "                                                                                                                                                                                                                                  Vivir sin preocupaciones est√° de la vrga muy aburrido      2    positivo\n",
            "#sue√±o de ayer.. en mi depa despert√© so√±oliento y eran las 9am pero segu√≠a obscuro, 3 personas en mi comedor. Me acerco a la ventana y digo ‚Äúhoy es el d√≠a, hoy vienen‚Äù y veo ‚Äúluces‚Äù de cielo acercarse y los 3 se esfuman de mi comedor.. se los llevaron.   #ufo #ovni #abduction ??      0    negativo\n",
            "‚úÖ df2_es ‚Üí df2_cargado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "==================================================\n",
            "üì• PROCESANDO: df3_es\n",
            "==================================================\n",
            "üîó URL: https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/d...\n",
            "üìù Separador detectado: ';'\n",
            "‚è¨ Descargando contenido...\n",
            "üîç Detectando encoding autom√°ticamente...\n",
            "üîç Encoding detectado: Windows-1254 (confianza: 56.84%)\n",
            "üíæ Cargando DataFrame...\n",
            "‚ö†Ô∏è  Error con separador ';'. Probando alternativas...\n",
            "‚úÖ df3_es: Cargado con separador alternativo ','\n",
            "üìä Dimensiones: 740 filas √ó 4 columnas\n",
            "üìã Columnas (4):\n",
            "   1. id\n",
            "   2. plataforma\n",
            "   3. sentimiento\n",
            "   4. texto\n",
            "üîç Muestra (3 filas aleatorias):\n",
            "  id plataforma sentimiento                                                                                                                             texto\n",
            "9044     Nvidia     Neutral Seg√∫n se informa, AMD est√° probando Big Navi, y podr√≠a ser una GPU monstruosa que preocupar√° seriamente a Nvidia dlvr.it / RNbcLk\n",
            "9173     Nvidia     Neutral                                                                                                                       ¬øQue sigue?\n",
            "9171     Nvidia     Neutral                 Esta comparaci√≥n de referencia entre la GPU Oculus Quest y la NVidia 2080Ti es simplemente una burla del sistema.\n",
            "‚úÖ df3_es ‚Üí df3_cargado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            ">>> RESUMEN DE CARGA\n",
            "============================================================\n",
            "üìä Datasets cargados exitosamente: 3/3\n",
            "  ‚úÖ df1_es ‚Üí df1_cargado: (1465, 15)\n",
            "  ‚úÖ df2_es ‚Üí df2_cargado: (2540, 3)\n",
            "  ‚úÖ df3_es ‚Üí df3_cargado: (740, 4)\n",
            "\n",
            "üéØ DATASETS CARGADOS DISPONIBLES:\n",
            "  ‚Ä¢ df1_cargado: DataFrame con forma (1465, 15)\n",
            "  ‚Ä¢ df2_cargado: DataFrame con forma (2540, 3)\n",
            "  ‚Ä¢ df3_cargado: DataFrame con forma (740, 4)\n"
          ]
        }
      ],
      "source": [
        "# IMPORTAR DATASETS\n",
        "\n",
        "def importar_dataset(url_param, nombre):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL que incluye par√°metros en el string.\n",
        "    Formato: \"url,sep=X\" o \"url,encoding=Y,sep=Z\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"üì• PROCESANDO: {nombre}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        # 1. Parsear URL y par√°metros usando regex para mayor robustez\n",
        "        if ',' in url_param:\n",
        "            # Encontrar la URL (todo antes del primer par√°metro)\n",
        "            match = re.match(r'^([^,]+)(,.+)?$', url_param)\n",
        "            if match:\n",
        "                url = match.group(1).strip()\n",
        "                parametros_str = match.group(2) or \"\"\n",
        "            else:\n",
        "                url = url_param\n",
        "                parametros_str = \"\"\n",
        "        else:\n",
        "            url = url_param\n",
        "            parametros_str = \"\"\n",
        "        \n",
        "        print(f\"üîó URL: {url[:80]}...\" if len(url) > 80 else f\"üîó URL: {url}\")\n",
        "        \n",
        "        # 2. Extraer par√°metros con valores por defecto\n",
        "        sep = ';'  # separador por defecto\n",
        "        encoding_param = None\n",
        "        \n",
        "        if parametros_str:\n",
        "            # Extraer todos los par√°metros tipo \"key=value\"\n",
        "            parametros = re.findall(r'(\\w+)=([^,]+)', parametros_str)\n",
        "            parametros_dict = dict(parametros)\n",
        "            \n",
        "            # Obtener separador\n",
        "            if 'sep' in parametros_dict:\n",
        "                sep = parametros_dict['sep']\n",
        "                # Si sep es literal 'comma', convertirlo a ','\n",
        "                if sep.lower() == 'comma':\n",
        "                    sep = ','\n",
        "            \n",
        "            # Obtener encoding si est√° especificado\n",
        "            if 'encoding' in parametros_dict:\n",
        "                encoding_param = parametros_dict['encoding']\n",
        "        \n",
        "        print(f\"üìù Separador detectado: '{sep}'\")\n",
        "        if encoding_param:\n",
        "            print(f\"üìù Encoding especificado: {encoding_param}\")\n",
        "        \n",
        "        # 3. Descargar contenido\n",
        "        print(\"‚è¨ Descargando contenido...\")\n",
        "        req = urllib.request.Request(\n",
        "            url, \n",
        "            headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
        "        )\n",
        "        \n",
        "        with urllib.request.urlopen(req, timeout=30) as response:\n",
        "            content = response.read()\n",
        "        \n",
        "        # 4. Determinar encoding\n",
        "        if encoding_param and encoding_param.lower() != 'auto':\n",
        "            # Usar encoding especificado\n",
        "            encoding = encoding_param\n",
        "            print(f\"üîç Usando encoding especificado: {encoding}\")\n",
        "        else:\n",
        "            # Detectar encoding autom√°ticamente\n",
        "            print(\"üîç Detectando encoding autom√°ticamente...\")\n",
        "            result = chardet.detect(content)\n",
        "            encoding = result['encoding'] or 'utf-8'\n",
        "            print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "        \n",
        "        # 5. Decodificar y cargar\n",
        "        print(\"üíæ Cargando DataFrame...\")\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        \n",
        "        # Intentar cargar con el separador detectado\n",
        "        try:\n",
        "            data = pd.read_csv(StringIO(decoded_content), sep=sep)\n",
        "            print(f\"‚úÖ {nombre}: Cargado exitosamente\")\n",
        "            \n",
        "        except pd.errors.ParserError:\n",
        "            print(f\"‚ö†Ô∏è  Error con separador '{sep}'. Probando alternativas...\")\n",
        "            # Probar separadores alternativos comunes\n",
        "            separadores_alternativos = [',', ';', '\\t', '|']\n",
        "            \n",
        "            for alt_sep in separadores_alternativos:\n",
        "                if alt_sep != sep:  # No probar el mismo\n",
        "                    try:\n",
        "                        data = pd.read_csv(StringIO(decoded_content), sep=alt_sep)\n",
        "                        print(f\"‚úÖ {nombre}: Cargado con separador alternativo '{alt_sep}'\")\n",
        "                        break\n",
        "                    except:\n",
        "                        continue\n",
        "            else:\n",
        "                # Si ning√∫n separador funciona, intentar sin especificar\n",
        "                print(\"üîÑ Intentando con separador autom√°tico...\")\n",
        "                data = pd.read_csv(StringIO(decoded_content), sep=None, engine='python')\n",
        "                print(f\"‚úÖ {nombre}: Cargado con separador autom√°tico\")\n",
        "        \n",
        "        # 6. Mostrar informaci√≥n del dataset\n",
        "        print(f\"üìä Dimensiones: {data.shape[0]} filas √ó {data.shape[1]} columnas\")\n",
        "        print(f\"üìã Columnas ({len(data.columns)}):\")\n",
        "        for i, col in enumerate(data.columns[:5]):  # Mostrar primeras 5 columnas\n",
        "            print(f\"   {i+1}. {col}\")\n",
        "        if len(data.columns) > 5:\n",
        "            print(f\"   ... y {len(data.columns)-5} columnas m√°s\")\n",
        "        \n",
        "        print(f\"üîç Muestra (3 filas aleatorias):\")\n",
        "        print(data.sample(min(3, len(data))).to_string(index=False))\n",
        "        \n",
        "        return data\n",
        "        \n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de conexi√≥n en {nombre}: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado en {nombre}: {type(e).__name__}: {str(e)[:100]}...\")\n",
        "        return None\n",
        "\n",
        "# Tu c√≥digo original SIN MODIFICAR\n",
        "def fase_carga_datasets(datasets):\n",
        "    print('=' * 60)\n",
        "    print('>>> INFORME DE CARGA DATASETS')\n",
        "    print('=' * 60)\n",
        "    \n",
        "    nuevo_diccionario = procesar_dic(\n",
        "        dict=datasets,\n",
        "        funcion_proceso=importar_dataset,\n",
        "        sufijo='_cargado'\n",
        "    )\n",
        "    \n",
        "    # Resumen final\n",
        "    print('\\n' + '=' * 60)\n",
        "    print('>>> RESUMEN DE CARGA')\n",
        "    print('=' * 60)\n",
        "    \n",
        "    cargados = sum(1 for df in nuevo_diccionario.values() if df is not None)\n",
        "    print(f\"üìä Datasets cargados exitosamente: {cargados}/{len(datasets)}\")\n",
        "    \n",
        "    for nombre_original, df in zip(datasets.keys(), nuevo_diccionario.values()):\n",
        "        nombre_nuevo = nombre_original.split('_')[0] + '_cargado'\n",
        "        if df is not None:\n",
        "            print(f\"  ‚úÖ {nombre_original} ‚Üí {nombre_nuevo}: {df.shape}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå {nombre_original} ‚Üí {nombre_nuevo}: FALL√ì\")\n",
        "    \n",
        "    return nuevo_diccionario\n",
        "\n",
        "\n",
        "# Ejecutar\n",
        "print(\"üöÄ Iniciando carga de datasets...\")\n",
        "dfs_originales = fase_carga_datasets(datasets)\n",
        "\n",
        "# Verificar resultados\n",
        "if dfs_originales:\n",
        "    print(\"\\nüéØ DATASETS CARGADOS DISPONIBLES:\")\n",
        "    for nombre, df in dfs_originales.items():\n",
        "        if df is not None:\n",
        "            print(f\"  ‚Ä¢ {nombre}: {type(df).__name__} con forma {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['df1_cargado', 'df2_cargado', 'df3_cargado']\n",
            "üìä TOTAL INICIAL REAL (suma de todos los datasets): 4,745\n"
          ]
        }
      ],
      "source": [
        "# Mostrar las claves del diccionario de dataframes cargados\n",
        "print(list(dfs_originales.keys()))\n",
        "df1_cargado = dfs_originales.get('df1_cargado')\n",
        "df2_cargado = dfs_originales.get('df2_cargado')\n",
        "df3_cargado = dfs_originales.get('df3_cargado')\n",
        "\n",
        "\n",
        "TOTAL_INICIAL_REAL = len(df1_cargado) + len(df2_cargado) + len(df3_cargado)\n",
        "print(f\"üìä TOTAL INICIAL REAL (suma de todos los datasets): {TOTAL_INICIAL_REAL:,}\")\n",
        "\n",
        "# Guardar como variable global\n",
        "INICIAL_GLOBAL = TOTAL_INICIAL_REAL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNDDOVQQ8MA-"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar y explorar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalizar_columnas(df):\n",
        "    df_copia = df.copy()\n",
        "\n",
        "    col_texto_encontrada = None\n",
        "    # Buscar una columna que pueda contener el texto\n",
        "    for nombre_columna in ['texto', 'Text', 'contenido']:\n",
        "        if nombre_columna in df_copia.columns:\n",
        "            col_texto_encontrada = nombre_columna\n",
        "            break\n",
        "\n",
        "    col_sentimiento_encontrada = None\n",
        "    # Buscar una columna que pueda contener el sentimiento\n",
        "    for nombre_columna in ['sentimiento', 'Sentiment', 'etiqueta']:\n",
        "        if nombre_columna in df_copia.columns:\n",
        "            # Si la columna 'sentimiento' ya existe y es de tipo string (ej., 'positivo', 'negativo'), priorizarla.\n",
        "            if nombre_columna == 'sentimiento' and df_copia[nombre_columna].dtype == 'object':\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "                break\n",
        "            # De lo contrario, si 'Sentiment' existe y es de tipo objeto\n",
        "            elif nombre_columna == 'Sentiment' and df_copia[nombre_columna].dtype == 'object':\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "                break\n",
        "            # Si 'etiqueta' existe (a menudo num√©rica para sentimiento)\n",
        "            elif nombre_columna == 'etiqueta' and pd.api.types.is_numeric_dtype(df_copia[nombre_columna]):\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "                # No salir inmediatamente, ya que una columna 'sentimiento' de tipo string podr√≠a existir y ser preferible.\n",
        "                # Continuar buscando 'sentimiento' o 'Sentiment' primero.\n",
        "            # Caso general para cualquier otra columna de sentimiento encontrada\n",
        "            elif col_sentimiento_encontrada is None: # Solo asignar si no se ha asignado ya una de mayor prioridad.\n",
        "                col_sentimiento_encontrada = nombre_columna\n",
        "\n",
        "    if col_texto_encontrada is None or col_sentimiento_encontrada is None:\n",
        "        # Si las columnas esenciales faltan, retornar un DataFrame vac√≠o con las columnas esperadas.\n",
        "        return pd.DataFrame(columns=['texto', 'sentimiento'])\n",
        "\n",
        "    # Renombrar si es necesario\n",
        "    if col_texto_encontrada != 'texto':\n",
        "        df_copia.rename(columns={col_texto_encontrada: 'texto'}, inplace=True)\n",
        "    if col_sentimiento_encontrada != 'sentimiento':\n",
        "        df_copia.rename(columns={col_sentimiento_encontrada: 'sentimiento'}, inplace=True)\n",
        "\n",
        "    # Retornar solo las dos columnas requeridas.\n",
        "    return df_copia[['texto', 'sentimiento']]\n",
        "df1_filtrado = normalizar_columnas(df1_cargado)\n",
        "df2_filtrado = normalizar_columnas(df2_cargado)\n",
        "df3_filtrado = normalizar_columnas(df3_cargado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filtrar_dataframe(df,nombre):\n",
        "    # A√±adir una verificaci√≥n al inicio para DataFrame nulo\n",
        "    if df is None:\n",
        "        print(f\"Advertencia: DataFrame '{nombre}' es None, saltando filtrado.\")\n",
        "        return None\n",
        "\n",
        "    # Paso 1: Normalizar nombres de columnas\n",
        "    # normalizar_columnas ahora devuelve solo 'texto' y 'sentimiento' o un df vac√≠o.\n",
        "    df = normalizar_columnas(df)\n",
        "\n",
        "    # Paso 2: Verificar que las columnas necesarias existan despu√©s de la normalizaci√≥n\n",
        "    columnas_requeridas = ['texto', 'sentimiento']\n",
        "    if not all(col in df.columns for col in columnas_requeridas) or df.empty:\n",
        "        # Si la normalizaci√≥n fall√≥ o devolvi√≥ un df vac√≠o, df estar√° vac√≠o aqu√≠.\n",
        "        print(f\"Advertencia: No se encontraron las columnas requeridas o el DataFrame est√° vac√≠o despu√©s de normalizar en {nombre}.\")\n",
        "        return None\n",
        "\n",
        "    # Paso 3: La l√≥gica actual de filtrado (ahora se garantiza que df tiene 'texto', 'sentimiento')\n",
        "    df_filtrado = df[columnas_requeridas].copy()\n",
        "\n",
        "    # Mostrar estad√≠sticas\n",
        "    print(f'\\nRESUMEN {nombre}')\n",
        "    print(f\"üìä Tama√±o del dataframe: {df_filtrado.shape}\")\n",
        "    print(f\"üìä Registros √∫nicos: {df_filtrado['texto'].nunique()}\")\n",
        "    print(f\"üìä Sentimientos √∫nicos: {df_filtrado['sentimiento'].nunique()}\")\n",
        "    print(f\"üìä Textos vac√≠os: {df_filtrado['texto'].isnull().sum()}\")\n",
        "    print(f\"üìä Sentimientos vac√≠os: {df_filtrado['sentimiento'].isnull().sum()}\")\n",
        "    print(f\"üìä Registros duplicados: {df_filtrado.duplicated().sum()}\")\n",
        "    print(f\"üìä Textos duplicados: {df_filtrado.duplicated(subset=['texto']).sum()}\")\n",
        "\n",
        "    print(df_filtrado.sample(3))\n",
        "\n",
        "    return df_filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "RESUMEN df1_cargado\n",
            "üìä Tama√±o del dataframe: (1465, 2)\n",
            "üìä Registros √∫nicos: 708\n",
            "üìä Sentimientos √∫nicos: 105\n",
            "üìä Textos vac√≠os: 2\n",
            "üìä Sentimientos vac√≠os: 2\n",
            "üìä Registros duplicados: 754\n",
            "üìä Textos duplicados: 756\n",
            "                                                  texto     sentimiento\n",
            "1337  Saborear los sabores de una comida casera.Las ...  Contentamiento\n",
            "504   Al caminar por la Gran Muralla China, cada pas...        Positivo\n",
            "169   Llega el aburrimiento, el d√≠a se siente infini...    Aburrimiento\n",
            "‚úÖ df1_cargado ‚Üí df1_filtrado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESUMEN df2_cargado\n",
            "üìä Tama√±o del dataframe: (2540, 2)\n",
            "üìä Registros √∫nicos: 2156\n",
            "üìä Sentimientos √∫nicos: 3\n",
            "üìä Textos vac√≠os: 0\n",
            "üìä Sentimientos vac√≠os: 0\n",
            "üìä Registros duplicados: 298\n",
            "üìä Textos duplicados: 384\n",
            "                                                  texto sentimiento\n",
            "1174  Al menda le va a tocar empollar fuerte el Java...    positivo\n",
            "743   √ÅNGEL GONZ√ÅLEZ . Aqu√≠ o all√≠ Qui√©n es el que e...    negativo\n",
            "1545  ya chicos, hilo apreciativo del humor que nos ...    positivo\n",
            "‚úÖ df2_cargado ‚Üí df2_filtrado\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "RESUMEN df3_cargado\n",
            "üìä Tama√±o del dataframe: (740, 2)\n",
            "üìä Registros √∫nicos: 697\n",
            "üìä Sentimientos √∫nicos: 3\n",
            "üìä Textos vac√≠os: 0\n",
            "üìä Sentimientos vac√≠os: 0\n",
            "üìä Registros duplicados: 43\n",
            "üìä Textos duplicados: 43\n",
            "                                                 texto sentimiento\n",
            "25   El mercado de GPU para aprendizaje de IA regis...     Neutral\n",
            "361                                                 el     Neutral\n",
            "318  Nvidia est√° lista para anunciar las novedades....     Neutral\n",
            "‚úÖ df3_cargado ‚Üí df3_filtrado\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def fase_filtrado(dfs_originarios):\n",
        "    # Solo orquesta: delega el recorrido a procesar_dict\n",
        "    dfs_filtrados = procesar_dic(\n",
        "        dict=dfs_originales,\n",
        "        funcion_proceso=filtrar_dataframe,\n",
        "        sufijo='_filtrado'\n",
        "    )\n",
        "    return dfs_filtrados\n",
        "\n",
        "# Uso\n",
        "dfs_filtrados = fase_filtrado(dfs_originales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['df1_filtrado', 'df2_filtrado', 'df3_filtrado']\n"
          ]
        }
      ],
      "source": [
        "print(list(dfs_filtrados.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpieza y normalizaci√≥n de textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "    \n",
        "    # Elimina los caracteres '#' que est√°n directamente seguidos por una palabra (hashtags).\n",
        "    resultado = re.sub(r'#(?=\\S)', '', resultado)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Iterable\n",
        "def obtener_lista_ordenada(*series_o_listas: Iterable,nombre='nombre'):\n",
        "    \"\"\"\n",
        "    Acepta cualquier cantidad de Series/Listas de sentimientos y devuelve\n",
        "    una lista ordenada de sentimientos √∫nicos ya limpios.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) Unir todas las entradas en un solo iterable\n",
        "    todos = []\n",
        "    for s in series_o_listas:\n",
        "        todos.extend(list(s))\n",
        "\n",
        "\n",
        "    # 2) Limpiar y eliminar duplicados en un solo paso usando un set\n",
        "    sentimientos_limpios = {limpiar_texto_sentimientos(x) for x in todos}\n",
        "\n",
        "    print('\\n====> RESUMEN LIMPIEZA',nombre)\n",
        "    print(f'üìä Registros (original):',len(todos))\n",
        "    print(f'üìä Registros (despues de la limpieza):',len(sentimientos_limpios))\n",
        "    # listar \n",
        "    print(f'Lista {nombre} limpios: {', '.join(sentimientos_limpios)}')\n",
        "\n",
        "    print('-' * 80)\n",
        "\n",
        "    # 3) Devolver ordenado\n",
        "    return sorted(sentimientos_limpios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limpieza dataframe\n",
        "\n",
        "def limpiar_columnas(df, col1_name, col2_name, nombre_df):\n",
        "    df_copy = df.copy()\n",
        "    \n",
        "    print(f\"üîÑ Procesando {nombre_df}...\")\n",
        "    print(f\"  Antes: {df_copy.shape}\")\n",
        "    \n",
        "    df_copy[col1_name + \"_limpio\"] = df_copy[col1_name].apply(limpiar_texto_sentimientos)\n",
        "    df_copy[col2_name + \"_limpio\"] = df_copy[col2_name].apply(limpiar_texto_sentimientos)\n",
        "    \n",
        "    print(f\"  Despu√©s: {df_copy.shape}, nuevas cols: {col1_name}_limpio, {col2_name}_limpio\")\n",
        "    \n",
        "    return df_copy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "üöÄ FASE 1: LIMPIEZA B√ÅSICA (COM√öN A TODOS)\n",
            "======================================================================\n",
            "üîÑ Procesando df1_filtrado...\n",
            "  Antes: (1465, 2)\n",
            "  Despu√©s: (1465, 4), nuevas cols: texto_limpio, sentimiento_limpio\n",
            "‚úÖ df1_filtrado ‚Üí df1_limpio\n",
            "--------------------------------------------------------------------------------\n",
            "üîÑ Procesando df2_filtrado...\n",
            "  Antes: (2540, 2)\n",
            "  Despu√©s: (2540, 4), nuevas cols: texto_limpio, sentimiento_limpio\n",
            "‚úÖ df2_filtrado ‚Üí df2_limpio\n",
            "--------------------------------------------------------------------------------\n",
            "üîÑ Procesando df3_filtrado...\n",
            "  Antes: (740, 2)\n",
            "  Despu√©s: (740, 4), nuevas cols: texto_limpio, sentimiento_limpio\n",
            "‚úÖ df3_filtrado ‚Üí df3_limpio\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úÖ LIMPIEZA B√ÅSICA COMPLETADA\n",
            "‚Ä¢ Entrada: 3 datasets\n",
            "‚Ä¢ Salida: 3 datasets procesados\n",
            "['df1_limpio', 'df2_limpio', 'df3_limpio']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# FUNCI√ìN 3: Fase de limpieza b√°sica (ORQUESTADOR)\n",
        "# ============================================================================\n",
        "def fase_limpieza_texto(dfs_filtrados):\n",
        "    \"\"\"\n",
        "    Orquesta la limpieza b√°sica de todos los datasets\n",
        "\n",
        "    Args:\n",
        "        dfs_originales: Diccionario con datasets filtrados\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con datasets despu√©s de limpieza b√°sica\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üöÄ FASE 1: LIMPIEZA B√ÅSICA (COM√öN A TODOS)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Usar procesar_dict_con_idioma para recorrer todos\n",
        "    dfs_limpios_resultado = procesar_dic(\n",
        "        dict=dfs_filtrados, # Corrected: should use dfs_filtrados here\n",
        "        funcion_proceso=lambda df, nombre: limpiar_columnas(\n",
        "            df,\n",
        "            col1_name=\"texto\",\n",
        "            col2_name=\"sentimiento\",\n",
        "            nombre_df=nombre\n",
        "        ),\n",
        "        sufijo='_limpio'\n",
        "    )\n",
        "\n",
        "    print(\"\\n‚úÖ LIMPIEZA B√ÅSICA COMPLETADA\")\n",
        "    print(f\"‚Ä¢ Entrada: {len(dfs_filtrados)} datasets\")\n",
        "    print(f\"‚Ä¢ Salida: {len(dfs_limpios_resultado)} datasets procesados\")\n",
        "\n",
        "    return dfs_limpios_resultado\n",
        "\n",
        "# Call the function and assign its result to the global dfs_limpios\n",
        "dfs_limpios = fase_limpieza_texto(dfs_filtrados)\n",
        "print(list(dfs_limpios.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=lightgreen size=12>Unificaci√≥n dfs</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä ESTAD√çSTICAS ANTES DE UNIFICAR:\n",
            "==================================================\n",
            "df1_limpio: 1465 filas, 4 cols\n",
            "  Columnas: ['texto', 'sentimiento', 'texto_limpio', 'sentimiento_limpio']\n",
            "df2_limpio: 2540 filas, 4 cols\n",
            "  Columnas: ['texto', 'sentimiento', 'texto_limpio', 'sentimiento_limpio']\n",
            "df3_limpio: 740 filas, 4 cols\n",
            "  Columnas: ['texto', 'sentimiento', 'texto_limpio', 'sentimiento_limpio']\n",
            "\n",
            "‚úÖ UNIFICACI√ìN COMPLETADA:\n",
            "==================================================\n",
            "df_unificado: 4745 filas, 4 cols\n",
            "Total filas originales: 4745 ‚úì\n",
            "\n",
            "Primeras 3 filas:\n",
            "                                              texto sentimiento  \\\n",
            "0      ¬°Disfrutando de un hermoso d√≠a en el parque!    Positivo   \n",
            "1              Esta ma√±ana el tr√°fico era terrible.    Negativo   \n",
            "2  ¬°Acabo de terminar un entrenamiento incre√≠ble!??    Positivo   \n",
            "\n",
            "                                       texto_limpio sentimiento_limpio  \n",
            "0      ¬°Disfrutando de un hermoso dia en el parque!           Positivo  \n",
            "1              Esta ma√±ana el trafico era terrible.           Negativo  \n",
            "2  ¬°Acabo de terminar un entrenamiento increible!??           Positivo  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def unificar_dfs_limpios(dfs_limpios):\n",
        "    \"\"\"\n",
        "    Une todos los DataFrames del diccionario dfs_limpios en df_unificado.\n",
        "    Valida columnas iguales y muestra estad√≠sticas detalladas.\n",
        "    \"\"\"\n",
        "    # Validaciones\n",
        "    if not dfs_limpios:\n",
        "        print(\"‚ùå Error: dfs_limpios est√° vac√≠o\")\n",
        "        return None\n",
        "    \n",
        "    dfs_list = list(dfs_limpios.values())\n",
        "    columnas_esperadas = ['texto_limpio', 'sentimiento_limpio']  # De tu workflow\n",
        "    \n",
        "    # Estad√≠sticas antes de unir\n",
        "    print(\"üìä ESTAD√çSTICAS ANTES DE UNIFICAR:\")\n",
        "    print(\"=\" * 50)\n",
        "    total_filas = 0\n",
        "    for nombre, df in dfs_limpios.items():\n",
        "        print(f\"{nombre}: {df.shape[0]} filas, {df.shape[1]} cols\")\n",
        "        print(f\"  Columnas: {list(df.columns)}\")\n",
        "        if not all(col in df.columns for col in columnas_esperadas):\n",
        "            print(f\"  ‚ö†Ô∏è  {nombre} falta columnas esperadas\")\n",
        "        total_filas += df.shape[0]\n",
        "    \n",
        "    # Verificar columnas iguales\n",
        "    columnas_set = {frozenset(df.columns) for df in dfs_list}\n",
        "    if len(columnas_set) > 1:\n",
        "        print(\"‚ùå Error: Columnas no coinciden entre DataFrames\")\n",
        "        return None\n",
        "    \n",
        "    # Unificar\n",
        "    df_unificado = pd.concat(dfs_list, ignore_index=True)\n",
        "   \n",
        "    # Estad√≠sticas despu√©s\n",
        "    print(\"\\n‚úÖ UNIFICACI√ìN COMPLETADA:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"df_unificado: {df_unificado.shape[0]} filas, {df_unificado.shape[1]} cols\")\n",
        "    print(f\"Total filas originales: {total_filas} ‚úì\")\n",
        "    print(\"\\nPrimeras 3 filas:\")\n",
        "    print(df_unificado.head(3))\n",
        "    \n",
        "    return df_unificado\n",
        "\n",
        "# Uso:\n",
        "df_unificado = unificar_dfs_limpios(dfs_limpios)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwBnt_Bx8MBD"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpieza df unificado</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ LIMPIEZA R√ÅPIDA CON ESTAD√çSTICAS Y AUDITOR√çA\n",
            "======================================================================\n",
            "\n",
            "üìä INICIAL: 4,745 registros\n",
            "üîç Textos contradictorios √∫nicos: 90\n",
            "üìà Registros afectados: 180 (todos se eliminar√°n)\n",
            "   Ejemplos:\n",
            "     ‚ùå '\"De manera apacible, se puede sacudir el mundo\" MG...' ‚Üí ['negativo', 'positivo'] (3 regs)\n",
            "     ‚ùå '\"He aprendido que el valor no es la ausencia de mi...' ‚Üí ['neutral', 'positivo'] (2 regs)\n",
            "     ‚ùå '\"La soledad es peligrosa. Es muy adictiva. Se conv...' ‚Üí ['negativo', 'positivo'] (6 regs)\n",
            "     ... y 87 m√°s\n",
            "\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS CONTRADICTORIOS: 216\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS DUPLICADOS:     1,073\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS NULOS/VAC√çOS:  1\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìä FINAL: 3,455 registros\n",
            "üìä ELIMINADOS TOTAL: 1,290 (27.2%)\n",
            "\n",
            "üìà CONTADOR ACUMULADO:\n",
            "   Contradicciones: 216\n",
            "   Duplicados: 1073\n",
            "   Vac√≠os/Nulos: 1\n",
            "   Total Eliminados: 1290\n",
            "\n",
            "‚úÖ Estad√≠sticas guardadas en df: True\n"
          ]
        }
      ],
      "source": [
        "def limpieza_dataframe_unificado(df, col_texto='texto_limpio', col_sentimiento='sentimiento_limpio', contador=None):\n",
        "    \"\"\"\n",
        "    Limpieza con acumulaci√≥n de estad√≠sticas\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üßπ LIMPIEZA R√ÅPIDA CON ESTAD√çSTICAS Y AUDITOR√çA\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Inicializar contador si no se proporciona\n",
        "    if contador is None:\n",
        "        contador = {\n",
        "            'contradicciones': 0,\n",
        "            'duplicados': 0,\n",
        "            'vacios_nulos': 0,\n",
        "            'sentimientos_nan': 0,\n",
        "            'total_eliminados': 0\n",
        "\n",
        "        }\n",
        "\n",
        "    df_original = df.copy()\n",
        "    registros_iniciales = len(df)\n",
        "\n",
        "    # AUDITOR√çA CONTRADICCIONES (igual que antes)\n",
        "    print(f\"\\nüìä INICIAL: {registros_iniciales:,} registros\")\n",
        "    grupos = df.groupby(col_texto)[col_sentimiento].nunique()\n",
        "    contradictorios = grupos[grupos > 1]\n",
        "    print(f\"üîç Textos contradictorios √∫nicos: {len(contradictorios):,}\")\n",
        "    print(f\"üìà Registros afectados: {contradictorios.sum():,} (todos se eliminar√°n)\")\n",
        "\n",
        "    # Mostrar top 3 ejemplos reales (igual que antes)\n",
        "    top_ejemplos = contradictorios.head(3).index.tolist()\n",
        "    print(\"   Ejemplos:\")\n",
        "    for texto in top_ejemplos:\n",
        "        sentimientos = sorted(df[df[col_texto] == texto][col_sentimiento].unique())\n",
        "        registros = len(df[df[col_texto] == texto])\n",
        "        print(f\"     ‚ùå '{texto[:50]}...' ‚Üí {sentimientos} ({registros} regs)\")\n",
        "    if len(contradictorios) > 3:\n",
        "        print(f\"     ... y {len(contradictorios)-3:,} m√°s\")\n",
        "\n",
        "    # 1. ELIMINAR CONTRADICTORIOS (igual c√°lculo)\n",
        "    textos_contradictorios = contradictorios.index.tolist()\n",
        "    df_antes = df.copy()\n",
        "    df = df[~df[col_texto].isin(textos_contradictorios)]\n",
        "    eliminados_contradictorios = len(df_antes) - len(df)\n",
        "\n",
        "    # ACUMULAR ESTAD√çSTICA (NUEVO)\n",
        "    contador['contradicciones'] += eliminados_contradictorios\n",
        "    print(f\"\\n‚úÇÔ∏è  REGISTROS ELIMINADOS CONTRADICTORIOS: {eliminados_contradictorios:,}\")\n",
        "\n",
        "    # 2. DUPLICADOS (igual c√°lculo)\n",
        "    df_antes = df.copy()\n",
        "    duplicados = df.duplicated(subset=[col_texto, col_sentimiento]).sum()\n",
        "    df = df.drop_duplicates(subset=[col_texto, col_sentimiento])\n",
        "    eliminados_duplicados = len(df_antes) - len(df)\n",
        "\n",
        "    # ACUMULAR ESTAD√çSTICA (NUEVO)\n",
        "    contador['duplicados'] += eliminados_duplicados\n",
        "    print(f\"‚úÇÔ∏è  REGISTROS ELIMINADOS DUPLICADOS:     {duplicados:,}\")\n",
        "\n",
        "    # 3. VAC√çOS Y NULOS (igual c√°lculo)\n",
        "    df_antes = df.copy()\n",
        "    vacios_antes = len(df)\n",
        "    df = df.dropna(subset=[col_texto, col_sentimiento])\n",
        "    df = df[(df[col_texto].astype(str).str.strip() != '') &\n",
        "            (df[col_sentimiento].astype(str).str.strip() != '')]\n",
        "    vacios_eliminados = len(df_antes) - len(df)\n",
        "\n",
        "    # ACUMULAR ESTAD√çSTICA (NUEVO)\n",
        "    contador['vacios_nulos'] += vacios_eliminados\n",
        "    print(f\"‚úÇÔ∏è  REGISTROS ELIMINADOS NULOS/VAC√çOS:  {vacios_eliminados:,}\")\n",
        "\n",
        "    # ESTAD√çSTICAS FINALES\n",
        "    registros_finales = len(df)\n",
        "    total_eliminados = registros_iniciales - registros_finales\n",
        "\n",
        "    # Update total_eliminados in the contador\n",
        "    contador['total_eliminados'] += total_eliminados\n",
        "\n",
        "    print('-' * 80)\n",
        "\n",
        "    print(f\"\\nüìä FINAL: {registros_finales:,} registros\")\n",
        "    print(f\"üìä ELIMINADOS TOTAL: {total_eliminados:,} ({total_eliminados/registros_iniciales*100:.1f}%)\")\n",
        "\n",
        "    # CREAR ESTAD√çSTICAS PARA EL GR√ÅFICO (NUEVO)\n",
        "    stats = {\n",
        "        'inicial': registros_iniciales, # Use registros_iniciales from this specific call\n",
        "        'final': registros_finales,\n",
        "        'contradicciones_encontradas': contador['contradicciones'],\n",
        "        'registros_eliminados_contradicciones': contador['contradicciones'],\n",
        "        'duplicados_exactos_encontrados': contador['duplicados'],\n",
        "        'registros_eliminados_duplicados': contador['duplicados'],\n",
        "        'textos_vacios_eliminados': contador['vacios_nulos'],  # Juntamos vac√≠os y nulos\n",
        "        'sentimientos_nan_eliminados': 0,  # No manejas sentimientos NaN separados\n",
        "        'total_eliminados':contador['total_eliminados'], # This will now be correct\n",
        "        'porcentaje_eliminado': round((total_eliminados / registros_iniciales * 100), 2) if registros_iniciales > 0 else 0\n",
        "    }\n",
        "\n",
        "    # GUARDAR EN EL DATAFRAME (NUEVO)\n",
        "    df.estadisticas_limpieza = stats\n",
        "\n",
        "    # Mostrar contador acumulado\n",
        "    print(f\"\\nüìà CONTADOR ACUMULADO:\")\n",
        "    print(f\"   Contradicciones: {contador['contradicciones']}\")\n",
        "    print(f\"   Duplicados: {contador['duplicados']}\")\n",
        "    print(f\"   Vac√≠os/Nulos: {contador['vacios_nulos']}\")\n",
        "    print(f\"   Total Eliminados: {contador['total_eliminados']}\")\n",
        "\n",
        "    return df, contador, stats\n",
        "\n",
        "\n",
        "\n",
        "# 2. Llamar la funci√≥n pasando el contador\n",
        "df_limpio, CONTADOR_GLOBAL, stats = limpieza_dataframe_unificado(\n",
        "    df_unificado,\n",
        "    contador=CONTADOR_GLOBAL\n",
        ")\n",
        "\n",
        "\n",
        "# 3. Verificar que las stats est√°n en df_limpio\n",
        "print(f\"\\n‚úÖ Estad√≠sticas guardadas en df: {hasattr(df_limpio, 'estadisticas_limpieza')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Normalizando dataset...\n",
            "   Eliminadas columnas: ['texto', 'sentimiento']\n",
            "   Renombradas columnas: {'texto_limpio': 'texto', 'sentimiento_limpio': 'sentimiento'}\n",
            "\n",
            "‚úÖ Dataset normalizado:\n",
            "   ‚Ä¢ Forma: (3455, 2)\n",
            "   ‚Ä¢ Columnas: ['texto', 'sentimiento']\n"
          ]
        }
      ],
      "source": [
        "# PRIMERA NORMALIZACION - DF LIMPIO\n",
        "\n",
        "def primera_normalizacion(df_limpio):\n",
        "    \"\"\"\n",
        "    Versi√≥n simple de normalizaci√≥n\n",
        "    \"\"\"\n",
        "    if df_limpio is None or df_limpio.empty:\n",
        "        print(\"‚ùå Dataset vac√≠o o None\")\n",
        "        return None\n",
        "    \n",
        "    print(\"üîß Normalizando dataset...\")\n",
        "    \n",
        "    # 1. Eliminar columnas originales si existen\n",
        "    columnas_a_eliminar = []\n",
        "    if 'texto' in df_limpio.columns:\n",
        "        columnas_a_eliminar.append('texto')\n",
        "    if 'sentimiento' in df_limpio.columns:\n",
        "        columnas_a_eliminar.append('sentimiento')\n",
        "    \n",
        "    if columnas_a_eliminar:\n",
        "        df = df_limpio.drop(columns=columnas_a_eliminar)\n",
        "        print(f\"   Eliminadas columnas: {columnas_a_eliminar}\")\n",
        "    else:\n",
        "        df = df_limpio.copy()\n",
        "    \n",
        "    # 2. Renombrar columnas limpias\n",
        "    mapeo = {}\n",
        "    if 'texto_limpio' in df.columns:\n",
        "        mapeo['texto_limpio'] = 'texto'\n",
        "    if 'sentimiento_limpio' in df.columns:\n",
        "        mapeo['sentimiento_limpio'] = 'sentimiento'\n",
        "    \n",
        "    if mapeo:\n",
        "        df = df.rename(columns=mapeo)\n",
        "        print(f\"   Renombradas columnas: {mapeo}\")\n",
        "    \n",
        "    # 3. Verificar resultado\n",
        "    print(f\"\\n‚úÖ Dataset normalizado:\")\n",
        "    print(f\"   ‚Ä¢ Forma: {df.shape}\")\n",
        "    print(f\"   ‚Ä¢ Columnas: {list(df.columns)}\")\n",
        "    \n",
        "    # Verificar que tengamos las columnas esenciales\n",
        "    if 'texto' not in df.columns:\n",
        "        print(\"‚ö†Ô∏è  Advertencia: Columna 'texto' no encontrada\")\n",
        "    if 'sentimiento' not in df.columns:\n",
        "        print(\"‚ö†Ô∏è  Advertencia: Columna 'sentimiento' no encontrada\")\n",
        "    \n",
        "    return df\n",
        "df_normal1 = primera_normalizacion(df_limpio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>Negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°Emocionado por la escapada de fin de semana q...</td>\n",
              "      <td>Positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probando una nueva receta para cenar esta noche.</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texto sentimiento\n",
              "0       ¬°Disfrutando de un hermoso dia en el parque!    Positivo\n",
              "1               Esta ma√±ana el trafico era terrible.    Negativo\n",
              "2   ¬°Acabo de terminar un entrenamiento increible!??    Positivo\n",
              "3  ¬°Emocionado por la escapada de fin de semana q...    Positivo\n",
              "4   Probando una nueva receta para cenar esta noche.     Neutral"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normal1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos: 109\n",
            "Sentimientos √∫nicos: ['', 'Abrumado', 'Aburrimiento', 'Aceptacion', 'Admiracion', 'Adoracion', 'Agradecido', 'Aislamiento', 'Alegria', 'Amabilidad', 'Amargura', 'Ambivalencia', 'Amistad', 'Amor', 'Angustia', 'Anhelo', 'Animo', 'Ansiedad', 'Anticipacion', 'Apreciacion', 'Aprensivo', 'Armonia', 'Arrepentimiento', 'Asco', 'Asombro', 'Cautivacion', 'Celebracion', 'Colorido', 'Confiado', 'Confianza', 'Contentamiento', 'Creatividad', 'Cumplimiento', 'Curiosidad', 'Decepcion', 'Desamor', 'Descubrimiento', 'Desesperacion', 'Deslumbrar', 'Despectivo', 'Determinacion', 'Devastado', 'Disfrute', 'Diversion', 'Dolor', 'Elegancia', 'Emocion', 'Empatico', 'Empoderamiento', 'Encantamiento', 'Energia', 'Enojo', 'Entumecimiento', 'Entusiasmo', 'Envidia', 'Envidioso', 'Esperanza', 'Euforia', 'Excitacion', 'Exito', 'Felicidad', 'Frustracion', 'Frustrado', 'Grandeza', 'Gratitud', 'Inspiracion', 'Inspirado', 'Intimidacion', 'Jugueton', 'Lastima', 'Logro', 'Malo', 'Maravilla', 'Melancolia', 'Melodico', 'Miedo', 'Motivacion', 'Negativo', 'Neutral', 'Obstaculo', 'Odiar', 'Optimismo', 'Orgullo', 'Pena', 'Perdida', 'Positividad', 'Positivo', 'Reconfortante', 'Reflexion', 'Resentimiento', 'Resiliencia', 'Resplandor', 'Reverencia', 'Romance', 'Satisfaccion', 'Sentiment', 'Serenidad', 'Soledad', 'Sorpresa', 'Sufrimiento', 'Temeroso', 'Ternura', 'Traicion', 'Tristeza', 'Triunfo', 'Verguenza', 'negativo', 'neutral', 'positivo']\n",
            "Sentimientos no clasificados (total: 2): \n",
            " Son: Animo, Sentiment\n"
          ]
        }
      ],
      "source": [
        "categorias ='positivo_es, negativo_es, neutral_es'\n",
        "def verificar_sentimientos_clasificados():\n",
        "    \"\"\"\n",
        "    Verifica qu√© sentimientos en df_unificado no est√°n clasificados en datos_es.\n",
        "    Muestra estad√≠sticas y lista de sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    print(\"\\nüîç VERIFICANDO SENTIMIENTOS NO CLASIFICADOS\")\n",
        "    print(\"=\" * 70)\n",
        "# Identificar y mostrar entimientos que est√°n en sentimientos_unicos_es, pero no en datos_es.keys\n",
        "sentimientos_unicos = sorted(df_unificado['sentimiento_limpio'].unique())\n",
        "print(f'Total de sentimientos: {len(sentimientos_unicos)}')\n",
        "print('Sentimientos √∫nicos:', sentimientos_unicos)\n",
        "\n",
        "# Convertir las claves de datos_es a min√∫sculas para una comparaci√≥n sin distinci√≥n de may√∫sculas y min√∫sculas\n",
        "datos_es_lower = {k.lower() for k in datos_es.keys()}\n",
        "\n",
        "sentimientos_no_clasificados = []\n",
        "for sentimiento in sentimientos_unicos:\n",
        "    # Limpiar y convertir a min√∫sculas para la comparaci√≥n\n",
        "    sentimiento_limpio_lower = sentimiento.strip().lower()\n",
        "    # Excluir la cadena vac√≠a si es que existe\n",
        "    if sentimiento_limpio_lower and sentimiento_limpio_lower not in datos_es_lower:\n",
        "        sentimientos_no_clasificados.append(sentimiento)\n",
        "\n",
        "print(f'Sentimientos no clasificados (total: {len(sentimientos_no_clasificados)}): ')\n",
        "\n",
        "if sentimientos_no_clasificados:\n",
        "    print(f\" Son: {', '.join(sentimientos_no_clasificados)}\")\n",
        "else:\n",
        "    print(\"No se encontraron sentimientos no clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQa-9sE8MBB"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SEGUNDA NORMALIZACI√ìN\n",
        "def segunda_normalizacion(df):\n",
        "\t# Crea una copia con un dataset excluyendo valores nulos\n",
        "\tnormalizado = df[df['sentimiento'].notna()].copy()\n",
        "\t# Quitar la columna sentimiento\n",
        "\tnormalizado = normalizado.drop(columns=['sentimiento']).reset_index(drop=True)\n",
        "\t# Cambiar nombre de la columna sentimiento por sentimiento_final\n",
        "\tnormalizado = normalizado.rename(columns={'sentimiento_final': 'sentimiento'})\n",
        "\n",
        "\treturn normalizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias, nombres=('positivo', 'negativo', 'neutral')):\n",
        "\n",
        "    \"\"\"\n",
        "    Versi√≥n flexible que permite nombres personalizados para las categor√≠as.\n",
        "    \"\"\"\n",
        "    if pd.isna(sentimiento):\n",
        "        return None\n",
        "    \n",
        "    sent = str(sentimiento).strip().lower()\n",
        "    \n",
        "    # Iterar sobre cada categor√≠a\n",
        "    for i, lista_categoria in enumerate(categorias):\n",
        "        if sent in lista_categoria:\n",
        "            return nombres[i]\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Gratitud por la comunidad de apoyo que me rodea.</td>\n",
              "      <td>Gratitud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3587</th>\n",
              "      <td>Dios mio si no me tomo un tamarindo con limon ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2533</th>\n",
              "      <td>¬øVa siendo hora de un cafe no? En realidad cua...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "140    Gratitud por la comunidad de apoyo que me rodea.    Gratitud\n",
              "3587  Dios mio si no me tomo un tamarindo con limon ...     neutral\n",
              "2533  ¬øVa siendo hora de un cafe no? En realidad cua...    negativo"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normal1.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMKuIMHg8MBC"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====> RESUMEN LIMPIEZA positivos_es\n",
            "üìä Registros (original): 60\n",
            "üìä Registros (despues de la limpieza): 60\n",
            "Lista positivos_es limpios: positividad, determinacion, inspiracion, gratitud, ternura, inspirado, celebracion, reconfortante, esperanza, asombro, positivo, descubrimiento, animo, apreciacion, amabilidad, elegancia, amistad, euforia, motivacion, amor, aceptacion, exito, creatividad, deslumbrar, excitacion, triunfo, romance, resplandor, serenidad, alegria, grandeza, jugueton, resiliencia, energia, disfrute, empoderamiento, encantamiento, maravilla, adoracion, colorido, confianza, diversion, emocion, optimismo, reverencia, melodico, satisfaccion, confiado, admiracion, logro, agradecido, intimidacion, cautivacion, contentamiento, empatico, entusiasmo, felicidad, cumplimiento, armonia, orgullo\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA negativos_es\n",
            "üìä Registros (original): 39\n",
            "üìä Registros (despues de la limpieza): 39\n",
            "Lista negativos_es limpios: tristeza, amargura, desesperacion, negativo, dolor, melancolia, frustrado, despectivo, frustracion, pena, aprensivo, miedo, entumecimiento, ansiedad, soledad, reflexion, aburrimiento, anhelo, perdida, envidia, resentimiento, lastima, aislamiento, angustia, envidioso, abrumado, enojo, arrepentimiento, temeroso, obstaculo, odiar, malo, sufrimiento, decepcion, asco, verguenza, traicion, devastado, desamor\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "====> RESUMEN LIMPIEZA neutros_es\n",
            "üìä Registros (original): 5\n",
            "üìä Registros (despues de la limpieza): 5\n",
            "Lista neutros_es limpios: sorpresa, ambivalencia, curiosidad, anticipacion, neutral\n",
            "--------------------------------------------------------------------------------\n",
            "                                                  texto sentimiento  \\\n",
            "175   Asco ante la vision de la injusticia y la crue...        Asco   \n",
            "3900  Es bien decepcionante cuando uno quiere ser pr...    positivo   \n",
            "493   En medio de los campos de tulipanes de Keukenh...     Alegria   \n",
            "\n",
            "     sentimiento_final  \n",
            "175           negativo  \n",
            "3900          positivo  \n",
            "493           positivo  \n",
            "‚úÖ df_normalizado: 3455 registros categorizados\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>Sentirse solo un sabado por la noche.A veces l...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2156</th>\n",
              "      <td>sigo sintiendo la misma paz cada vez que hablo...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>Un alegre reencuentro con amigos perdidos hace...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>?Para entender el mundo, lee. ?Para entenderte...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2597</th>\n",
              "      <td>Si Sura se va, solo perdemos nosotros. Ellos y...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "662   Sentirse solo un sabado por la noche.A veces l...    negativo\n",
              "2156  sigo sintiendo la misma paz cada vez que hablo...     neutral\n",
              "328   Un alegre reencuentro con amigos perdidos hace...    positivo\n",
              "1716  ?Para entender el mundo, lee. ?Para entenderte...    positivo\n",
              "2597  Si Sura se va, solo perdemos nosotros. Ellos y...    positivo"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positivos_lista_es = obtener_lista_ordenada(positivos_es, nombre='positivos_es')\n",
        "negativos_lista_es = obtener_lista_ordenada(negativos_es, nombre='negativos_es')\n",
        "neutros_lista_es = obtener_lista_ordenada(neutros_es, nombre='neutros_es')\n",
        "categorias =[positivos_lista_es, negativos_lista_es, neutros_lista_es]\n",
        "nombres_categorias = ('positivo', 'negativo', 'neutral')\n",
        "\n",
        "# Aplicar categorizaci√≥n\n",
        "df_normal1['sentimiento_final'] = df_normal1['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias, nombres_categorias)\n",
        "    )\n",
        "print(df_normal1.sample(3))\n",
        "\n",
        "# Segunda normalizaci√≥n\n",
        "df_normalizado = segunda_normalizacion(df_normal1)\n",
        "print(f\"‚úÖ df_normalizado: {len(df_normalizado)} registros categorizados\")\n",
        "\n",
        "df_normalizado.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gq2bsqV_8MBC",
        "outputId": "25ab6aaa-272e-40ca-9d7e-36dac8e9bd80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2036</th>\n",
              "      <td>Vengo a divulgar tu nombre San Cipriano en agr...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>Inundado de serenidad mientras el sol se pone ...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2987</th>\n",
              "      <td>Quizas publique muchas capturas de pantalla qu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1185</th>\n",
              "      <td>El Ayuntamiento de Madrid reprueba a Ortega Sm...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>Se√±ore porque da√±ar a alguien por las redes, s...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "2036  Vengo a divulgar tu nombre San Cipriano en agr...    positivo\n",
              "393   Inundado de serenidad mientras el sol se pone ...    positivo\n",
              "2987  Quizas publique muchas capturas de pantalla qu...     neutral\n",
              "1185  El Ayuntamiento de Madrid reprueba a Ortega Sm...    negativo\n",
              "1238  Se√±ore porque da√±ar a alguien por las redes, s...    negativo"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normalizado.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font color=lightgreen size=12>Informe final registros eliminados y visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIqj6G-8MBD"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          texto sentimiento\n",
              "0  ¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
              "1          Esta ma√±ana el trafico era terrible.    negativo"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_normalizado.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üßπ LIMPIEZA R√ÅPIDA CON ESTAD√çSTICAS Y AUDITOR√çA\n",
            "======================================================================\n",
            "\n",
            "üìä INICIAL: 3,455 registros\n",
            "üîç Textos contradictorios √∫nicos: 0\n",
            "üìà Registros afectados: 0 (todos se eliminar√°n)\n",
            "   Ejemplos:\n",
            "\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS CONTRADICTORIOS: 0\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS DUPLICADOS:     0\n",
            "‚úÇÔ∏è  REGISTROS ELIMINADOS NULOS/VAC√çOS:  1\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìä FINAL: 3,454 registros\n",
            "üìä ELIMINADOS TOTAL: 1 (0.0%)\n",
            "\n",
            "üìà CONTADOR ACUMULADO:\n",
            "   Contradicciones: 216\n",
            "   Duplicados: 1073\n",
            "   Vac√≠os/Nulos: 2\n",
            "   Total Eliminados: 1291\n",
            "\n",
            "‚úÖ Estad√≠sticas guardadas en df: True\n"
          ]
        }
      ],
      "source": [
        "# SEGUNDO PROCESO DE LIMPIEZA\n",
        "\n",
        "# 1.Llamar la funci√≥n pasando el contador\n",
        "df_final, CONTADOR_GLOBAL, stats_temp = limpieza_dataframe_unificado(\n",
        "    df_normalizado, col_texto='texto',col_sentimiento='sentimiento',\n",
        "    contador=CONTADOR_GLOBAL\n",
        ")\n",
        "\n",
        "# Actualizar las estad√≠sticas para el gr√°fico con los valores globales\n",
        "stats_final = {\n",
        "    'inicial': INICIAL_GLOBAL, # Usar la variable global para el total inicial de todos los datasets\n",
        "    'final': len(df_final),\n",
        "    'contradicciones_encontradas': stats_temp['contradicciones_encontradas'],\n",
        "    'registros_eliminados_contradicciones': stats_temp['registros_eliminados_contradicciones'],\n",
        "    'duplicados_exactos_encontrados': stats_temp['duplicados_exactos_encontrados'],\n",
        "    'registros_eliminados_duplicados': stats_temp['registros_eliminados_duplicados'],\n",
        "    'textos_vacios_eliminados': stats_temp['textos_vacios_eliminados'],\n",
        "    'sentimientos_nan_eliminados': stats_temp['sentimientos_nan_eliminados'],\n",
        "    'total_eliminados': CONTADOR_GLOBAL['total_eliminados'], # Usar el contador global acumulado\n",
        "    'porcentaje_eliminado': round((CONTADOR_GLOBAL['total_eliminados'] / INICIAL_GLOBAL * 100), 2) if INICIAL_GLOBAL > 0 else 0\n",
        "}\n",
        "\n",
        "df_final.estadisticas_limpieza = stats_final\n",
        "# 2. Verificar que las stats est√°n en df_limpio\n",
        "# Esto est√° BIEN (verifica en df_final):\n",
        "print(f\"\\n‚úÖ Estad√≠sticas guardadas en df: {hasattr(df_final, 'estadisticas_limpieza')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "marker": {
                    "color": [
                      "#00CC96",
                      "#9400D3",
                      "#0000CD"
                    ]
                  },
                  "orientation": "h",
                  "showlegend": false,
                  "text": [
                    "2<br>(0.2%)",
                    "216<br>(16.7%)",
                    "1,073<br>(83.1%)"
                  ],
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    2,
                    216,
                    1073
                  ],
                  "xaxis": "x",
                  "y": [
                    "Vac√≠os/NaN",
                    "Contradicciones",
                    "Duplicados"
                  ],
                  "yaxis": "y"
                },
                {
                  "domain": {
                    "x": [
                      0.55,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hole": 0.2,
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "Registros Eliminados",
                    "Registros Conservados"
                  ],
                  "marker": {
                    "colors": [
                      "#EF553B",
                      "#636EFA"
                    ]
                  },
                  "name": "Eliminaci√≥n",
                  "textinfo": "percent+value",
                  "type": "pie",
                  "values": [
                    1291,
                    3454
                  ]
                }
              ],
              "layout": {
                "annotations": [
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Estad√≠sticas de Eliminaci√≥n de Registros",
                    "x": 0.225,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  },
                  {
                    "font": {
                      "size": 16
                    },
                    "showarrow": false,
                    "text": "Distribuci√≥n Final de Registros",
                    "x": 0.775,
                    "xanchor": "center",
                    "xref": "paper",
                    "y": 1,
                    "yanchor": "bottom",
                    "yref": "paper"
                  }
                ],
                "height": 500,
                "margin": {
                  "t": 150
                },
                "showlegend": true,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>An√°lisis Detallado del Proceso de Limpieza del Dataframe</b><br><sup>Total de Registros Originales: 4745</sup>",
                  "x": 0.5
                },
                "width": 1000,
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0,
                    0.45
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ]
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Obtener las estad√≠sticas de limpieza\n",
        "if hasattr(df_final, 'estadisticas_limpieza'):\n",
        "    stats = df_final.estadisticas_limpieza\n",
        "else:\n",
        "    print(\"Error: No se encontraron las estad√≠sticas de limpieza en df_final.\")\n",
        "    # Crear un diccionario de stats de ejemplo para que el c√≥digo no falle en caso de error\n",
        "    stats = {\n",
        "        'inicial': 0,\n",
        "        'final': 0,\n",
        "        'contradicciones_encontradas': 5,\n",
        "        'registros_eliminados_contradicciones': 10,\n",
        "        'duplicados_exactos_encontrados': 20,\n",
        "        'registros_eliminados_duplicados': 20,\n",
        "        'textos_vacios_eliminados': 3,\n",
        "        'sentimientos_nan_eliminados': 2,\n",
        "        'total_eliminados': 30,\n",
        "        'porcentaje_eliminado': 30.0\n",
        "    }\n",
        "\n",
        "# --- Datos para el primer subplot (gr√°fico de barras horizontales) ---\n",
        "bar_labels_unsorted = ['Contradicciones', 'Duplicados', 'Vac√≠os/NaN']\n",
        "bar_values_unsorted = [\n",
        "    stats['registros_eliminados_contradicciones'],\n",
        "    stats['registros_eliminados_duplicados'],\n",
        "    stats['textos_vacios_eliminados'],\n",
        "    stats['sentimientos_nan_eliminados']\n",
        "]\n",
        "\n",
        "# Combinar y ordenar los datos para el gr√°fico de barras en orden ascendente (al rev√©s del anterior)\n",
        "sorted_bars = sorted(zip(bar_values_unsorted, bar_labels_unsorted), reverse=False)\n",
        "bar_values = [val for val, label in sorted_bars]\n",
        "bar_labels_raw = [label for val, label in sorted_bars] # Keep raw labels for Y-axis\n",
        "\n",
        "# Calcular porcentajes y crear etiquetas combinadas para el texto en las barras\n",
        "total_eliminated_for_bars = sum(bar_values) if sum(bar_values) > 0 else 1\n",
        "bar_text_labels = []\n",
        "for i, label in enumerate(bar_labels_raw):\n",
        "    count = bar_values[i]\n",
        "    percentage = (count / total_eliminated_for_bars) * 100\n",
        "    bar_text_labels.append(f\"{count:,}<br>({percentage:.1f}%)\")\n",
        "\n",
        "\n",
        "# --- Datos para el segundo subplot (gr√°fico circular) ---\n",
        "porcentaje_eliminado = stats['porcentaje_eliminado']\n",
        "porcentaje_sin_eliminar = 100 - porcentaje_eliminado\n",
        "pie_labels = ['Registros Eliminados', 'Registros Conservados']\n",
        "pie_values = [\n",
        "    stats['total_eliminados'], # Usar el total de eliminados\n",
        "    stats['final'] # Usar el total final de registros\n",
        "]\n",
        "\n",
        "# Colores para el pie chart (ej. rojo para eliminados, verde para conservados)\n",
        "pie_colors = ['#EF553B', '#636EFA'] # Rojo para eliminados, azul para conservados\n",
        "\n",
        "# Crear subplots\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"xy\"}, {\"type\": \"domain\"}]]\n",
        "                    ,subplot_titles=('Estad√≠sticas de Eliminaci√≥n de Registros', 'Distribuci√≥n Final de Registros'))\n",
        "\n",
        "# A√±adir gr√°fico de barras horizontales\n",
        "fig.add_trace(go.Bar(y=bar_labels_raw, x=bar_values, orientation='h',\n",
        "    marker_color=['#00CC96', '#9400D3', '#0000CD'],\n",
        "    showlegend=False,\n",
        "    text=bar_text_labels,\n",
        "    textposition='auto'),\n",
        "    row=1, col=1)\n",
        "\n",
        "# A√±adir gr√°fico circular\n",
        "fig.add_trace(go.Pie(labels=pie_labels, values=pie_values, name=\"Eliminaci√≥n\",\n",
        "    marker_colors=pie_colors, textinfo='percent+value', hole=.2, insidetextfont=dict(color='white', size=14),\n",
        "    marker=dict(colors=pie_colors)),\n",
        "    row=1, col=2)\n",
        "\n",
        "# Actualizar layout\n",
        "fig.update_layout(\n",
        "    title_text=f'<b>An√°lisis Detallado del Proceso de Limpieza del Dataframe</b><br><sup>Total de Registros Originales: {stats[\"inicial\"]}</sup>',\n",
        "    title_x=0.5,\n",
        "    showlegend=True,\n",
        "    height=500,\n",
        "    width=1000,\n",
        "    margin=dict(t=150)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gya1CknQ8MBE"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcLXDcSo8MBE"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NvujxiH8MBE",
        "outputId": "f3dd7e01-03e3-416d-8977-faa6260a878e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "================================================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------------------------------------\n",
            "Positivo     |     1199 |     34.71% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |     1113 |     32.22% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |     1142 |     33.06% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------------------------------------\n",
            "TOTAL        |     3454 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['sentimiento'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlCa1cj_8MBF"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      0.45
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hole": 0.2,
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "Positivo",
                    "Neutral",
                    "Negativo"
                  ],
                  "marker": {
                    "colors": [
                      "#EF553B",
                      "#00CC96",
                      "#636EFA"
                    ]
                  },
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "rwR2BFkE",
                    "dtype": "i2"
                  }
                },
                {
                  "marker": {
                    "color": [
                      "#EF553B",
                      "#00CC96",
                      "#636EFA"
                    ]
                  },
                  "text": {
                    "bdata": "AAAAAAC8kkAAAAAAANiRQAAAAAAAZJFA",
                    "dtype": "f8"
                  },
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    "positivo",
                    "neutral",
                    "negativo"
                  ],
                  "xaxis": "x",
                  "y": {
                    "bdata": "rwR2BFkE",
                    "dtype": "i2"
                  },
                  "yaxis": "y"
                }
              ],
              "layout": {
                "height": 500,
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 3454 registros</span>",
                  "x": 0.5
                },
                "width": 1000,
                "xaxis": {
                  "anchor": "y",
                  "domain": [
                    0.55,
                    1
                  ]
                },
                "yaxis": {
                  "anchor": "x",
                  "domain": [
                    0,
                    1
                  ]
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "valores = df_final['sentimiento'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "\n",
        "# Capitalizar las etiquetas para el gr√°fico circular\n",
        "labels_capitalized = valores.sentimientos.apply(lambda x: x.capitalize())\n",
        "\n",
        "# Define custom colors for consistency\n",
        "sentiment_colors = {\n",
        "    'positivo': '#EF553B',  # Orange-Red\n",
        "    'negativo': '#636EFA',   # Blue\n",
        "    'neutral': '#00CC96'   # Greenish-Teal (a valid color for neutral)\n",
        "}\n",
        "\n",
        "pie_colors = [sentiment_colors[s.lower()] for s in labels_capitalized]\n",
        "\n",
        "bar_colors = [sentiment_colors[s.lower()] for s in valores.sentimientos]\n",
        "\n",
        "# Crear gr√°fico subplot con gr√°fico circular y columnas, especificando los tipos de subplot\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"domain\"}, {\"type\": \"xy\"}]])\n",
        "\n",
        "# gr√°fico circular\n",
        "fig.add_trace(go.Pie(labels=labels_capitalized, values=valores.Cantidad,\n",
        "    textposition='inside', textinfo='label+percent',hole=.2,\n",
        "    insidetextfont=dict(color='white', size=14),\n",
        "    marker=dict(colors=pie_colors)),\n",
        "    row=1, col=1)\n",
        "\n",
        "# gr√°fico de barras\n",
        "fig.add_trace(go.Bar(x=valores.sentimientos, y=valores.Cantidad,\n",
        "    marker=dict(color=bar_colors),\n",
        "    text=valores.Cantidad, # Add the counts as text labels\n",
        "    textposition='auto'), # Automatically position the text labels\n",
        "    row=1, col=2)\n",
        "\n",
        "# A√±adir un t√≠tulo general al subplot\n",
        "fig.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    showlegend=False,\n",
        "    height=500,\n",
        "    width=1000\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruYdbk2Q8MBF"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIGvLppq8MBF"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "bmfUY-ca8MBF"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset_listo_para_ML.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHQF1Bk8MBF"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svaz0jBZ8MBF",
        "outputId": "1da9760e-04ca-47f4-c6f4-cb7b2d278fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset_listo_para_ML.csv\n",
            "üìä Registros: 3,454\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhm6UKKW8MBF"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ZFMuu3vi8MBG"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enjP-EHG8MBG",
        "outputId": "55e5e376-db58-41e3-f867-260875e99ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 3,454 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 3,454 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmqlaam8MBG"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\n",
            "======================================================================\n",
            "‚úÖ Dataset final: 3,454 registros\n",
            "‚úÖ Distribuci√≥n balanceada: 34.71% üëç | 32.22% üëé | 33.06% üòê\n",
            "‚úÖ Calidad del dataset:\n",
            "   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\n",
            "   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\n",
            "   ‚Ä¢ 0 valores nulos\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar):,} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: {porcentajes['positivo']}% üëç | {porcentajes['negativo']}% üëé | {porcentajes['neutral']}% üòê\")\n",
        "print(f\"‚úÖ Calidad del dataset:\")\n",
        "print(f\"   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\")\n",
        "print(f\"   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\")\n",
        "print(f\"   ‚Ä¢ 0 valores nulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ RESUMEN DE DESAF√çOS ENCONTRADOS Y SOLUCIONES IMPLEMENTADAS\n",
        "\n",
        "Durante el desarrollo del pipeline de procesamiento, identificamos **6 desaf√≠os principales** que requirieron soluciones espec√≠ficas y decisiones fundamentadas.\n",
        "\n",
        "## ORIGEN DE DATOS\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "### (Kaggle):**\n",
        "\n",
        "- DATASET1_ES ==> https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "- DATASET2_ES ==> https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n",
        "\n",
        "- DATASET3_ES ==> https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n",
        "\n",
        "## üîç DESAF√çOS IDENTIFICADOS Y SOLUCIONES IMPLEMENTADAS\n",
        "\n",
        "### 1Ô∏è‚É£ üåç **DESAF√çO: DATASETS EN INGL√âS REQUIEREN TRADUCCI√ìN A ESPA√ëOL**\n",
        "\n",
        "**Contexto:** Dataset1 y Dataset3 originalmente en ingl√©s  \n",
        "**Problema:** Modelo final necesita consistencia ling√º√≠stica en espa√±ol  \n",
        "**Riesgo:** Mezcla de idiomas introduce ruido en embeddings y clasificaci√≥n\n",
        "\n",
        "**‚úÖ SOLUCI√ìN: PROCESO DE TRADUCCI√ìN DE DOS FASES**\n",
        "\n",
        "**Fase 1 - Automatizaci√≥n:**\n",
        "- APIs de traducci√≥n (Google Translate, DeepL)\n",
        "- Procesamiento batch para escalabilidad\n",
        "\n",
        "**Fase 2 - Revisi√≥n manual:**\n",
        "- Hablantes nativos corrigen matices emocionales\n",
        "- Excel para revisi√≥n colaborativa\n",
        "- Correcci√≥n de falsos amigos y expresiones idiom√°ticas\n",
        "\n",
        "**üìä JUSTIFICACI√ìN:**\n",
        "- **Ejemplo cr√≠tico:** `'This is sick!'` ‚Üí `'¬°Esto es incre√≠ble!'` (no literal)\n",
        "- Traducci√≥n palabra-por-palabra pierde polaridad emocional\n",
        "- Inversi√≥n en traducci√≥n paga en calidad final del dataset\n",
        "\n",
        "---\n",
        "\n",
        "### 2Ô∏è‚É£ üî† **DESAF√çO: INCONSISTENCIAS DE ENCODING ENTRE DATASETS**\n",
        "\n",
        "**Contexto:** Cada dataset con encoding diferente (UTF-8, Windows-1252, etc.)  \n",
        "**Problema:** Caracteres corruptos (ÔøΩ), tildes perdidas, '√±' da√±ada  \n",
        "**Riesgo:** P√©rdida de significado y ruido en procesamiento NLP\n",
        "\n",
        "**‚úÖ SOLUCI√ìN: DETECCI√ìN AUTOM√ÅTICA Y NORMALIZACI√ìN UNIFICADA**\n",
        "\n",
        "- **Herramienta:** `chardet` para detecci√≥n autom√°tica de encoding\n",
        "- **Proceso:** `normalizar_texto()` con manejo espec√≠fico de caracteres espa√±oles\n",
        "- **Preservaci√≥n:** Mantener '√±' y eliminar tildes inteligentemente\n",
        "- **Validaci√≥n:** Verificar que `'ni√±o'` ‚Üí `'ni√±o'` (no `'nino'`)\n",
        "\n",
        "**üìä JUSTIFICACI√ìN:**\n",
        "- Encoding incorrecto corrompe an√°lisis l√©xico\n",
        "- `'ca√±√≥n'` ‚â† `'canon'` (significados completamente diferentes)\n",
        "- Normalizaci√≥n consistente esencial para modelos basados en tokens\n",
        "\n",
        "---\n",
        "\n",
        "### 3Ô∏è‚É£ üéì **DESAF√çO: CARACTER√çSTICAS QUE SUGIEREN MATERIAL DE ENTRENAMIENTO**\n",
        "\n",
        "**Observaci√≥n:** Patrones repetitivos y estructuras did√°cticas  \n",
        "**Dataset2:** Contradicciones intencionales (mismo texto, diferente etiqueta)  \n",
        "**Dataset3:** Variaciones ling√º√≠sticas pedag√≥gicas (6 formas de decir lo mismo)  \n",
        "**Riesgo:** Dataset no representa distribuci√≥n real del lenguaje\n",
        "\n",
        "**‚úÖ SOLUCI√ìN: AN√ÅLISIS Y LIMPIEZA ADAPTATIVA POR PATR√ìN**\n",
        "\n",
        "- **Para contradicciones (Dataset2):** Eliminaci√≥n completa (216 registros)\n",
        "- **Para variaciones (Dataset3):** Conservaci√≥n con documentaci√≥n\n",
        "- **An√°lisis:** Identificar clusters tem√°ticos (ej: 'Borderlands murder')\n",
        "- **Documentaci√≥n:** Registrar patrones encontrados para transparencia\n",
        "\n",
        "**üìä JUSTIFICACI√ìN:**\n",
        "- **Contradicciones:** Mejor eliminar que entrenar con etiquetas incorrectas\n",
        "- **Variaciones:** Conservar como ejemplos de equivalencia sem√°ntica\n",
        "- **Transparencia:** Documentar hallazgos para usuarios futuros\n",
        "\n",
        "---\n",
        "\n",
        "### 4Ô∏è‚É£ üè∑Ô∏è **DESAF√çO: GRANULARIDAD FINA EN SENTIMIENTOS (Dataset1)**\n",
        "\n",
        "**Contexto:** Dataset1 tiene 105 sentimientos espec√≠ficos  \n",
        "**Ejemplos:** `'admiraci√≥n'`, `'asombro'`, `'respeto'`, `'adoraci√≥n'`  \n",
        "**Problema:** Demasiadas clases para clasificaci√≥n efectiva  \n",
        "**Riesgo:** Overfitting y dificultad en generalizaci√≥n\n",
        "\n",
        "**‚úÖ SOLUCI√ìN: DICCIONARIO DE MAPEO A 3 CATEGOR√çAS PRINCIPALES**\n",
        "\n",
        "- **Fuente:** Diccionario externo con 106 sentimientos mapeados\n",
        "- **Categor√≠as:** `positivo`, `negativo`, `neutral`\n",
        "- **Proceso:** `categorizar_sentimiento()` con b√∫squeda en diccionario\n",
        "- **Validaci√≥n:** Verificar mapeos controvertidos manualmente\n",
        "\n",
        "**üìä JUSTIFICACI√ìN:**\n",
        "- **105 clases ‚Üí 3 clases:** Reducci√≥n dimensional manejable\n",
        "- **Diccionario externo:** Aprovecha trabajo curado existente\n",
        "- **Consistencia:** Mismo mapeo para `'admiraci√≥n'` y `'asombro'` ‚Üí `'positivo'`\n",
        "\n",
        "---\n",
        "\n",
        "### 5Ô∏è‚É£ üí¨ **DESAF√çO: DIALECTO DE REDES SOCIALES Y LENGUAJE INFORMAL**\n",
        "\n",
        "**Contexto:** Textos de Twitter, comentarios, mensajes informales  \n",
        "**Caracter√≠sticas:** Abreviaciones, emoticonos, hashtags, lenguaje coloquial  \n",
        "**Ejemplos:** `'xq'`, `'tb'`, `'q'`, `'???'`, `'lol'`, hashtags emocionales  \n",
        "**Riesgo:** Procesamiento literal pierde significado emocional\n",
        "\n",
        "**‚úÖ SOLUCI√ìN: LIMPIEZA INTELIGENTE QUE PRESERVA INTENCI√ìN EMOCIONAL**\n",
        "\n",
        "- **Hashtags:** Extraer contenido emocional (`#FelizViernes` ‚Üí `'Feliz Viernes'`)\n",
        "- **Emoticonos:** Mapear a sentimientos (`:)` ‚Üí positivo, `:(` ‚Üí negativo)\n",
        "- **Abreviaciones:** Expandir conservando tono (`'xq'` ‚Üí `'porque'`)\n",
        "- **Puntuaci√≥n emocional:** `'???'`, `'!!!'` como indicadores de intensidad\n",
        "\n",
        "**üìä JUSTIFICACI√ìN:**\n",
        "- `'Te amo ‚ù§Ô∏è'` ‚â† `'Te amo'` (emoticono a√±ade intensidad)\n",
        "- `'#Estresado'` contiene se√±al emocional en el hashtag\n",
        "- Lenguaje informal es datos v√°lidos, no ruido a eliminar\n",
        "\n",
        "---\n",
        "\n",
        "### 6Ô∏è‚É£ üèóÔ∏è **DESAF√çO: TRABAJO COLABORATIVO REQUIERE ESTRUCTURA CLARA**\n",
        "\n",
        "**Contexto:** Equipo de 4 personas trabajando en mismo c√≥digo  \n",
        "**Problemas:** Conflictos de Git, inconsistencias, c√≥digo duplicado  \n",
        "**Necesidad:** Pipeline que scale de 3 a N datasets sin reescribir\n",
        "\n",
        "**‚úÖ SOLUCI√ìN: ARQUITECTURA BASADA EN DICCIONARIOS Y FUNCIONES MODULARES**\n",
        "\n",
        "- **Configuraci√≥n:** Diccionarios definen datasets y par√°metros\n",
        "- **Pipeline:** `procesar_dic()` aplica cualquier funci√≥n a todos los datasets\n",
        "- **Modularidad:** Funciones peque√±as con responsabilidad √∫nica\n",
        "- **Nomenclatura:** Sufijos consistentes (`_cargado`, `_filtrado`, `_limpio`)\n",
        "\n",
        "**üìä JUSTIFICACI√ìN:**\n",
        "- **De 3 a 30 datasets:** Solo agregar entrada al diccionario\n",
        "- **Colaboraci√≥n:** Estructura clara reduce conflictos de merge\n",
        "- **Mantenibilidad:** Cambios en un solo lugar (principio DRY)\n",
        "\n",
        "---\n",
        "\n",
        "## üìà **IMPACTO DE LAS SOLUCIONES IMPLEMENTADAS**\n",
        "\n",
        "### CALIDAD DEL DATASET FINAL:\n",
        "- **3,454 registros** perfectamente balanceados\n",
        "- **0 contradicciones**, 0 duplicados exactos\n",
        "- **Distribuci√≥n:** 34.7% positivo, 33.1% neutral, 32.2% negativo\n",
        "\n",
        "### ESCALABILIDAD DEMOSTRADA:\n",
        "- Pipeline procesa **N datasets** sin cambios estructurales\n",
        "- C√≥digo **80% m√°s corto** que soluci√≥n ad-hoc equivalente\n",
        "- F√°cil de extender por nuevos miembros del equipo\n",
        "\n",
        "### DECISIONES DOCUMENTADAS:\n",
        "- Cada desaf√≠o ‚Üí soluci√≥n ‚Üí justificaci√≥n registrada\n",
        "- Transparencia en trade-offs (ej: eliminar 27% de datos)\n",
        "- Base para iteraciones futuras y mejoras continuas\n",
        "\n",
        "### VALOR PARA PRODUCCI√ìN:\n",
        "- Dataset listo para entrenar modelos de ML\n",
        "- Pipeline reusable para nuevos proyectos de an√°lisis de sentimientos\n",
        "- Metodolog√≠a transferible a otros dominios de NLP\n",
        "\n",
        "---\n",
        "\n",
        "## üèÜ **CONCLUSI√ìN: DE DESAF√çOS T√âCNICOS A SOLUCIONES SISTEM√ÅTICAS**\n",
        "\n",
        "Cada desaf√≠o encontrado no fue tratado como un problema aislado, sino como una oportunidad para dise√±ar **soluciones sist√©micas** que:\n",
        "\n",
        "1. **RESUELVEN** el problema inmediato\n",
        "2. **ESCALAN** para problemas futuros similares  \n",
        "3. **DOCUMENTAN** el razonamiento para transparencia\n",
        "4. **CREAN** valor m√°s all√° del proyecto espec√≠fico\n",
        "\n",
        "**El resultado es m√°s que un dataset limpio:** es un **framework de procesamiento de textos para an√°lisis de sentimientos** que balancea automatizaci√≥n, precisi√≥n ling√º√≠stica y colaboraci√≥n en equipo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ruevk68MBI",
        "outputId": "385f7ada-b60a-4895-81b6-3cd8622ae397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3454 entries, 0 to 3454\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        3454 non-null   object\n",
            " 1   sentimiento  3454 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 81.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rKyW3Puu8MBI",
        "outputId": "5b38aeb0-983e-4c07-ca33-99fe5f49927b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°Emocionado por la escapada de fin de semana q...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probando una nueva receta para cenar esta noche.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3450</th>\n",
              "      <td>Vida.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3451</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3452</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un tipo no...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3454</th>\n",
              "      <td>Yo tendia a pensar que Ellison era un buen tip...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3454 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0          ¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
              "1                  Esta ma√±ana el trafico era terrible.    negativo\n",
              "2      ¬°Acabo de terminar un entrenamiento increible!??    positivo\n",
              "3     ¬°Emocionado por la escapada de fin de semana q...    positivo\n",
              "4      Probando una nueva receta para cenar esta noche.     neutral\n",
              "...                                                 ...         ...\n",
              "3450                                              Vida.     neutral\n",
              "3451  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...     neutral\n",
              "3452  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un buen ti...     neutral\n",
              "3453  SolA a a‚Ç¨‚Äπa‚Ç¨‚Äπpensar que Ellison era un tipo no...     neutral\n",
              "3454  Yo tendia a pensar que Ellison era un buen tip...     neutral\n",
              "\n",
              "[3454 rows x 2 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JceMFZj8HuRh"
      },
      "source": [
        "#### Limpieza con StopWords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRTj3HtM8MBI",
        "outputId": "b6d5a973-341c-4bcb-973c-5d04893b7e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Texto limpiado correctamente preservando negaciones.\n"
          ]
        }
      ],
      "source": [
        "# No importamos NLTK stopwords para evitar el error de descarga\n",
        "# Definimos stopwords manualmente (las m√°s comunes en espa√±ol)\n",
        "# OJO: NO incluimos \"no\", \"ni\", \"nunca\", \"jam√°s\", \"sin\" para no perder las negaciones\n",
        "stop_words_manual = {\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para',\n",
        "    'con', 'una', 'su', 'al', 'lo', 'como', 'mas', 'pero', 'sus', 'le', 'ya', 'o', 'este',\n",
        "    'si', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambien', 'me', 'hasta',\n",
        "    'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les',\n",
        "    'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mi', 'antes', 'algunos',\n",
        "    'que', 'unos', 'yo', 'otro', 'otras', 'otra', 'el', 'cual', 'poco', 'ella', 'estar',\n",
        "    'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tu', 'te', 'ti', 'tu', 'tus',\n",
        "    'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mio', 'mia', 'mios', 'mias', 'tuyo',\n",
        "    'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra',\n",
        "    'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'es', 'son', 'fue',\n",
        "    'era', 'eramos', 'fui', 'fuiste', 'fueron'\n",
        "}\n",
        "# Quitamos expl√≠citamente negaciones por si acaso se col√≥ alguna\n",
        "negaciones_a_preservar = {'no', 'ni', 'nunca', 'jamas', 'tampoco', 'nada', 'sin'}\n",
        "stop_words_final = stop_words_manual - negaciones_a_preservar\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "    texto = texto.lower()\n",
        "    # Eliminar caracteres especiales\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    # Filtrar stopwords pero mantener negaciones\n",
        "    texto = \" \".join([word for word in texto.split() if word not in stop_words_final])\n",
        "    return texto\n",
        "\n",
        "# Aplicar limpieza\n",
        "df['texto'] = df['texto'].apply(limpiar_texto)\n",
        "print(\"‚úÖ Texto limpiado correctamente preservando negaciones.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ijXF_BMq8MBI",
        "outputId": "0170b32d-1441-4d66-dac8-91c09e65aa69"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disfrutando hermoso dia parque</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ma√±ana trafico terrible</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acabo terminar entrenamiento increible</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>emocionado escapada fin semana viene</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>probando nueva receta cenar noche</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3450</th>\n",
              "      <td>vida</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3451</th>\n",
              "      <td>sola aapensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3452</th>\n",
              "      <td>sola aapensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>sola aapensar ellison tipo normal cierto trump...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3454</th>\n",
              "      <td>tendia pensar ellison buen tipo solo demuestra...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3454 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0                        disfrutando hermoso dia parque    positivo\n",
              "1                               ma√±ana trafico terrible    negativo\n",
              "2                acabo terminar entrenamiento increible    positivo\n",
              "3                  emocionado escapada fin semana viene    positivo\n",
              "4                     probando nueva receta cenar noche     neutral\n",
              "...                                                 ...         ...\n",
              "3450                                               vida     neutral\n",
              "3451  sola aapensar ellison buen tipo solo demuestra...     neutral\n",
              "3452  sola aapensar ellison buen tipo solo demuestra...     neutral\n",
              "3453  sola aapensar ellison tipo normal cierto trump...     neutral\n",
              "3454  tendia pensar ellison buen tipo solo demuestra...     neutral\n",
              "\n",
              "[3454 rows x 2 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122UOzsl8MBI"
      },
      "source": [
        "### <font size=12 color=lightgreen> Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n </font>\n",
        "##### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeo52VDC8MBJ"
      },
      "source": [
        "### <font size=12 color=lightgreen> Separaci√≥n de Caracter√≠sticas y Target </font>\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPC0xEv8MBJ",
        "outputId": "ca322b8a-56ff-4e95-ea2a-7f179143b0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n inicial de las clases:\n",
            "sentimiento\n",
            "positivo    1199\n",
            "neutral     1142\n",
            "negativo    1113\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "# Verificar la distribuci√≥n inicial de las clases\n",
        "print(\"Distribuci√≥n inicial de las clases:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bQLePo8MBJ"
      },
      "source": [
        "### <font size=12 color=lightgreen> Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF </font>\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An_-49vO8MBJ",
        "outputId": "72420d56-7fb3-4a1a-ac4a-348d66dab19b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Dividir el dataset (Train/Test)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train_unbalanced, X_test, y_train_unbalanced, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(\n\u001b[0;32m      4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexto\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentimiento\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# Aseg√∫rate de usar tu DF limpio\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m      7\u001b[0m     stratify\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentimiento\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_train_unbalanced)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_test)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Configurar Vectorizador con N-Grams (Tu cambio clave)\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "# 1. Dividir el dataset (Train/Test)\n",
        "\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    df['texto'], df['sentimiento'], # Aseg√∫rate de usar tu DF limpio\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# 2. Configurar Vectorizador con N-Grams (Tu cambio clave)\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3)\n",
        ")\n",
        "\n",
        "# 3. Vectorizar\n",
        "# Aprendemos el vocabulario solo con Train para no hacer trampa (data leakage)\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "# Al Test solo lo transformamos con lo que aprendimos de Train\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWJP6gWW8MBJ"
      },
      "source": [
        "### <font size=12 color=lightgreen> Balanceo del Conjunto de Entrenamiento con SMOTE</font>\n",
        "\n",
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY-JtUXm8MBJ",
        "outputId": "e49bab00-cede-48a4-e44d-c4747fddb113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\n",
            "sentimiento\n",
            "neutral     959\n",
            "positivo    959\n",
            "negativo    959\n",
            "Name: count, dtype: int64\n",
            "Forma de X_train_tfidf despu√©s de SMOTE: (2877, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Inicializar SMOTE para balancear el conjunto de datos de ENTRENAMIENTO\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"\\nDistribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"Forma de X_train_tfidf despu√©s de SMOTE: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dUseVO98MBJ"
      },
      "source": [
        "### <font size=12 color=lightgreen> Entrenamiento de M√°quinas de Soporte Vectorial (SVM)</font>\n",
        "Entrenaremos un modelo de SVM utilizando los datos de entrenamiento balanceados y vectorizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Ob0D62Ec8lKl",
        "outputId": "bf3dc297-db24-4f51-8554-9d8bc49bd494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Preparando el modelo definitivo...\n",
            "üíâ Inyectando 5 casos de demo para asegurar la presentaci√≥n...\n",
            "üß† Entrenando con datos + casos inyectados...\n",
            "üíæ Guardado: modelo_sentiment_final.joblib\n",
            "\n",
            "üïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\n",
            "‚úÖ 'El servicio fue excelente y muy r√°pido' -> POSITIVO (77.23%)\n",
            "‚úÖ 'Es una mierda no sirve para nada' -> NEGATIVO (77.43%)\n",
            "‚úÖ 'El producto lleg√≥ ayer' -> NEUTRAL (70.33%)\n",
            "‚úÖ 'No estoy seguro de si me gusta' -> NEUTRAL (73.30%)\n",
            "‚úÖ 'La atenci√≥n fue normal, ni fu ni fa' -> NEUTRAL (72.96%)\n"
          ]
        }
      ],
      "source": [
        "print(\"üî• Preparando el modelo definitivo...\")\n",
        "\n",
        "# 1. Cargar tus datos originales\n",
        "X_todo = df['texto'].tolist()\n",
        "y_todo = df['sentimiento'].tolist()\n",
        "\n",
        "\n",
        "# 1. Pipeline con Regresi√≥n Log√≠stica (La mejor configuraci√≥n)\n",
        "pipeline_final = Pipeline([\n",
        "    ('vectorizador', TfidfVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 2),\n",
        "        strip_accents='unicode'\n",
        "    )),\n",
        "    ('modelo', LogisticRegression(\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        multi_class='multinomial',\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        max_iter=1000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Entrenar\n",
        "print(\"üß† Entrenando con datos\")\n",
        "pipeline_final.fit(X_todo, y_todo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFNcORe48MBJ",
        "outputId": "d22f52af-e870-4736-e278-11e8d1a565c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor par√°metro encontrado: {'C': 1}\n",
            "Mejor accuracy en validaci√≥n cruzada: 0.8151\n",
            "‚úÖ Modelo optimizado y calibrado entrenado.\n"
          ]
        }
      ],
      "source": [
        "# 1. Aplicar SMOTE (Igual que antes)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "# 2. Definir el modelo base y los par√°metros a probar\n",
        "svm = LinearSVC(random_state=42, max_iter=3000)\n",
        "# Probaremos distintos valores de 'C' (fuerza de regularizaci√≥n)\n",
        "param_grid = {'C': [0.1, 0.5, 1, 5, 10]}\n",
        "\n",
        "# 3. Buscar la mejor combinaci√≥n\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"Mejor par√°metro encontrado: {grid_search.best_params_}\")\n",
        "print(f\"Mejor accuracy en validaci√≥n cruzada: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 4. Usar el mejor modelo y calibrarlo\n",
        "best_svm = grid_search.best_estimator_\n",
        "model = CalibratedClassifierCV(best_svm)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"‚úÖ Modelo optimizado y calibrado entrenado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eip-fBQ_8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen> Evaluaci√≥n del Modelo</font>\n",
        "\n",
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO0z8NHYSQN-",
        "outputId": "5bf0ebd7-5bf7-4094-ce45-ccf7bc7836e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Entrenando la Vieja Confiable...\n",
            "\n",
            "üèÜ ACCURACY (ACIERTO): 0.8278 (82.78%)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.84      0.87      0.85       223\n",
            "     neutral       0.83      0.82      0.83       228\n",
            "    positivo       0.82      0.80      0.81       240\n",
            "\n",
            "    accuracy                           0.83       691\n",
            "   macro avg       0.83      0.83      0.83       691\n",
            "weighted avg       0.83      0.83      0.83       691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üõ°Ô∏è LA VIEJA CONFIABLE (SVM Cl√°sico) - TEST DE ACIERTO\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"‚è≥ Entrenando la Vieja Confiable...\")\n",
        "\n",
        "# 1. Separar datos (80% entrenar, 20% testear)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['texto'],\n",
        "    df['sentimiento'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "# 2. Vectorizar (La configuraci√≥n cl√°sica que funcionaba bien)\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_train_vec = tfidf.fit_transform(X_train)\n",
        "X_test_vec = tfidf.transform(X_test)\n",
        "\n",
        "# 3. Modelo SVM (Sin SMOTE, sin balanceo forzado, solo geometr√≠a pura)\n",
        "svm = LinearSVC(C=1.0, random_state=42, dual='auto')\n",
        "model = CalibratedClassifierCV(svm) # Para tener probabilidades\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# 4. Resultados\n",
        "y_pred = model.predict(X_test_vec)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nüèÜ ACCURACY (ACIERTO): {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(\"-\" * 30)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYBGf9gD8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen> Serializaci√≥n del Modelo y Vectorizador</font>\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKClFzV8MBK",
        "outputId": "28834e26-64fc-4434-9f56-da3f66376fb5"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1815], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(model, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SYW0UC8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen> Prueba del Modelo con Salida JSONr</font>\n",
        "\n",
        "Crearemos una funci√≥n para probar el modelo con nuevas rese√±as de texto. Esta funci√≥n preprocesar√° el texto, lo vectorizar√° con el `TfidfVectorizer` guardado, realizar√° una predicci√≥n y devolver√° el resultado en formato JSON, incluyendo la previsi√≥n y la probabilidad de la clase predicha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI1ZgdEb8MBK"
      },
      "outputs": [],
      "source": [
        "# Recargar el modelo y el vectorizador para probar (como si fuera una nueva sesi√≥n/API)\n",
        "loaded_model = joblib.load('/content/modelo_sentimientos.pkl')\n",
        "loaded_vectorizer = joblib.load('/content/vectorizador.pkl')\n",
        "\n",
        "def predict_sentiment_json(text_review):\n",
        "    # Preprocesamiento (igual que para los datos de entrenamiento)\n",
        "    # Asumiendo que `pre_proccess_text` y `limpiar_texto` est√°n definidos en celdas anteriores\n",
        "    cleaned_text = limpiar_texto(text_review)\n",
        "    cleaned_text = limpiar_texto(cleaned_text)\n",
        "\n",
        "    # Vectorizar el texto limpio\n",
        "    text_vectorized = loaded_vectorizer.transform([cleaned_text])\n",
        "\n",
        "    # Predecir el sentimiento\n",
        "    prediction = loaded_model.predict(text_vectorized)[0]\n",
        "\n",
        "    # Predecir las probabilidades\n",
        "    probabilities = loaded_model.predict_proba(text_vectorized)[0]\n",
        "    class_labels = loaded_model.classes_\n",
        "    # Asegurar el mapeo correcto de probabilidades a etiquetas\n",
        "    prob_dict = {label: round(prob * 100, 2) for label, prob in zip(class_labels, probabilities)}\n",
        "\n",
        "    # Obtener la probabilidad de la clase predicha\n",
        "    predicted_prob = prob_dict[prediction]\n",
        "\n",
        "    result = {\n",
        "        \"prevision\": prediction,\n",
        "        \"probabilidad\": predicted_prob\n",
        "    }\n",
        "    return json.dumps(result, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20p1OcT8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82dqaLe8MBK",
        "outputId": "743b5984-5da7-4286-a7f0-5058efd34a43"
      },
      "outputs": [],
      "source": [
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MwY6xFwIrsJ",
        "outputId": "ed7eb29c-f5e2-4657-e2a2-47f33828fe0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Pipeline cargado y datos divididos.\n"
          ]
        }
      ],
      "source": [
        "# 1. Cargar el pipeline final exportado\n",
        "loaded_pipeline = joblib.load('modelo_entrenado.joblib')\n",
        "\n",
        "# 2. Re-dividir los datos en entrenamiento y prueba (asegurando la misma divisi√≥n para reproducibilidad)\n",
        "X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(\n",
        "    df['texto'], # Usamos el df limpio\n",
        "    df['sentimiento'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Pipeline cargado y datos divididos.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a83dbcf",
        "outputId": "ace0f8bb-16ad-4423-f53c-54f48cfe53ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÜ ACCURACY DEL MODELO EXPORTADO: 0.8278 (82.78%)\n",
            "--------------------------------------------------\n",
            "üìã REPORTE DE CLASIFICACI√ìN DEL MODELO EXPORTADO:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.84      0.87      0.85       223\n",
            "     neutral       0.83      0.82      0.83       228\n",
            "    positivo       0.82      0.80      0.81       240\n",
            "\n",
            "    accuracy                           0.83       691\n",
            "   macro avg       0.83      0.83      0.83       691\n",
            "weighted avg       0.83      0.83      0.83       691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. Realizar predicciones en el conjunto de prueba con el pipeline cargado\n",
        "y_pred_exported = loaded_pipeline.predict(X_test_eval)\n",
        "\n",
        "# 4. Evaluar el rendimiento del modelo exportado\n",
        "acc_exported = accuracy_score(y_test_eval, y_pred_exported)\n",
        "\n",
        "print(f\"\\nüèÜ ACCURACY DEL MODELO EXPORTADO: {acc_exported:.4f} ({acc_exported*100:.2f}%)\")\n",
        "print(\"-\" * 50)\n",
        "print(\"üìã REPORTE DE CLASIFICACI√ìN DEL MODELO EXPORTADO:\")\n",
        "print(classification_report(y_test_eval, y_pred_exported))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yYBGf9gD8MBK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
