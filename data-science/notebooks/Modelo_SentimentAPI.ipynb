{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import uvicorn\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "from io import StringIO\n",
        "import urllib.response\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de los datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "yOwHw3xtYJEg"
      },
      "outputs": [],
      "source": [
        "def importar_dataset(url):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL detectando encoding autom√°ticamente.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Descargar contenido una sola vez\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "\n",
        "        # 2. Detectar encoding\n",
        "        result = chardet.detect(content)\n",
        "        encoding = result['encoding']\n",
        "        print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "\n",
        "        # 3. Decodificar y cargar en DataFrame\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        data = pd.read_csv(StringIO(decoded_content), sep=';')\n",
        "\n",
        "        print(\"‚úÖ Archivo cargado correctamente\")\n",
        "        print(f\"üìä Tama√±o del dataset: {data.shape}\")\n",
        "        print(\"\\nüîç Muestra aleatoria (3 registros):\")\n",
        "        print(data.sample(3))\n",
        "\n",
        "        return data\n",
        "\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e}\")\n",
        "        return None\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ùå Error al parsear CSV: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZW5B7jk5-x"
      },
      "source": [
        "#### **Dataset1: sentimentdataset_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWgPb0VhYeKT",
        "outputId": "80e6ac42-1fda-4070-d08e-77bead709466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 72.97%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (732, 15)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "     Unnamed: 0.1  Unnamed: 0  \\\n",
            "590            57          59   \n",
            "481             8           8   \n",
            "547           367         371   \n",
            "\n",
            "                                                  Text  Sentiment  \\\n",
            "590  Pura felicidad: ¬°celebrar el logro de un ser q...  Felicidad   \n",
            "481  Las discusiones pol√≠ticas se intensifican en l...   Negativo   \n",
            "547  Orgullo de lograr un hito personal en la progr...    Orgullo   \n",
            "\n",
            "            Timestamp            User   Platform                 Hashtags  \\\n",
            "590  13-02-2023 10:00     ProudFriend  Instagram  #Felicidad #Celebraci√≥n   \n",
            "481   17-01-2023 8:00      DebateTalk    Twitter        #Pol√≠tica #Debate   \n",
            "547  15-04-2016 14:50  CareerAchiever   Facebook    #Orgullo #HitoCarrera   \n",
            "\n",
            "     Retweets  Likes      Country  Year  Month  Day  Hour  \n",
            "590        30     60        EE.UU  2023      2   13    10  \n",
            "481        30     60        EE.UU  2023      1   17     8  \n",
            "547        28     55  Reino Unido  2016      4   15    14  \n"
          ]
        }
      ],
      "source": [
        "df1_raw = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/sentimentdataset_es.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKr3W1NEaBrP"
      },
      "source": [
        "#### **Dataset2: sentiment_analysis_dataset.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2eRhM-MYh6L",
        "outputId": "ad21b119-f712-4e03-e52b-4a6745b13bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (2540, 3)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "                                                  texto  label sentimiento\n",
            "1911  Se puede ser optimista, pero no pendejo. Estos...      1     neutral\n",
            "1987  Hola buenos d√≠as, siempre somos y seremos inve...      1     neutral\n",
            "763   Que Eliane y Erin est√©n tristes no es un caso ...      0    negativo\n"
          ]
        }
      ],
      "source": [
        "df2_raw = importar_dataset(\"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/refs/heads/feature/data-science-marely/data-science/datasets/datasets-origin/sentiment_analysis_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 1\n",
            "============================================================\n",
            "üìä Forma: (732, 15)\n",
            "üìù Columnas: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
            "üî§ Columnas de texto: ['Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Country']\n",
            "\n",
            "üìù Analizando columna: 'Text'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     '¬°Acabo de adoptar a un lindo amigo peludo!??'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     '¬°Acabo de terminar un entrenamiento incre√≠ble!??'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     '¬°Adoraci√≥n desbordante por un lindo cachorro rescatado!??'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     '¬°A√±o nuevo, nuevos objetivos de fitness!??'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     '¬°Celebrando el cumplea√±os de un amigo esta noche!??'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 2\n",
            "============================================================\n",
            "üìä Forma: (2540, 3)\n",
            "üìù Columnas: ['texto', 'label', 'sentimiento']\n",
            "üî§ Columnas de texto: ['texto', 'sentimiento']\n",
            "\n",
            "üìù Analizando columna: 'texto'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'termine bien abrumado despu√©s de hoy'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'me siento abrumado'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Me siento un poco abrumado por la cantidad de cosas que quiero dibujar, ver, jug...'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Salvador la √∫nica persona que no la ha abrumado de versiones???? #NadieComoT√∫'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Denme un helado o algo que ando full abrumado.'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def verificar_calidad_importacion(df, nombre_dataset):\n",
        "    \"\"\"\n",
        "    Verifica que no se haya perdido informaci√≥n durante la importaci√≥n.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD: {nombre_dataset}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if df is None:\n",
        "        print(\"‚ùå Dataset es None\")\n",
        "        return False\n",
        "    \n",
        "    # 1. Informaci√≥n b√°sica\n",
        "    print(f\"üìä Forma: {df.shape}\")\n",
        "    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "    \n",
        "    # 2. Buscar columnas de texto\n",
        "    columnas_texto = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    print(f\"üî§ Columnas de texto: {columnas_texto}\")\n",
        "    \n",
        "    if not columnas_texto:\n",
        "        print(\"‚ö†Ô∏è  No se encontraron columnas de texto\")\n",
        "        return True\n",
        "    \n",
        "    # 3. Analizar una columna de texto (usar la primera)\n",
        "    col_texto = columnas_texto[0]\n",
        "    print(f\"\\nüìù Analizando columna: '{col_texto}'\")\n",
        "    \n",
        "    # Muestra de textos\n",
        "    textos = df[col_texto].dropna().head(5).tolist()\n",
        "    \n",
        "    problemas = []\n",
        "    \n",
        "    for i, texto in enumerate(textos):\n",
        "        if isinstance(texto, str):\n",
        "            # Buscar caracteres de reemplazo (ÔøΩ) que indican problemas\n",
        "            caracteres_problema = texto.count('ÔøΩ')\n",
        "            if caracteres_problema > 0:\n",
        "                problemas.append(f\"Texto {i+1} tiene {caracteres_problema} caracteres de reemplazo (ÔøΩ)\")\n",
        "            \n",
        "            # Buscar emojis\n",
        "            emojis = [c for c in texto if unicodedata.category(c)[0] in ['S', 'So']]\n",
        "            if emojis:\n",
        "                print(f\"  Texto {i+1}: ‚úÖ Tiene {len(emojis)} emoji(s): {''.join(emojis[:3])}\")\n",
        "            else:\n",
        "                print(f\"  Texto {i+1}: üìÑ Sin emojis\")\n",
        "            \n",
        "            # Mostrar fragmento\n",
        "            preview = texto[:80] + \"...\" if len(texto) > 80 else texto\n",
        "            print(f\"     '{preview}'\")\n",
        "    \n",
        "    # 4. Resumen\n",
        "    if problemas:\n",
        "        print(f\"\\n‚ö†Ô∏è  PROBLEMAS ENCONTRADOS:\")\n",
        "        for problema in problemas:\n",
        "            print(f\"   ‚Ä¢ {problema}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\")\n",
        "        return True\n",
        "\n",
        "verificar_calidad_importacion(df1_raw, \"Dataset 1\")\n",
        "verificar_calidad_importacion(df2_raw, \"Dataset 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvsjkC76PuLm"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X6oJxnAPuLm",
        "outputId": "680cdb5c-07ff-454e-a8f9-44f90365bbae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 texto  sentimiento\n",
            "278  En el torneo de tenis, un jugador muy esperado...  Frustraci√≥n\n",
            "521  Motivado para alcanzar objetivos de acondicion...   Motivaci√≥n\n",
            "47   Agradecimiento de todo coraz√≥n por las risas c...     Positivo\n",
            "274  En el p√∫blico de una actuaci√≥n de Jay-Z, la le...      Orgullo\n",
            "290  En las ruinas de la esperanza, los ecos de los...      Soledad\n",
            "                                                  texto sentimiento\n",
            "1736            holaa, finally twitter est√° m√°s calmado    positivo\n",
            "513   Lo hermoso que es el RE4 me hab√≠a olvidado tot...    negativo\n",
            "375   Carla es mufa nunca nos tuvo fe y ahora morimo...    negativo\n",
            "1727  Ser√° que todav√≠a hay gente que va a Cartagena ...    positivo\n",
            "388   Me p√°rese re injusto que cuando las mujeres op...    negativo\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n filtrar dataset\n",
        "def filtrar_dataset(data):\n",
        "    data_filtro = data[['texto', 'sentimiento']]\n",
        "    data_filtro = data_filtro[data_filtro['texto'].str.strip() != \"\"]\n",
        "    print(data_filtro.sample(5))\n",
        "    return data_filtro\n",
        "\n",
        "# Reemplazar nombre columnas Text por texto, Sentiment por sentimiento\n",
        "df1_raw.rename({'Text':'texto', 'Sentiment':'sentimiento'}, axis=1, inplace=True)\n",
        "df1_filtrado = filtrar_dataset(df1_raw)\n",
        "df2_filtrado = filtrar_dataset(df2_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmazYt9QBYT"
      },
      "source": [
        "### <font size= 12 color=\"lightgreen\" >Explorando los datasets<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "_sb3UjtYPuLn"
      },
      "outputs": [],
      "source": [
        "# Crear funci√≥n para explorar datasets\n",
        "def explorar_dataset(data):\n",
        "    print('Filas: ' + str(data.shape[0]))\n",
        "    print('Columnas: ' + str(data.shape[1]))\n",
        "    print('\\nColumnas: \\n' + str(data.columns.tolist()))\n",
        "    print('\\nTipo de datos: \\n' + str(data.dtypes))\n",
        "    print('\\nValores nulos: \\n' + str(data.isnull().sum()))\n",
        "    print('\\nMuestra aleatoria (5 registros): \\n' + str(data.sample(5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-OpMWf0l8DM"
      },
      "source": [
        "#### **Explorando Data1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0SICtaLs770",
        "outputId": "3eb49226-5445-4ef0-9413-ef7f983530f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 732\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto     sentimiento\n",
            "205  Disfrutando de una tarde tranquila con una nov...  Contentamiento\n",
            "141      Codificando un nuevo proyecto con entusiasmo.        Positivo\n",
            "228  El intento fallido del levantador de pesas de ...         Neutral\n",
            "98   Asisti√≥ a un concierto y bail√≥ toda la noche.L...         Alegr√≠a\n",
            "700  Un estallido de creatividad art√≠stica en la tr...        Positivo\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfglf1PjDfz"
      },
      "source": [
        "#### **Explorando data2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvetNKaKfI3X",
        "outputId": "291f0ad4-172a-4762-b18b-e62c6ed17fc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 732\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto sentimiento\n",
            "590  Pura felicidad: ¬°celebrar el logro de un ser q...   Felicidad\n",
            "401  Inmerso en las encantadoras melod√≠as del viol√≠...    Mel√≥dico\n",
            "530  Nostalgia, un baile agridulce en el sal√≥n de b...     Neutral\n",
            "192  Desgarrado por el dolor, los ecos de la p√©rdid...       Dolor\n",
            "612  Reverencia por el significado hist√≥rico de un ...  Reverencia\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "    # Mostrar resultados estad√≠sticos de la limpieza.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62jGtD-PuLo"
      },
      "source": [
        "#### **An√°lisis proceso de limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "Gs5CRWmVPuLo"
      },
      "outputs": [],
      "source": [
        "def analizar_limpieza_sentimientos(df_antes, df_despues, nombre):\n",
        "    \"\"\"\n",
        "    An√°lisis espec√≠fico para tu funci√≥n limpiar_texto_para_sentimientos\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç AN√ÅLISIS ESPEC√çFICO: {nombre}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Cambios en caracteres espec√≠ficos del espa√±ol\n",
        "    cambios_especificos = {\n",
        "        'tildes_eliminadas': 0,\n",
        "        '√±_preservadas': 0,\n",
        "        'urls_eliminadas': 0,\n",
        "        'mayusculas_preservadas': 0\n",
        "    }\n",
        "\n",
        "    # Muestra de 50 textos para an√°lisis detallado\n",
        "    muestra = min(50, len(df_antes))\n",
        "\n",
        "    for i in range(muestra):\n",
        "        if i < len(df_despues):\n",
        "            texto_antes = str(df_antes.iloc[i]['texto'])\n",
        "            texto_despues = str(df_despues.iloc[i]['texto'])\n",
        "\n",
        "            # Contar √± preservadas\n",
        "            if '√±' in texto_antes.lower() and '√±' in texto_despues.lower():\n",
        "                cambios_especificos['√±_preservadas'] += 1\n",
        "\n",
        "            # Contar URLs eliminadas\n",
        "            import re\n",
        "            urls_antes = len(re.findall(r'https?://\\S+', texto_antes))\n",
        "            urls_despues = len(re.findall(r'https?://\\S+', texto_despues))\n",
        "            if urls_antes > urls_despues:\n",
        "                cambios_especificos['urls_eliminadas'] += (urls_antes - urls_despues)\n",
        "\n",
        "            # Verificar may√∫sculas preservadas\n",
        "            mayus_antes = sum(1 for c in texto_antes if c.isupper())\n",
        "            mayus_despues = sum(1 for c in texto_despues if c.isupper())\n",
        "            if mayus_antes > 0 and mayus_despues > 0:\n",
        "                cambios_especificos['mayusculas_preservadas'] += 1\n",
        "\n",
        "    print(\"üìä Cambios espec√≠ficos de tu limpiador:\")\n",
        "    for cambio, cantidad in cambios_especificos.items():\n",
        "        print(f\"   ‚Ä¢ {cambio.replace('_', ' ').title()}: {cantidad} de {muestra} textos\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJST9GAJPuLo",
        "outputId": "c22a5272-1071-49c9-b6d1-c0dd08af24d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÅ Dataset 1\n",
            "   Registros: 732\n",
            "   Muestra (3 textos):\n",
            "                                                 texto  \\\n",
            "539  Organizar una marat√≥n de pel√≠culas con amigos....   \n",
            "120  Bailando juguetonamente bajo la lluvia de risa...   \n",
            "360  Explorando galer√≠as de arte locales este fin d...   \n",
            "\n",
            "                                          Texto_Limpio  \n",
            "539  Organizar una maraton de peliculas con amigos....  \n",
            "120  Bailando juguetonamente bajo la lluvia de risa...  \n",
            "360  Explorando galerias de arte locales este fin d...  \n",
            "\n",
            "üìÅ Dataset 2\n",
            "   Registros: 2,540\n",
            "   Muestra (3 textos):\n",
            "                                                  texto  \\\n",
            "2151  Incre√≠ble me acabo de auto jugar un rpg mental...   \n",
            "1793  Mi coraz√≥n se volvi√≥ inquebrantable, cuando el...   \n",
            "171   PREGUNTA yo recuerdo que cuando le√≠ SAVE por W...   \n",
            "\n",
            "                                           Texto_Limpio  \n",
            "2151  Increible me acabo de auto jugar un rpg mental...  \n",
            "1793  Mi corazon se volvio inquebrantable, cuando el...  \n",
            "171   PREGUNTA yo recuerdo que cuando lei SAVE por W...  \n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 1\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 10 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 50 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 2\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 7 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 43 de 50 textos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Lista de dataframes para procesar\n",
        "dataframes = [\n",
        "    (df1_filtrado, \"Dataset 1\"),\n",
        "    (df2_filtrado, \"Dataset 2\")\n",
        "]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for df, nombre in dataframes:\n",
        "    # Aplicar limpieza\n",
        "    df['Texto_Limpio'] = df['texto'].apply(limpiar_texto_sentimientos)\n",
        "\n",
        "    # Guardar copia limpia\n",
        "    resultados[nombre] = df.copy()\n",
        "\n",
        "    # Mostrar info\n",
        "    print(f\"\\nüìÅ {nombre}\")\n",
        "    print(f\"   Registros: {len(df):,}\")\n",
        "    print(f\"   Muestra (3 textos):\")\n",
        "    print(df[['texto', 'Texto_Limpio']].sample(3))\n",
        "\n",
        "# Asignar a variables originales\n",
        "df1_clean = resultados[\"Dataset 1\"]\n",
        "df2_clean = resultados[\"Dataset 2\"]\n",
        "\n",
        "analizar_limpieza_sentimientos(df1_filtrado, df1_clean, \"Dataset 1\")\n",
        "analizar_limpieza_sentimientos(df2_filtrado, df2_clean, \"Dataset 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uj1j4hVnPuLo",
        "outputId": "7eef6135-1bbf-4ee6-f11e-ea0dc45fc45e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>Entumecido ante el caos, las emociones encerra...</td>\n",
              "      <td>Entumecimiento</td>\n",
              "      <td>Entumecido ante el caos, las emociones encerra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>La confusi√≥n nubla mi mente mientras tomo deci...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>La confusion nubla mi mente mientras tomo deci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>Entre la multitud en un concierto de Taylor Sw...</td>\n",
              "      <td>Encantamiento</td>\n",
              "      <td>Entre la multitud en un concierto de Taylor Sw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto     sentimiento  \\\n",
              "315  Entumecido ante el caos, las emociones encerra...  Entumecimiento   \n",
              "436  La confusi√≥n nubla mi mente mientras tomo deci...         Neutral   \n",
              "313  Entre la multitud en un concierto de Taylor Sw...   Encantamiento   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "315  Entumecido ante el caos, las emociones encerra...  \n",
              "436  La confusion nubla mi mente mientras tomo deci...  \n",
              "313  Entre la multitud en un concierto de Taylor Sw...  "
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jiA1uCrfPuLo",
        "outputId": "cdf54008-6cde-4d27-d7e4-dc472608f99d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>me da ternura mi mam√° de suegra la vdd, se pre...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>me da ternura mi mama de suegra la vdd, se pre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2170</th>\n",
              "      <td>dios mio lo hab√≠a extra√±ado TANTO ????</td>\n",
              "      <td>neutral</td>\n",
              "      <td>dios mio lo habia extra√±ado TANTO ????</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1944</th>\n",
              "      <td>He llorado como pocas veces con \"La Sociedad d...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>He llorado como pocas veces con \"La Sociedad d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1499  me da ternura mi mam√° de suegra la vdd, se pre...    positivo   \n",
              "2170             dios mio lo hab√≠a extra√±ado TANTO ????     neutral   \n",
              "1944  He llorado como pocas veces con \"La Sociedad d...     neutral   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "1499  me da ternura mi mama de suegra la vdd, se pre...  \n",
              "2170             dios mio lo habia extra√±ado TANTO ????  \n",
              "1944  He llorado como pocas veces con \"La Sociedad d...  "
            ]
          },
          "execution_count": 177,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ_i8f3tPuLp"
      },
      "source": [
        "#### **Categor√≠as Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq_HYQiePuLp",
        "outputId": "3a26f669-b547-498a-afe5-e04d40d6cc36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos √∫nicos: 106\n",
            "['Abrumado', 'Aburrimiento', 'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Aislamiento', 'Alegr√≠a', 'Amabilidad', 'Amargura', 'Ambivalencia', 'Amistad', 'Amor', 'Angustia', 'Anhelo', 'Ansiedad', 'Anticipaci√≥n', 'Apreciaci√≥n', 'Aprensivo', 'Armon√≠a', 'Arrepentimiento', 'Asco', 'Asombro', 'Cautivaci√≥n', 'Celebraci√≥n', 'Colorido', 'Confiado', 'Confianza', 'Contentamiento', 'Creatividad', 'Cumplimiento', 'Curiosidad', 'Decepci√≥n', 'Desamor', 'Descubrimiento', 'Desesperaci√≥n', 'Deslumbrar', 'Despectivo', 'Determinaci√≥n', 'Devastado', 'Disfrute', 'Diversi√≥n', 'Dolor', 'Elaci√≥n', 'Elegancia', 'Emoci√≥n', 'Empoderamiento', 'Emp√°tico', 'Encantamiento', 'Energ√≠a', 'Enojo', 'Entumecimiento', 'Entusiasmo', 'Envidia', 'Envidioso', 'Esperanza', 'Euforia', 'Excitaci√≥n', 'Felicidad', 'Frustraci√≥n', 'Frustrado', 'Grandeza', 'Gratitud', 'Inspiraci√≥n', 'Inspirado', 'Intimidaci√≥n', 'Juguet√≥n', 'Logro', 'L√°stima', 'Malo', 'Maravilla', 'Melancol√≠a', 'Mel√≥dico', 'Miedo', 'Motivaci√≥n', 'Negativo', 'Neutral', 'Obst√°culo', 'Odiar', 'Optimismo', 'Orgullo', 'Pena', 'Positividad', 'Positivo', 'P√©rdida', 'Reconfortante', 'Reflexi√≥n', 'Resentimiento', 'Resiliencia', 'Resplandor', 'Reverencia', 'Romance', 'Satisfacci√≥n', 'Serenidad', 'Soledad', 'Sorpresa', 'Sufrimiento', 'Temeroso', 'Ternura', 'Traici√≥n', 'Tristeza', 'Triunfo', 'Verguenza', '√Ånimo', '√âxito', '√âxtasis']\n",
            "Sentimientos positivos: 62\n",
            "Sentimientos negativos: 39\n",
            "Sentimientos neutros: 5\n",
            "\n",
            "‚úÖ Total clasificado: 106/106 sentimientos\n",
            "   - Positivos: 62 (58.5%)\n",
            "   - Negativos: 39 (36.8%)\n",
            "   - Neutros: 5 (4.7%)\n",
            "Total: 106\n",
            "\n",
            "‚úÖ Todos los sentimientos del dataset est√°n clasificados.\n"
          ]
        }
      ],
      "source": [
        "# 1. Definimos las listas de sentimientos seg√∫n su categor√≠a\n",
        "# Ver todos los sentimientos √∫nicos para saber qu√© agrupar y ordenar alfabetizamente\n",
        "sentimientos_unicos = sorted(df1_clean['sentimiento'].unique())\n",
        "print(f\"Total de sentimientos √∫nicos: {len(sentimientos_unicos)}\")\n",
        "print(sentimientos_unicos)\n",
        "\n",
        "# 2. SENTIMIENTOS POSITIVOS COMPLETOS (Bienestar, √©xito, alegr√≠a, admiraci√≥n)\n",
        "positivos = [\n",
        "    'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Alegr√≠a', 'Amabilidad', 'Amor', 'Amistad', 'Apreciaci√≥n', 'Armon√≠a', 'Asombro', 'Cautivaci√≥n', 'Celebraci√≥n', 'Colorido', 'Confiado','Confianza', 'Contentamiento', 'Creatividad', 'Cumplimiento', 'Descubrimiento', 'Deslumbrar', 'Determinaci√≥n', 'Disfrute','Diversi√≥n', 'Elegancia', 'Emoci√≥n', 'Emp√°tico', 'Empoderamiento',\n",
        "    'Encantamiento', 'Energ√≠a', 'Entusiasmo', 'Esperanza', 'Euforia', 'Excitaci√≥n', 'Felicidad', 'Grandeza', 'Gratitud', 'Inspiraci√≥n', 'Inspirado', 'Intimidaci√≥n', 'Juguet√≥n', 'Logro','Maravilla', 'Mel√≥dico', 'Motivaci√≥n', 'Optimismo', 'Orgullo',\n",
        "    'Positividad', 'Positivo', 'Reconfortante', 'Resiliencia', 'Resplandor', 'Reverencia', 'Romance', 'Satisfacci√≥n', 'Serenidad','Ternura', 'Triunfo', '√Ånimo', '√âxito','Elaci√≥n','√âxtasis']\n",
        "print(f'Sentimientos positivos: {len(positivos)}'),\n",
        "\n",
        "# 3. SENTIMIENTOS NEGATIVOS COMPLETOS (Dolor, ira, miedo, estr√©s, p√©rdida)\n",
        "negativos = [\n",
        "    'Abrumado', 'Aburrimiento', 'Aislamiento', 'Amargura', 'Angustia', 'Anhelo', 'Ansiedad', 'Aprensivo', 'Arrepentimiento', 'Asco',  'Decepci√≥n', 'Desamor', 'Desesperaci√≥n', 'Despectivo', 'Devastado',\n",
        "    'Dolor', 'Enojo', 'Entumecimiento', 'Envidia', 'Envidioso', 'Frustraci√≥n', 'Frustrado', 'L√°stima', 'Obst√°culo', 'Malo', 'Melancol√≠a', 'Miedo', 'Negativo', 'Odiar', 'Pena', 'P√©rdida', 'Reflexi√≥n', 'Resentimiento', 'Soledad', 'Sufrimiento', 'Temeroso', 'Traici√≥n', 'Tristeza', 'Verguenza']\n",
        "print(f'Sentimientos negativos: {len(negativos)}')\n",
        "\n",
        "# 4. SENTIMIENTOS NEUTRALES (Estados ambiguos o contemplativos)\n",
        "neutros = ['Ambivalencia', 'Curiosidad', 'Neutral','Sorpresa','Anticipaci√≥n']\n",
        "print(f'Sentimientos neutros: {len(neutros)}')\n",
        "\n",
        "categorias = [positivos, negativos, neutros]\n",
        "\n",
        "# Verificaci√≥n del total\n",
        "total_clasificados = len(positivos) + len(negativos) + len(neutros)\n",
        "print(f'\\n‚úÖ Total clasificado: {total_clasificados}/106 sentimientos')\n",
        "print(f'   - Positivos: {len(positivos)} ({len(positivos)/106*100:.1f}%)')\n",
        "print(f'   - Negativos: {len(negativos)} ({len(negativos)/106*100:.1f}%)')\n",
        "print(f'   - Neutros: {len(neutros)} ({len(neutros)/106*100:.1f}%)')\n",
        "print(f'Total: {len(positivos) + len(negativos) + len(neutros)}')\n",
        "print()\n",
        "\n",
        "# Verificar si existen elementos en las listas que no se encuentran en la lista sentimientos_unicos\n",
        "for sentimiento in negativos + positivos + neutros:\n",
        "    if sentimiento not in sentimientos_unicos:\n",
        "        print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "\n",
        "# Verificar si todos los sentimientos del dataset est√°n clasificados\n",
        "for sentimiento in sentimientos_unicos:\n",
        "    if sentimiento not in positivos + negativos + neutros:\n",
        "        print(f\"‚ùå Sentimiento no clasificado: {sentimiento}\")\n",
        "else:\n",
        "    print(\"‚úÖ Todos los sentimientos del dataset est√°n clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12vkocMMPuLp"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "hAy-90rDPuLp"
      },
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias):\n",
        "    \"\"\"\n",
        "    Categoriza sentimientos solo si est√°n en las listas definidas.\n",
        "    Devuelve None para sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    sent = str(sentimiento).strip().title()\n",
        "\n",
        "    if sent in positivos:\n",
        "        return 'positivo'\n",
        "    elif sent in negativos:\n",
        "        return 'negativo'\n",
        "    elif sent in neutros:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        # Devolvemos None para posterior filtrado\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XgFiRtKtPuLp",
        "outputId": "ec3e9d03-050d-4b71-94c6-1cc9e7ba75b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>Revisando viejos recuerdos, sintiendo una sens...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Revisando viejos recuerdos, sintiendo una sens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>Asisti√≥ a una cata de vinos y sabore√≥ la rique...</td>\n",
              "      <td>Alegr√≠a</td>\n",
              "      <td>Asistio a una cata de vinos y saboreo la rique...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>Intentos frustrados de reparar una conexi√≥n ro...</td>\n",
              "      <td>Frustrado</td>\n",
              "      <td>Intentos frustrados de reparar una conexion ro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "616  Revisando viejos recuerdos, sintiendo una sens...    Positivo   \n",
              "100  Asisti√≥ a una cata de vinos y sabore√≥ la rique...     Alegr√≠a   \n",
              "414  Intentos frustrados de reparar una conexi√≥n ro...   Frustrado   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "616  Revisando viejos recuerdos, sintiendo una sens...  \n",
              "100  Asistio a una cata de vinos y saboreo la rique...  \n",
              "414  Intentos frustrados de reparar una conexion ro...  "
            ]
          },
          "execution_count": 180,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rKZfkztUPuLp",
        "outputId": "623437f6-56cb-41d0-e3c2-3f57f0b36153"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>#AquamanAndTheLostKingdom el cachondeo autocon...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>#AquamanAndTheLostKingdom el cachondeo autocon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>El cielo es el l√≠mite.   Cada vez m√°s convenci...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>El cielo es el limite. Cada vez mas convencido...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>?? Phillip estaba inquieto, insist√≠a mucho en ...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>?? Phillip estaba inquieto, insistia mucho en ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "254   #AquamanAndTheLostKingdom el cachondeo autocon...    negativo   \n",
              "1817  El cielo es el l√≠mite.   Cada vez m√°s convenci...     neutral   \n",
              "439   ?? Phillip estaba inquieto, insist√≠a mucho en ...    negativo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "254   #AquamanAndTheLostKingdom el cachondeo autocon...  \n",
              "1817  El cielo es el limite. Cada vez mas convencido...  \n",
              "439   ?? Phillip estaba inquieto, insistia mucho en ...  "
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT9snuZtPuLq"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRuHBnaFPuLq",
        "outputId": "4c176f23-e178-440d-c2cb-db089a3fac43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ df1: 732 registros categorizados\n",
            "‚úÖ df2: 2540 registros categorizados\n"
          ]
        }
      ],
      "source": [
        "df1_clean['Sentimiento_Final'] = df1_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df1_categorized = df1_clean[df1_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df2_clean['Sentimiento_Final'] = df2_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df2_categorized = df2_clean[df2_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "print(f\"‚úÖ df1: {len(df1_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df2: {len(df2_categorized)} registros categorizados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2Q8euH7QPuLq",
        "outputId": "b7470a5e-22e6-499c-a3db-3dcdacef664d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>Pasando el d√≠a con aire de indiferencia, indif...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Pasando el dia con aire de indiferencia, indif...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>Ante una derrota en el campeonato, el boxeador...</td>\n",
              "      <td>Reflexi√≥n</td>\n",
              "      <td>Ante una derrota en el campeonato, el boxeador...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Explorando las antiguas ruinas de Angkor Wat, ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Explorando las antiguas ruinas de Angkor Wat, ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "556  Pasando el d√≠a con aire de indiferencia, indif...     Neutral   \n",
              "84   Ante una derrota en el campeonato, el boxeador...   Reflexi√≥n   \n",
              "361  Explorando las antiguas ruinas de Angkor Wat, ...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "556  Pasando el dia con aire de indiferencia, indif...           neutral  \n",
              "84   Ante una derrota en el campeonato, el boxeador...          negativo  \n",
              "361  Explorando las antiguas ruinas de Angkor Wat, ...           neutral  "
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "onq_zeNRPuLt",
        "outputId": "15299e9f-2214-4750-9411-82375bf7ed4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1813</th>\n",
              "      <td>Juro que cada vez mas convencido de estar con ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Juro que cada vez mas convencido de estar con ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>‚ÄîNo me cierro contigo. T√∫ tampoco me cuentas t...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>‚ÄîNo me cierro contigo. Tu tampoco me cuentas t...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>Que calor caloroso</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Que calor caloroso</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1813  Juro que cada vez mas convencido de estar con ...     neutral   \n",
              "1079  ‚ÄîNo me cierro contigo. T√∫ tampoco me cuentas t...    negativo   \n",
              "1510                                 Que calor caloroso    positivo   \n",
              "\n",
              "                                           Texto_Limpio Sentimiento_Final  \n",
              "1813  Juro que cada vez mas convencido de estar con ...           neutral  \n",
              "1079  ‚ÄîNo me cierro contigo. Tu tampoco me cuentas t...          negativo  \n",
              "1510                                 Que calor caloroso          positivo  "
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfhg_fBXPuLt"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar dataset unificado</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEB_qDA3PuLt"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "W19ms-90PuLu"
      },
      "outputs": [],
      "source": [
        "def limpiar_dataset_unificado(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('Texto_Limpio')['Sentimiento_Final'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['Texto_Limpio'] == texto]['Sentimiento_Final'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['Texto_Limpio'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['Texto_Limpio'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['Texto_Limpio'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['Texto_Limpio', 'Sentimiento_Final']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Texto_Limpio'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Sentimiento_Final'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['Texto_Limpio'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['Texto_Limpio'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['Sentimiento_Final'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n8a2z5ZNPuLu",
        "outputId": "cccf931c-641b-45c3-cab7-d558648859ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2429</th>\n",
              "      <td>En tiempos de incertidumbre pol√≠tica, es cruci...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>En tiempos de incertidumbre politica, es cruci...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2535</th>\n",
              "      <td>No podemos vivir con miedo:   ¬°Manejen borrach...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>No podemos vivir con miedo: ¬°Manejen borrachos...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>Melchor: grax por su compra  Baltazar: s√≠ lo m...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Melchor: grax por su compra Baltazar: si lo mo...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "2429  En tiempos de incertidumbre pol√≠tica, es cruci...    positivo   \n",
              "2535  No podemos vivir con miedo:   ¬°Manejen borrach...    positivo   \n",
              "386   Melchor: grax por su compra  Baltazar: s√≠ lo m...    negativo   \n",
              "\n",
              "                                           Texto_Limpio Sentimiento_Final  \n",
              "2429  En tiempos de incertidumbre politica, es cruci...          positivo  \n",
              "2535  No podemos vivir con miedo: ¬°Manejen borrachos...          positivo  \n",
              "386   Melchor: grax por su compra Baltazar: si lo mo...          negativo  "
            ]
          },
          "execution_count": 186,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_categorized.sample(3)\n",
        "df2_categorized.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4d4Mra2PuLu"
      },
      "source": [
        "#### **Unificar datataset y limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJeTAgAkPuLu",
        "outputId": "44a076c7-89f5-4ab3-b99e-b6256ca22b55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó UNIFICANDO DATASETS CATEGORIZADOS\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (3272, 2)\n",
            "   ‚Ä¢ Registros: 3,272\n",
            "   ‚Ä¢ Textos √∫nicos: 2,849\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 3,272\n",
            "Textos √∫nicos iniciales: 2,849\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚ö†Ô∏è  Encontradas: 90 contradicciones\n",
            "   ‚Ä¢ Ejemplos (primeros 2):\n",
            "     - '\"De manera apacible, se puede sacudir el mundo\" MG'\n",
            "       ‚Üí Sentimientos: negativo, positivo\n",
            "     - '\"He aprendido que el valor no es la ausencia de miedo, sino ...'\n",
            "       ‚Üí Sentimientos: neutral, positivo\n",
            "   üóëÔ∏è  Eliminados: 212 registros por contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚ö†Ô∏è  Encontrados: 252 textos duplicados\n",
            "   ‚Ä¢ Registros a eliminar: 301\n",
            "   üóëÔ∏è  Eliminados: 301 registros duplicados\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 2,759\n",
            "   ‚Ä¢ Textos √∫nicos finales: 2,759\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 3,272\n",
            "Registros finales: 2,759\n",
            "Total eliminados: 513 (15.7%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ positivo: 1,177 (42.7%)\n",
            "   ‚Ä¢ negativo: 1,091 (39.5%)\n",
            "   ‚Ä¢ neutral: 491 (17.8%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó UNIFICANDO DATASETS CATEGORIZADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Unificar los datasets categorizados\n",
        "df_unificado = pd.concat([df1_categorized[['Texto_Limpio', 'Sentimiento_Final']], df2_categorized[['Texto_Limpio', 'Sentimiento_Final']]], ignore_index=True)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_unificado.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_unificado):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_unificado['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "df_final = limpiar_dataset_unificado(df_unificado, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PiaR4I5zPuLu",
        "outputId": "c153adfb-72ce-43c9-a843-f98248e1e66b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2832</th>\n",
              "      <td>Hasta alguien como el tiene limites sobre el d...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>Cada tanto me acuerdo de que nos gobierna Javi...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>Yo soy de esos que no me quejo por nada, con q...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Texto_Limpio Sentimiento_Final\n",
              "2832  Hasta alguien como el tiene limites sobre el d...           neutral\n",
              "2895  Cada tanto me acuerdo de que nos gobierna Javi...           neutral\n",
              "1021  Yo soy de esos que no me quejo por nada, con q...          negativo"
            ]
          },
          "execution_count": 188,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unificado.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOG13F7lPuLv"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5DwJkdPuLv"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VLH0dQePuLv",
        "outputId": "d910f9b3-2f6d-4345-90ed-81ae499bf0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "============================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------\n",
            "Positivo     |     1177 |     42.66% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |     1091 |     39.54% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |      491 |      17.8% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------\n",
            "TOTAL        |     2759 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['Sentimiento_Final'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 58)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6Bpu2ZPuLv"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "INsd0XvNPuLv",
        "outputId": "f5f771f0-c179-4c36-ff48-5a7f497c5b41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hovertemplate": "label=%{label}<br>value=%{value}<extra></extra>",
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "positivo",
                    "negativo",
                    "neutral"
                  ],
                  "legendgroup": "",
                  "name": "",
                  "showlegend": true,
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "mQRDBOsB",
                    "dtype": "i2"
                  }
                }
              ],
              "layout": {
                "height": 500,
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 2759 registros</span>",
                  "x": 0.5
                },
                "width": 500
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Grafica de pastel con Plotly\n",
        "\n",
        "valores = df_final['Sentimiento_Final'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "fig1 = px.pie(\n",
        "    names = valores.sentimientos,\n",
        "    values = valores.Cantidad,\n",
        ")\n",
        "\n",
        "fig1.update_traces(textposition='inside', textinfo='label+percent',  insidetextfont=dict(color = 'white', size=14)\n",
        ")\n",
        "\n",
        "fig1.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMplULMaPuLv"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwSlmvXSPuLv"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "esUzQFjnPuLv"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9kZOcK7PuLv"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBwUlWgPuLw",
        "outputId": "ddf616bd-2f8d-468c-f675-7a5984eac78f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset.csv\n",
            "üìä Registros: 2,759\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxLqWrOWPuLw"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "YB9ZY3b3PuLw"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwJXRfMxPuLw",
        "outputId": "af31205a-3374-4a7a-e907-5afe1416dbde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 2,759 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 2,759 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                           texto sentimiento\n",
            "    ¬°Acabo de adoptar a un lindo amigo peludo!??    positivo\n",
            "¬°Acabo de terminar un entrenamiento increible!??    positivo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 2,759 registros (encoding: utf-8-sig)\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                           texto sentimiento\n",
            "    ¬°Acabo de adoptar a un lindo amigo peludo!??    positivo\n",
            "¬°Acabo de terminar un entrenamiento increible!??    positivo\n"
          ]
        }
      ],
      "source": [
        "# Verificar que el archivo se pueda leer\n",
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=enc, nrows=5)  # Probar con 5 filas\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None\n",
        "\n",
        "# Uso simple\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL-DDylhPuLw"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQcqcJa0PuLx",
        "outputId": "27f00ccd-7964-4e8c-fe31-0142ce2d9166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìã RESUMEN EJECUTIVO - PREPROCESAMIENTO COMPLETADO\n",
            "============================================================\n",
            "‚úÖ Dataset final: 2759 registros\n",
            "‚úÖ Distribuci√≥n balanceada: Positivo 42.66%, Negativo 39.54%, Neutral 17.8%\n",
            "‚úÖ Archivo exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset.csv\n",
            "‚úÖ Calidad: 0 textos vac√≠os, 0 valores nulos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"üìã RESUMEN EJECUTIVO - PREPROCESAMIENTO COMPLETADO\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar)} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: Positivo {porcentajes['positivo']}%, Negativo {porcentajes['negativo']}%, Neutral {porcentajes['neutral']}%\")\n",
        "print(f\"‚úÖ Archivo exportado: {archivo_final}\")\n",
        "print(f\"‚úÖ Calidad: 0 textos vac√≠os, 0 valores nulos\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATONPfOQG56"
      },
      "source": [
        "### 4. <font color='lightgreen'>**Categorizaci√≥n de Sentimientos**</font>\n",
        "Dado que el Dataset 1 conten√≠a 106 sentimientos diferentes, se defini√≥ un esquema de agrupaci√≥n en tres categor√≠as:\n",
        "\n",
        "Categor√≠a\tEjemplos de Sentimientos Incluidos\n",
        "\n",
        "La funci√≥n categorizar_sentimiento() asign√≥ cada etiqueta original a una de estas tres clases, priorizando neutral para casos ambiguos o no clasificables.\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKs6qCjlPuLx"
      },
      "source": [
        "###  4. <font color='lightgreen'>**Limpieza Rigurosa del Dataset Unificado**</font>\n",
        "\n",
        "**Problemas Identificados Post-Fusi√≥n**:\n",
        "- **90 casos de contradicciones**: Textos id√©nticos con sentimientos diferentes (ej: \"me siento bien\" ‚Üí positivo Y negativo)\n",
        "- **252 casos de duplicados exactos**: Textos id√©nticos con mismo sentimiento (ej: \"qu√© bonito d√≠a\" ‚Üí positivo, repetido)\n",
        "- **Inconsistencia cr√≠tica** para entrenamiento de ML: Un texto no puede tener m√∫ltiples sentimientos\n",
        "\n",
        "**Pipeline de 3 Etapas de Depuraci√≥n**:\n",
        "\n",
        "1. **Eliminaci√≥n de Contradicciones** (prioridad m√°xima):\n",
        "   - **90 textos problem√°ticos** identificados\n",
        "   - **212 registros eliminados** (todos los registros de textos contradictorios)\n",
        "   - **Ejemplo**: Texto \"La vida es bella\" aparec√≠a 3 veces: 2√ópositivo, 1√ónegativo ‚Üí se eliminaron LAS 3 apariciones\n",
        "\n",
        "2. **Eliminaci√≥n de Duplicados Exactos**:\n",
        "   - **252 textos duplicados** identificados  \n",
        "   - **301 registros eliminados** (se mantuvo solo la primera aparici√≥n de cada texto)\n",
        "   - **Ejemplo**: \"Hoy es mi cumplea√±os\" aparec√≠a 4 veces como positivo ‚Üí se mantuvo 1, se eliminaron 3\n",
        "\n",
        "3. **Verificaci√≥n Final de Consistencia**:\n",
        "   - **2,759 textos √∫nicos** (0% duplicados)\n",
        "   - **0 contradicciones** (cada texto con un √∫nico sentimiento)\n",
        "   - **2,759 registros finales** (cada texto aparece exactamente una vez)\n",
        "\n",
        "**M√©tricas de Depuraci√≥n**:\n",
        "| Concepto | Cantidad | Explicaci√≥n |\n",
        "|----------|----------|-------------|\n",
        "| **Textos iniciales** | 3,272 registros | Combinaci√≥n cruda de ambos datasets |\n",
        "| **Casos de contradicci√≥n** | 90 textos | Mismo texto, sentimientos diferentes |\n",
        "| **Registros por contradicciones** | 212 eliminados | Todos los registros de textos contradictorios |\n",
        "| **Casos de duplicaci√≥n** | 252 textos | Mismo texto, mismo sentimiento |\n",
        "| **Registros por duplicados** | 301 eliminados | Registros repetidos (manteniendo primero) |\n",
        "| **Textos finales √∫nicos** | 2,759 textos | 0 duplicados, 0 contradicciones |\n",
        "| **Registros finales** | 2,759 registros | Un registro por texto √∫nico |\n",
        "| **Tasa de retenci√≥n** | 84.3% | 2,759/3,272 registros v√°lidos |\n",
        "| **Tasa de depuraci√≥n** | 15.7% | 513/3,272 registros eliminados |\n",
        "\n",
        "**Impacto en Calidad del Dataset**:\n",
        "- ‚úÖ **Consistencia absoluta**: Cada texto ‚Üí un √∫nico sentimiento\n",
        "- ‚úÖ **Unicidad garantizada**: Sin repeticiones que inflen m√©tricas\n",
        "- ‚úÖ **Preparado para ML**: Estructura √≥ptima para entrenamiento y validaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqglET-NCI0P"
      },
      "source": [
        "---\n",
        "### 5. **<font color='lightgreen'>Estructura final de Dataset Unificado</font>**\n",
        "\n",
        "El dataset exportado ``dataset_listo_para_ML.csv`` contiene:\n",
        "\n",
        "**Columnas:** texto, sentimiento\n",
        "\n",
        "**Estad√≠sticas finales**\n",
        "\n",
        "Registros totales: 3,272\n",
        "\n",
        "Distribuci√≥n:\n",
        "\n",
        "- Negativo: 1,300 (39.7%)\n",
        "\n",
        "- Positivo: 1,231 (37.6%)\n",
        "\n",
        "- Neutral: 741 (22.7%)`\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K2ezd_nPuLy",
        "outputId": "48802afa-37c4-4afd-d4d7-ab7cf01ed6ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2759 entries, 0 to 3270\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        2759 non-null   object\n",
            " 1   sentimiento  2759 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 64.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzFpQ4smRcug"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Machine Learning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Z6MSbMjXPuLy",
        "outputId": "b528d000-0676-4c81-b439-f7794a110736"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Acabo de adoptar a un lindo amigo peludo!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Adoracion desbordante por un lindo cachorro r...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°A√±o nuevo, nuevos objetivos de fitness!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>¬°Celebrando el cumplea√±os de un amigo esta noc...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>Debes amar sin miedo a ser traicionado</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>No podemos vivir con miedo: ¬°Manejen borrachos...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>La vida es un constante, SIN MIEDO AL EXITO ????</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>Esquizofrenia = mente dividida: Miedo a las re...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>\"Lo que mas miedo me da, es ver como desaparec...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2759 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0          ¬°Acabo de adoptar a un lindo amigo peludo!??    positivo\n",
              "1      ¬°Acabo de terminar un entrenamiento increible!??    positivo\n",
              "2     ¬°Adoracion desbordante por un lindo cachorro r...    positivo\n",
              "3            ¬°A√±o nuevo, nuevos objetivos de fitness!??    positivo\n",
              "4     ¬°Celebrando el cumplea√±os de un amigo esta noc...    positivo\n",
              "...                                                 ...         ...\n",
              "3266             Debes amar sin miedo a ser traicionado    positivo\n",
              "3267  No podemos vivir con miedo: ¬°Manejen borrachos...    positivo\n",
              "3268   La vida es un constante, SIN MIEDO AL EXITO ????    positivo\n",
              "3269  Esquizofrenia = mente dividida: Miedo a las re...    positivo\n",
              "3270  \"Lo que mas miedo me da, es ver como desaparec...    positivo\n",
              "\n",
              "[2759 rows x 2 columns]"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1E-xGVFPuLy",
        "outputId": "af34e479-4b90-40c3-9fb9-6b211049ebc6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\marely\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Descargar palabras vac√≠as\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    texto = \" \".join([word for word in texto.split() if word not in stop_words]) # Quitar stopwords\n",
        "    return texto\n",
        "\n",
        "# Aplicar a tu dataset\n",
        "df['texto'] = df['texto'].apply(limpiar_texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3SJfTa-EPuLy",
        "outputId": "8f0e81ea-5194-4b76-bc08-da47a34879df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Acabo adoptar lindo amigo peludo!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¬°Acabo terminar entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Adoracion desbordante lindo cachorro rescatad...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°A√±o nuevo, nuevos objetivos fitness!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>¬°Celebrando cumplea√±os amigo noche!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>Debes amar miedo ser traicionado</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>No podemos vivir miedo: ¬°Manejen borrachos, de...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>La vida constante, SIN MIEDO AL EXITO ????</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>Esquizofrenia = mente dividida: Miedo realidad...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>\"Lo mas miedo da, ver desapareces mundo, mas t...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2759 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0                  ¬°Acabo adoptar lindo amigo peludo!??    positivo\n",
              "1            ¬°Acabo terminar entrenamiento increible!??    positivo\n",
              "2     ¬°Adoracion desbordante lindo cachorro rescatad...    positivo\n",
              "3               ¬°A√±o nuevo, nuevos objetivos fitness!??    positivo\n",
              "4                 ¬°Celebrando cumplea√±os amigo noche!??    positivo\n",
              "...                                                 ...         ...\n",
              "3266                   Debes amar miedo ser traicionado    positivo\n",
              "3267  No podemos vivir miedo: ¬°Manejen borrachos, de...    positivo\n",
              "3268         La vida constante, SIN MIEDO AL EXITO ????    positivo\n",
              "3269  Esquizofrenia = mente dividida: Miedo realidad...    positivo\n",
              "3270  \"Lo mas miedo da, ver desapareces mundo, mas t...    positivo\n",
              "\n",
              "[2759 rows x 2 columns]"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LH5NgVcQKEx"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGMacHrPuLy"
      },
      "source": [
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpuPPs85PuLy",
        "outputId": "d951e761-c419-4b21-b291-4556609fbec8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)Librer√≠a 'imblearn' instalada exitosamente.\n",
            "\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('pip install imblearn')\n",
        "print(\"Librer√≠a 'imblearn' instalada exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx2DlzvEPuLz"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFz0LAY_PuLz",
        "outputId": "16105818-3ccf-4d7e-e926-0abc4259c07d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n inicial de las clases:\n",
            "sentimiento\n",
            "positivo    1177\n",
            "negativo    1091\n",
            "neutral      491\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "# Verificar la distribuci√≥n inicial de las clases\n",
        "print(\"Distribuci√≥n inicial de las clases:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIbtwkkQhx0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbfr-opZPuLz"
      },
      "source": [
        "\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoyoVnuNPuLz",
        "outputId": "5f597fb6-5068-48e6-ede7-d9e921e6e302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tama√±o del conjunto de entrenamiento (desbalanceado): 2207 muestras\n",
            "Tama√±o del conjunto de prueba: 552 muestras\n",
            "Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\n",
            "sentimiento\n",
            "positivo    941\n",
            "negativo    873\n",
            "neutral     393\n",
            "Name: count, dtype: int64\n",
            "Distribuci√≥n de clases en el conjunto de prueba:\n",
            "sentimiento\n",
            "positivo    236\n",
            "negativo    218\n",
            "neutral      98\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\n",
            "Forma de X_train_tfidf_unbalanced: (2207, 5000)\n",
            "Forma de X_test_tfidf: (552, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Dividir el dataset en conjuntos de entrenamiento y prueba ANTES de aplicar SMOTE\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTama√±o del conjunto de entrenamiento (desbalanceado): {len(X_train_unbalanced)} muestras\")\n",
        "print(f\"Tama√±o del conjunto de prueba: {len(X_test)} muestras\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\\n{y_train_unbalanced.value_counts()}\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de prueba:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Inicializar TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(1,2)) # Limitando las caracter√≠sticas para eficiencia\n",
        "\n",
        "# Ajustar y transformar X_train_unbalanced, y transformar X_test\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nVectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\")\n",
        "print(f\"Forma de X_train_tfidf_unbalanced: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"Forma de X_test_tfidf: {X_test_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpTP-d7RHYa"
      },
      "source": [
        "### <font size=12 color=lightgreen> Balanceo del Conjunto de Entrenamiento con SMOTE</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_FmuXRPuLz"
      },
      "source": [
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHm0iiw1PuLz",
        "outputId": "79e547e7-57fa-4de6-a6b8-29f951b9f0a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\n",
            "sentimiento\n",
            "negativo    941\n",
            "positivo    941\n",
            "neutral     941\n",
            "Name: count, dtype: int64\n",
            "Forma de X_train_tfidf despu√©s de SMOTE: (2823, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Inicializar SMOTE para balancear el conjunto de datos de ENTRENAMIENTO\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"\\nDistribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"Forma de X_train_tfidf despu√©s de SMOTE: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5mkvXaQlFi"
      },
      "source": [
        "### <font size=12 color=lightgreen> Entrenamiento del Modelo de Regresi√≥n Log√≠stica</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_cggSuxPuLz"
      },
      "source": [
        "\n",
        "\n",
        "Entrenaremos un modelo de Regresi√≥n Log√≠stica utilizando los datos de entrenamiento balanceados y vectorizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4cR6qbPuLz",
        "outputId": "2f0d87bb-f3e3-4673-f5c9-29f48329e824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Modelo de Regresi√≥n Log√≠stica entrenado.\n"
          ]
        }
      ],
      "source": [
        "# Entrenar el Modelo de Regresi√≥n Log√≠stica\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"\\nModelo de Regresi√≥n Log√≠stica entrenado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq-wLkyQmaI"
      },
      "source": [
        "### <font size=12 color=lightgreen>Evaluaci√≥n del Modelo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNhozE5IPuLz"
      },
      "source": [
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3o_bP1aPuL0",
        "outputId": "9be4e27a-e73e-4a4e-d7b1-199f2947ce4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluaci√≥n del Modelo:\n",
            "Accuracy: 0.78\n",
            "Precision (ponderada): 0.78\n",
            "Recall (ponderado): 0.78\n",
            "F1-Score (ponderado): 0.78\n",
            "\n",
            "Reporte de Clasificaci√≥n:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.82      0.84      0.83       218\n",
            "     neutral       0.66      0.66      0.66        98\n",
            "    positivo       0.80      0.78      0.79       236\n",
            "\n",
            "    accuracy                           0.78       552\n",
            "   macro avg       0.76      0.76      0.76       552\n",
            "weighted avg       0.78      0.78      0.78       552\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el Modelo\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "y_pred_proba = model.predict_proba(X_test_tfidf)\n",
        "\n",
        "print(\"\\nEvaluaci√≥n del Modelo:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(f\"Precision (ponderada): {precision_score(y_test, y_pred, average='weighted'):.2f}\")\n",
        "print(f\"Recall (ponderado): {recall_score(y_test, y_pred, average='weighted'):.2f}\")\n",
        "print(f\"F1-Score (ponderado): {f1_score(y_test, y_pred, average='weighted'):.2f}\")\n",
        "print(\"\\nReporte de Clasificaci√≥n:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye01V19FQn7Z"
      },
      "source": [
        "### <font size=12 color=lightgreen> Serializaci√≥n del Modelo y Vectorizadors</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r68b_Sx6PuL0"
      },
      "source": [
        "\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meOQ2yohPuL0",
        "outputId": "dc729218-c63b-43e2-dbab-14c33e674c75"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[207], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(model, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKTLn4ylPuL0"
      },
      "source": [
        "### Prueba del Modelo con Salida JSON\n",
        "\n",
        "Crearemos una funci√≥n para probar el modelo con nuevas rese√±as de texto. Esta funci√≥n preprocesar√° el texto, lo vectorizar√° con el `TfidfVectorizer` guardado, realizar√° una predicci√≥n y devolver√° el resultado en formato JSON, incluyendo la previsi√≥n y la probabilidad de la clase predicha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q-eYggXPuL0",
        "outputId": "fc48dfe3-863f-47fa-c2a6-6106b61ca2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicci√≥n para 'Tengo hambre':\n",
            "{\n",
            "    \"prevision\": \"negativo\",\n",
            "    \"probabilidad\": 34.5\n",
            "}\n",
            "\n",
            "Predicci√≥n para 'mala actitud del personal':\n",
            "{\n",
            "    \"prevision\": \"positivo\",\n",
            "    \"probabilidad\": 55.58\n",
            "}\n",
            "\n",
            "Predicci√≥n para 'La situaci√≥n es complicada, no s√© qu√© pensar.':\n",
            "{\n",
            "    \"prevision\": \"neutral\",\n",
            "    \"probabilidad\": 42.59\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Recargar el modelo y el vectorizador para probar (como si fuera una nueva sesi√≥n/API)\n",
        "loaded_model = joblib.load('/content/modelo_sentimientos.pkl')\n",
        "loaded_vectorizer = joblib.load('/content/vectorizador.pkl')\n",
        "\n",
        "def predict_sentiment_json(text_review):\n",
        "    # Preprocesamiento (igual que para los datos de entrenamiento)\n",
        "    # Asumiendo que `pre_proccess_text` y `limpiar_texto` est√°n definidos en celdas anteriores\n",
        "    cleaned_text = limpiar_texto(text_review)\n",
        "    cleaned_text = limpiar_texto(cleaned_text)\n",
        "\n",
        "    # Vectorizar el texto limpio\n",
        "    text_vectorized = loaded_vectorizer.transform([cleaned_text])\n",
        "\n",
        "    # Predecir el sentimiento\n",
        "    prediction = loaded_model.predict(text_vectorized)[0]\n",
        "\n",
        "    # Predecir las probabilidades\n",
        "    probabilities = loaded_model.predict_proba(text_vectorized)[0]\n",
        "    class_labels = loaded_model.classes_\n",
        "    # Asegurar el mapeo correcto de probabilidades a etiquetas\n",
        "    prob_dict = {label: round(prob * 100, 2) for label, prob in zip(class_labels, probabilities)}\n",
        "\n",
        "    # Obtener la probabilidad de la clase predicha\n",
        "    predicted_prob = prob_dict[prediction]\n",
        "\n",
        "    result = {\n",
        "        \"prevision\": prediction,\n",
        "        \"probabilidad\": predicted_prob\n",
        "    }\n",
        "    return json.dumps(result, indent=4)\n",
        "\n",
        "# Ejemplos de uso de la funci√≥n de predicci√≥n\n",
        "new_review1 = \"Tengo hambre\"\n",
        "new_review2 = \"mala actitud del personal\"\n",
        "new_review3 = \"La situaci√≥n es complicada, no s√© qu√© pensar.\"\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review1}':\")\n",
        "print(predict_sentiment_json(new_review1))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review2}':\")\n",
        "print(predict_sentiment_json(new_review2))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review3}':\")\n",
        "print(predict_sentiment_json(new_review3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYeFtgokPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1xQz3UgPuL0",
        "outputId": "5fe3093f-2375-4307-d6a8-27f7efd4e36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prueba del pipeline: ['negativo']\n",
            "‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "# Este es el archivo que debes subir a la carpeta de tu microservicio\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e1WimRtik1c6",
        "VengB6XbODtf",
        "NEXpMdxbOQAV",
        "EkmazYt9QBYT",
        "szn46SXAhzyW",
        "ppTw4PLfmrRx",
        "mWAtT-iQm7fM",
        "NYvX17ceGa1i"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
