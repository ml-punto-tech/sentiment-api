{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import uvicorn\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "from io import StringIO\n",
        "import urllib.response\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de los datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "yOwHw3xtYJEg"
      },
      "outputs": [],
      "source": [
        "def importar_dataset(url, sep=';'):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL detectando encoding autom√°ticamente.\n",
        "    Acepta un argumento `sep` para especificar el separador del CSV (por defecto ';').\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Descargar contenido una sola vez\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "\n",
        "        # 2. Detectar encoding\n",
        "        result = chardet.detect(content)\n",
        "        encoding = result['encoding']\n",
        "        print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "\n",
        "        # 3. Decodificar y cargar en DataFrame\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        data = pd.read_csv(StringIO(decoded_content), sep=sep)\n",
        "\n",
        "        print(\"‚úÖ Archivo cargado correctamente\")\n",
        "        print(f\"üìä Tama√±o del dataset: {data.shape}\")\n",
        "        print(\"\\nüîç Muestra aleatoria (3 registros):\")\n",
        "        print(data.sample(3))\n",
        "\n",
        "        return data\n",
        "\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e}\")\n",
        "        return None\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ùå Error al parsear CSV: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZW5B7jk5-x"
      },
      "source": [
        "#### **Dataset1: sentimentdataset_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWgPb0VhYeKT",
        "outputId": "1265d274-21aa-4f74-b3b7-e0a7d18e6a1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 72.97%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (731, 15)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "     Unnamed: 0.1  Unnamed: 0  \\\n",
            "525           527         531   \n",
            "358           359         363   \n",
            "14             14          14   \n",
            "\n",
            "                                                  Text    Sentiment  \\\n",
            "525  En un concierto de U2, los acordes del himno d...      Neutral   \n",
            "358  Apreciaci√≥n por la vibrante cultura experiment...  Apreciaci√≥n   \n",
            "14   La tecnolog√≠a est√° cambiando la forma en que v...      Neutral   \n",
            "\n",
            "            Timestamp                User   Platform  \\\n",
            "525  15-05-2016 19:30  U2ConnectionSeeker  Instagram   \n",
            "358  14-11-2016 13:45     CultureExplorer    Twitter   \n",
            "14    19-01-2023 9:45      TechEnthusiast    Twitter   \n",
            "\n",
            "                              Hashtags  Retweets  Likes      Country  Year  \\\n",
            "525                #Conexi√≥n #U2Anthem        25     50      Irlanda  2016   \n",
            "358  #Apreciaci√≥n #ExperienciaCultural        28     55  Reino Unido  2016   \n",
            "14             #Tecnolog√≠a #Innovaci√≥n        15     30        India  2023   \n",
            "\n",
            "     Month  Day  Hour  \n",
            "525      5   15    19  \n",
            "358     11   14    13  \n",
            "14       1   19     9  \n"
          ]
        }
      ],
      "source": [
        "df1_url_es = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset1_esp.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKr3W1NEaBrP"
      },
      "source": [
        "#### **Dataset2: sentiment_analysis_dataset.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2eRhM-MYh6L",
        "outputId": "e224480a-7b3e-44c6-ec3f-dea83217a6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (2540, 3)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "                                                  texto  label sentimiento\n",
            "1247  ¬°Descubre el poder de Mar√≠a! ???? Convi√©rtete ...      2    positivo\n",
            "2157  La historia primero como mito, m√°s tarde como ...      1     neutral\n",
            "1124                             Creo que pedir√© pan xd      0    negativo\n"
          ]
        }
      ],
      "source": [
        "df2_url_es = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset2_esp.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmMcmf9gyZpS",
        "outputId": "59797edf-93fb-42fc-b82e-8f20bf2f8763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1254 (confianza: 56.84%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (740, 4)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "       id plataforma sentimiento  \\\n",
            "248  9149     Nvidia     Neutral   \n",
            "597  6713   Fortnite     Neutral   \n",
            "253  9153     Nvidia     Neutral   \n",
            "\n",
            "                                                 texto  \n",
            "248  ¬´ Nvidia Shield no es mi dispositivo de uso di...  \n",
            "597  @ClixHimself Todos usen el c√≥digo Notclix en l...  \n",
            "253  Ganar pruebas de benchmark es excelente para e...  \n"
          ]
        }
      ],
      "source": [
        "df3_url_es = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/dataset3_esp.csv\", sep=',') # Probando con ',' como separador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNDDOVQQ8MA-"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RMmgpQO8MA_",
        "outputId": "2764d8bf-e0f2-4484-c9b4-33cf9853d0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 texto  sentimiento\n",
            "388  La euforia inunda cuando la √∫ltima pieza del r...      Euforia\n",
            "340  Surgen emociones agridulces al despedirse de u...      Neutral\n",
            "322  Ojos temerosos que escanean las sombras, prisi...     Temeroso\n",
            "592  Decidi√≥ aprender un nuevo instrumento.D√≠a uno:...  Frustraci√≥n\n",
            "669  Intentando establecer un nuevo r√©cord de m√°s p...   Excitaci√≥n\n",
            "                                                  texto sentimiento\n",
            "183   Es que estaba claro que en las fiestas DENI y ...    negativo\n",
            "556                                 Frustrado y la csmr    negativo\n",
            "755   viernes 23:58  me puse a jugar al solitario se...    negativo\n",
            "1197  Que tiene como casi dos horas vi√©ndose la espa...    positivo\n",
            "1704  Quiero volver a ser el yo de antes, sin preocu...    positivo\n",
            "                                                 texto sentimiento\n",
            "430  Para quienes juegan CS:GO y sufren tirones, ac...     Neutral\n",
            "587                  ¬øVale la pena reiniciar Fortnite?     Neutral\n",
            "722  Amenaza | Servidor abusado de Microsoft Hot Sw...     Neutral\n",
            "50   Como no, es casi seguro que no necesitar√É¬°s qu...     Neutral\n",
            "637  ¬øEpic vs. Apple? Ahora bien, si esto es algo m...     Neutral\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n filtrar dataset\n",
        "def filtrar_dataset(data):\n",
        "    data_filtro = data[['texto', 'sentimiento']]\n",
        "    data_filtro = data_filtro[data_filtro['texto'].str.strip() != \"\"]\n",
        "    print(data_filtro.sample(3))\n",
        "    return data_filtro\n",
        "\n",
        "# Reemplazar nombre columnas Text por texto, Sentiment por sentimiento\n",
        "df1_raw.rename({'Text':'texto', 'Sentiment':'sentimiento'}, axis=1, inplace=True)\n",
        "df1_filtrado = filtrar_dataset(df1_raw)\n",
        "df2_filtrado = filtrar_dataset(df2_raw)\n",
        "df3_filtrado = filtrar_dataset(df3_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmazYt9QBYT"
      },
      "source": [
        "### <font size= 12 color=\"lightgreen\" >Explorando los datasets<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "TarluP_c8MA_"
      },
      "outputs": [],
      "source": [
        "# Crear funci√≥n para explorar datasets\n",
        "def explorar_dataset(data):\n",
        "    print('Filas: ' + str(data.shape[0]))\n",
        "    print('Columnas: ' + str(data.shape[1]))\n",
        "    print('\\nColumnas: \\n' + str(data.columns.tolist()))\n",
        "    print('\\nTipo de datos: \\n' + str(data.dtypes))\n",
        "    print('\\nValores nulos: \\n' + str(data.isnull().sum()))\n",
        "    print('\\nMuestra aleatoria (5 registros): \\n' + str(data.sample(5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-OpMWf0l8DM"
      },
      "source": [
        "#### **Explorando Data1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0SICtaLs770",
        "outputId": "e1572150-79c0-4c08-98fe-7ab3c4fe14f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 731\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto sentimiento\n",
            "198  El complejo rompecabezas de la vida me deja en...     Neutral\n",
            "594  Cocin√© con √©xito una comida gourmet para la fa...     Orgullo\n",
            "295  Una escapada l√∫dica al carnaval de la vida, ri...    Positivo\n",
            "696  Enfrentando el rechazo de la universidad de su...    Tristeza\n",
            "188  Asco ante la corrupci√≥n que mancha a la sociedad.        Asco\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfglf1PjDfz"
      },
      "source": [
        "#### **Explorando data2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvetNKaKfI3X",
        "outputId": "08205418-118b-4f38-e70a-473e2b50dcad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 731\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto    sentimiento\n",
            "405  Saboreando el calor de una taza de chocolate e...        Neutral\n",
            "193  El resentimiento se pudre, una herida que se n...  Resentimiento\n",
            "278  Una lluvia compasiva, l√°grimas de empat√≠a caye...        Neutral\n",
            "217  Pasar el d√≠a con un comportamiento indiferente...        Neutral\n",
            "164  Abrumado por el dolor, extra√±ando profundament...          Dolor\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKjMJtnFzPRg",
        "outputId": "4d7ffdcd-cbe1-4228-ef62-78ceb4da1bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 740\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto sentimiento\n",
            "609  Apple acaba de lanzarse a la guerra nuclear co...     Neutral\n",
            "384  Horario del servicio de mini transmisi√≥n: mi√©r...     Neutral\n",
            "739  Yo tend√≠a a pensar que Ellison era un buen tip...     Neutral\n",
            "218  Mac es una basura... dificultan el uso de tarj...     Neutral\n",
            "599  @ Clixself Todos usan el c√≥digo Notclix en una...     Neutral\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df3_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOAtZ3kK8MBA"
      },
      "source": [
        "#### **An√°lisis proceso de limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "enJAqTD68MBA"
      },
      "outputs": [],
      "source": [
        "def analizar_limpieza_sentimientos(df_antes, df_despues, nombre):\n",
        "    \"\"\"\n",
        "    An√°lisis espec√≠fico para tu funci√≥n limpiar_texto_para_sentimientos\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç AN√ÅLISIS ESPEC√çFICO: {nombre}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Cambios en caracteres espec√≠ficos del espa√±ol\n",
        "    cambios_especificos = {\n",
        "        'tildes_eliminadas': 0,\n",
        "        '√±_preservadas': 0,\n",
        "        'urls_eliminadas': 0,\n",
        "        'mayusculas_preservadas': 0\n",
        "    }\n",
        "\n",
        "    # Muestra de 50 textos para an√°lisis detallado\n",
        "    muestra = min(50, len(df_antes))\n",
        "\n",
        "    for i in range(muestra):\n",
        "        if i < len(df_despues):\n",
        "            texto_antes = str(df_antes.iloc[i]['texto'])\n",
        "            texto_despues = str(df_despues.iloc[i]['texto'])\n",
        "\n",
        "            # Contar √± preservadas\n",
        "            if '√±' in texto_antes.lower() and '√±' in texto_despues.lower():\n",
        "                cambios_especificos['√±_preservadas'] += 1\n",
        "\n",
        "            # Contar URLs eliminadas\n",
        "            import re\n",
        "            urls_antes = len(re.findall(r'https?://\\S+', texto_antes))\n",
        "            urls_despues = len(re.findall(r'https?://\\S+', texto_despues))\n",
        "            if urls_antes > urls_despues:\n",
        "                cambios_especificos['urls_eliminadas'] += (urls_antes - urls_despues)\n",
        "\n",
        "            # Verificar may√∫sculas preservadas\n",
        "            mayus_antes = sum(1 for c in texto_antes if c.isupper())\n",
        "            mayus_despues = sum(1 for c in texto_despues if c.isupper())\n",
        "            if mayus_antes > 0 and mayus_despues > 0:\n",
        "                cambios_especificos['mayusculas_preservadas'] += 1\n",
        "\n",
        "    print(\"üìä Cambios espec√≠ficos de tu limpiador:\")\n",
        "    for cambio, cantidad in cambios_especificos.items():\n",
        "        print(f\"   ‚Ä¢ {cambio.replace('_', ' ').title()}: {cantidad} de {muestra} textos\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYkBr6o-8MBA",
        "outputId": "a80b78a8-4d49-4164-d9cd-9918feb82b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÅ Dataset 1\n",
            "   Registros: 731\n",
            "   Muestra (3 textos):\n",
            "                                                 texto  \\\n",
            "398  Montar la adrenalina en los giros salvajes de ...   \n",
            "320  La soledad, una luna solitaria en un cielo sin...   \n",
            "577  Mientras las olas rompen contra la orilla, el ...   \n",
            "\n",
            "                                          Texto_Limpio  \n",
            "398  Montar la adrenalina en los giros salvajes de ...  \n",
            "320  La soledad, una luna solitaria en un cielo sin...  \n",
            "577  Mientras las olas rompen contra la orilla, el ...  \n",
            "\n",
            "üìÅ Dataset 2\n",
            "   Registros: 2,540\n",
            "   Muestra (3 textos):\n",
            "                                                  texto  \\\n",
            "630                                           impotente   \n",
            "440   ¬´Nos hiciste, Se√±or, para ti, y nuestro coraz√≥...   \n",
            "1277  Mk ahora si me mareo con una copa y el sereno ...   \n",
            "\n",
            "                                           Texto_Limpio  \n",
            "630                                           impotente  \n",
            "440   ¬´Nos hiciste, Se√±or, para ti, y nuestro corazo...  \n",
            "1277  Mk ahora si me mareo con una copa y el sereno ...  \n",
            "\n",
            "üìÅ Dataset 3\n",
            "   Registros: 740\n",
            "   Muestra (3 textos):\n",
            "                                                 texto  \\\n",
            "314  √Ç¬°√É‚Ä∞chales un vistazo a esta hermosa AORUS GeF...   \n",
            "418           De ti sentir la belleza de un paisaje...   \n",
            "559  ¬°A por todas! ¬°Cr√≠as! ¬°Vuelvan, pasen un rato ...   \n",
            "\n",
            "                                          Texto_Limpio  \n",
            "314  A¬°A‚Ä∞chales un vistazo a esta hermosa AORUS GeF...  \n",
            "418           De ti sentir la belleza de un paisaje...  \n",
            "559  ¬°A por todas! ¬°Crias! ¬°Vuelvan, pasen un rato ...  \n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 1\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 5 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 50 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 2\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 7 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 43 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 3\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 1 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 50 de 50 textos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Lista de dataframes para procesar\n",
        "dataframes = [\n",
        "    (df1_filtrado, \"Dataset 1\"),\n",
        "    (df2_filtrado, \"Dataset 2\"),\n",
        "    (df3_filtrado, \"Dataset 3\")\n",
        "]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for df, nombre in dataframes:\n",
        "    # Aplicar limpieza\n",
        "    df['Texto_Limpio'] = df['texto'].apply(limpiar_texto_sentimientos)\n",
        "\n",
        "    # Guardar copia limpia\n",
        "    resultados[nombre] = df.copy()\n",
        "\n",
        "    # Mostrar info\n",
        "    print(f\"\\nüìÅ {nombre}\")\n",
        "    print(f\"   Registros: {len(df):,}\")\n",
        "    print(f\"   Muestra (3 textos):\")\n",
        "    print(df[['texto', 'Texto_Limpio']].sample(3))\n",
        "\n",
        "# Asignar a variables originales\n",
        "df1_clean = resultados[\"Dataset 1\"]\n",
        "df2_clean = resultados[\"Dataset 2\"]\n",
        "df3_clean = resultados[\"Dataset 3\"]\n",
        "\n",
        "analizar_limpieza_sentimientos(df1_filtrado, df1_clean, \"Dataset 1\")\n",
        "analizar_limpieza_sentimientos(df2_filtrado, df2_clean, \"Dataset 2\")\n",
        "analizar_limpieza_sentimientos(df3_filtrado, df3_clean, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "pvjzAeYF8MBB",
        "outputId": "d1899b07-8f33-4a06-b340-ef982e90d6f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>Sentirse bendecido por la comunidad solidaria ...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Sentirse bendecido por la comunidad solidaria ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>Una determinaci√≥n ardiente arde en su interior...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Una determinacion ardiente arde en su interior...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>Susurros de inspiraci√≥n provenientes del susur...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Susurros de inspiracion provenientes del susur...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "353  Sentirse bendecido por la comunidad solidaria ...    Positivo   \n",
              "224  Una determinaci√≥n ardiente arde en su interior...    Positivo   \n",
              "384  Susurros de inspiraci√≥n provenientes del susur...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "353  Sentirse bendecido por la comunidad solidaria ...  \n",
              "224  Una determinacion ardiente arde en su interior...  \n",
              "384  Susurros de inspiracion provenientes del susur...  "
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "iuyv_0yC8MBB",
        "outputId": "b44fd853-8f6c-49c5-ad4c-1a50cabb181a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1806</th>\n",
              "      <td>tambi√©n tengo qe aceptar q ya no es mi lugar s...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>tambien tengo qe aceptar q ya no es mi lugar s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>Algo que me parece incre√≠ble y muy molesto de ...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Algo que me parece increible y muy molesto de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>Lo de √ìscar Puente trayendo el AVE a Vigo la n...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Lo de Oscar Puente trayendo el AVE a Vigo la n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1806  tambi√©n tengo qe aceptar q ya no es mi lugar s...     neutral   \n",
              "384   Algo que me parece incre√≠ble y muy molesto de ...    negativo   \n",
              "1337  Lo de √ìscar Puente trayendo el AVE a Vigo la n...    positivo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "1806  tambien tengo qe aceptar q ya no es mi lugar s...  \n",
              "384   Algo que me parece increible y muy molesto de ...  \n",
              "1337  Lo de Oscar Puente trayendo el AVE a Vigo la n...  "
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FdZ-xdKa6Vn-",
        "outputId": "218258eb-3a1e-4067-a90e-0ea62fb82cb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>Bip bip . . store.playstation.com/</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Bip bip . . store.playstation.com/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>Microsoft News afirma que se est√°n preparando ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Microsoft News afirma que se estan preparando ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>GPU NVIDIA GeForce RTX 3090 y RTX 3080 Creator...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>GPU NVIDIA GeForce RTX 3090 y RTX 3080 Creator...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "549                 Bip bip . . store.playstation.com/     Neutral   \n",
              "668  Microsoft News afirma que se est√°n preparando ...     Neutral   \n",
              "295  GPU NVIDIA GeForce RTX 3090 y RTX 3080 Creator...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "549                 Bip bip . . store.playstation.com/  \n",
              "668  Microsoft News afirma que se estan preparando ...  \n",
              "295  GPU NVIDIA GeForce RTX 3090 y RTX 3080 Creator...  "
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2mOLfmB8MBB"
      },
      "source": [
        "#### **Categor√≠as Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObmR6SmO8MBB",
        "outputId": "38064e4c-e845-4bac-9910-6255c3c837e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos √∫nicos: 104\n",
            "['Abrumado', 'Aburrimiento', 'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Aislamiento', 'Alegr√≠a', 'Amabilidad', 'Amargura', 'Ambivalencia', 'Amistad', 'Amor', 'Angustia', 'Anhelo', 'Ansiedad', 'Anticipaci√≥n', 'Apreciaci√≥n', 'Aprensivo', 'Armon√≠a', 'Arrepentimiento', 'Asco', 'Asombro', 'Cautivaci√≥n', 'Celebraci√≥n', 'Colorido', 'Confiado', 'Confianza', 'Contentamiento', 'Creatividad', 'Cumplimiento', 'Curiosidad', 'Decepci√≥n', 'Desamor', 'Descubrimiento', 'Desesperaci√≥n', 'Deslumbrar', 'Despectivo', 'Determinaci√≥n', 'Devastado', 'Disfrute', 'Diversi√≥n', 'Dolor', 'Elegancia', 'Emoci√≥n', 'Empoderamiento', 'Emp√°tico', 'Encantamiento', 'Energ√≠a', 'Enojo', 'Entumecimiento', 'Entusiasmo', 'Envidia', 'Envidioso', 'Esperanza', 'Euforia', 'Excitaci√≥n', 'Felicidad', 'Frustraci√≥n', 'Frustrado', 'Grandeza', 'Gratitud', 'Inspiraci√≥n', 'Inspirado', 'Intimidaci√≥n', 'Juguet√≥n', 'Logro', 'L√°stima', 'Malo', 'Maravilla', 'Melancol√≠a', 'Mel√≥dico', 'Miedo', 'Motivaci√≥n', 'Negativo', 'Neutral', 'Obst√°culo', 'Odiar', 'Optimismo', 'Orgullo', 'Pena', 'Positividad', 'Positivo', 'P√©rdida', 'Reconfortante', 'Reflexi√≥n', 'Resentimiento', 'Resiliencia', 'Resplandor', 'Reverencia', 'Romance', 'Satisfacci√≥n', 'Serenidad', 'Soledad', 'Sorpresa', 'Sufrimiento', 'Temeroso', 'Ternura', 'Traici√≥n', 'Tristeza', 'Triunfo', 'Verguenza', '√Ånimo', '√âxito']\n",
            "Sentimientos positivos: 62\n",
            "Sentimientos negativos: 39\n",
            "Sentimientos neutros: 5\n",
            "\n",
            "‚úÖ Total clasificado: 106/106 sentimientos\n",
            "   - Positivos: 62 (58.5%)\n",
            "   - Negativos: 39 (36.8%)\n",
            "   - Neutros: 5 (4.7%)\n",
            "Total: 106\n",
            "\n",
            "‚ùå Sentimiento no encontrado en el dataset: Elaci√≥n\n",
            "‚ùå Sentimiento no encontrado en el dataset: √âxtasis\n",
            "‚úÖ Todos los sentimientos del dataset est√°n clasificados.\n"
          ]
        }
      ],
      "source": [
        "# 1. Definimos las listas de sentimientos seg√∫n su categor√≠a\n",
        "# Ver todos los sentimientos √∫nicos para saber qu√© agrupar y ordenar alfabetizamente\n",
        "sentimientos_unicos = sorted(df1_clean['sentimiento'].unique())\n",
        "print(f\"Total de sentimientos √∫nicos: {len(sentimientos_unicos)}\")\n",
        "print(sentimientos_unicos)\n",
        "\n",
        "# 2. SENTIMIENTOS POSITIVOS COMPLETOS (Bienestar, √©xito, alegr√≠a, admiraci√≥n)\n",
        "positivos = [\n",
        "    'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Alegr√≠a', 'Amabilidad', 'Amor', 'Amistad', 'Apreciaci√≥n', 'Armon√≠a', 'Asombro', 'Cautivaci√≥n', 'Celebraci√≥n', 'Colorido', 'Confiado','Confianza', 'Contentamiento', 'Creatividad', 'Cumplimiento', 'Descubrimiento', 'Deslumbrar', 'Determinaci√≥n', 'Disfrute','Diversi√≥n', 'Elegancia', 'Emoci√≥n', 'Emp√°tico', 'Empoderamiento',\n",
        "    'Encantamiento', 'Energ√≠a', 'Entusiasmo', 'Esperanza', 'Euforia', 'Excitaci√≥n', 'Felicidad', 'Grandeza', 'Gratitud', 'Inspiraci√≥n', 'Inspirado', 'Intimidaci√≥n', 'Juguet√≥n', 'Logro','Maravilla', 'Mel√≥dico', 'Motivaci√≥n', 'Optimismo', 'Orgullo',\n",
        "    'Positividad', 'Positivo', 'Reconfortante', 'Resiliencia', 'Resplandor', 'Reverencia', 'Romance', 'Satisfacci√≥n', 'Serenidad','Ternura', 'Triunfo', '√Ånimo', '√âxito','Elaci√≥n','√âxtasis']\n",
        "print(f'Sentimientos positivos: {len(positivos)}'),\n",
        "\n",
        "# 3. SENTIMIENTOS NEGATIVOS COMPLETOS (Dolor, ira, miedo, estr√©s, p√©rdida)\n",
        "negativos = [\n",
        "    'Abrumado', 'Aburrimiento', 'Aislamiento', 'Amargura', 'Angustia', 'Anhelo', 'Ansiedad', 'Aprensivo', 'Arrepentimiento', 'Asco',  'Decepci√≥n', 'Desamor', 'Desesperaci√≥n', 'Despectivo', 'Devastado',\n",
        "    'Dolor', 'Enojo', 'Entumecimiento', 'Envidia', 'Envidioso', 'Frustraci√≥n', 'Frustrado', 'L√°stima', 'Obst√°culo', 'Malo', 'Melancol√≠a', 'Miedo', 'Negativo', 'Odiar', 'Pena', 'P√©rdida', 'Reflexi√≥n', 'Resentimiento', 'Soledad', 'Sufrimiento', 'Temeroso', 'Traici√≥n', 'Tristeza', 'Verguenza']\n",
        "print(f'Sentimientos negativos: {len(negativos)}')\n",
        "\n",
        "# 4. SENTIMIENTOS NEUTRALES (Estados ambiguos o contemplativos)\n",
        "neutros = ['Ambivalencia', 'Curiosidad', 'Neutral','Sorpresa','Anticipaci√≥n']\n",
        "print(f'Sentimientos neutros: {len(neutros)}')\n",
        "\n",
        "categorias = [positivos, negativos, neutros]\n",
        "\n",
        "# Verificaci√≥n del total\n",
        "total_clasificados = len(positivos) + len(negativos) + len(neutros)\n",
        "print(f'\\n‚úÖ Total clasificado: {total_clasificados}/106 sentimientos')\n",
        "print(f'   - Positivos: {len(positivos)} ({len(positivos)/106*100:.1f}%)')\n",
        "print(f'   - Negativos: {len(negativos)} ({len(negativos)/106*100:.1f}%)')\n",
        "print(f'   - Neutros: {len(neutros)} ({len(neutros)/106*100:.1f}%)')\n",
        "print(f'Total: {len(positivos) + len(negativos) + len(neutros)}')\n",
        "print()\n",
        "\n",
        "# Verificar si existen elementos en las listas que no se encuentran en la lista sentimientos_unicos\n",
        "for sentimiento in negativos + positivos + neutros:\n",
        "    if sentimiento not in sentimientos_unicos:\n",
        "        print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "\n",
        "# Verificar si todos los sentimientos del dataset est√°n clasificados\n",
        "for sentimiento in sentimientos_unicos:\n",
        "    if sentimiento not in positivos + negativos + neutros:\n",
        "        print(f\"‚ùå Sentimiento no clasificado: {sentimiento}\")\n",
        "else:\n",
        "    print(\"‚úÖ Todos los sentimientos del dataset est√°n clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzQa-9sE8MBB"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "ALbr-iTw8MBB"
      },
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias):\n",
        "    \"\"\"\n",
        "    Categoriza sentimientos solo si est√°n en las listas definidas.\n",
        "    Devuelve None para sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    sent = str(sentimiento).strip().title()\n",
        "\n",
        "    if sent in positivos:\n",
        "        return 'positivo'\n",
        "    elif sent in negativos:\n",
        "        return 'negativo'\n",
        "    elif sent in neutros:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        # Devolvemos None para posterior filtrado\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kg8aCie08MBC",
        "outputId": "6e4024a6-7460-4112-c21f-cba266b99ab3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>Nostalgia, un baile agridulce en el sal√≥n de b...</td>\n",
              "      <td>Orgullo</td>\n",
              "      <td>Nostalgia, un baile agridulce en el salon de b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>Reverencia por el significado hist√≥rico de un ...</td>\n",
              "      <td>Reverencia</td>\n",
              "      <td>Reverencia por el significado historico de un ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>Perdido en el laberinto de pensamientos, la co...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Perdido en el laberinto de pensamientos, la co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "279  Nostalgia, un baile agridulce en el sal√≥n de b...     Orgullo   \n",
              "148  Reverencia por el significado hist√≥rico de un ...  Reverencia   \n",
              "237  Perdido en el laberinto de pensamientos, la co...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "279  Nostalgia, un baile agridulce en el salon de b...  \n",
              "148  Reverencia por el significado historico de un ...  \n",
              "237  Perdido en el laberinto de pensamientos, la co...  "
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "l7_KDj778MBC",
        "outputId": "3d14f5e6-c776-41f2-95db-29c80ae5784e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>Por primera vez, indagaciones rondan dentro de...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Por primera vez, indagaciones rondan dentro de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>Me acabo de subir al carro de mi hermano, me s...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Me acabo de subir al carro de mi hermano, me s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>Despreocupado de lo que est√° pasando yo sigo s...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Despreocupado de lo que esta pasando yo sigo s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "448   Por primera vez, indagaciones rondan dentro de...    negativo   \n",
              "1447  Me acabo de subir al carro de mi hermano, me s...    positivo   \n",
              "2496  Despreocupado de lo que est√° pasando yo sigo s...    positivo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "448   Por primera vez, indagaciones rondan dentro de...  \n",
              "1447  Me acabo de subir al carro de mi hermano, me s...  \n",
              "2496  Despreocupado de lo que esta pasando yo sigo s...  "
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "S4m9ExgSzgfw",
        "outputId": "cde464ed-ef1f-4f5c-a99d-ed07c510eac3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>¬°O publica mi tutorial \"Aprende lo b√°sico con ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>¬°O publica mi tutorial \"Aprende lo basico con ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>¬øEs ella HULK?... store.playstation.com /</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>¬øEs ella HULK?... store.playstation.com /</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>La valoraci√É¬≥n de Nvidia se dispara en compara...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>La valoraciA¬≥n de Nvidia se dispara en compara...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "681  ¬°O publica mi tutorial \"Aprende lo b√°sico con ...     Neutral   \n",
              "616          ¬øEs ella HULK?... store.playstation.com /     Neutral   \n",
              "266  La valoraci√É¬≥n de Nvidia se dispara en compara...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "681  ¬°O publica mi tutorial \"Aprende lo basico con ...  \n",
              "616          ¬øEs ella HULK?... store.playstation.com /  \n",
              "266  La valoraciA¬≥n de Nvidia se dispara en compara...  "
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMKuIMHg8MBC"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edYTir6T8MBC",
        "outputId": "12d39bbb-cacb-4edd-8510-78b9471ceb7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ df1: 731 registros categorizados\n",
            "‚úÖ df2: 2540 registros categorizados\n",
            "‚úÖ df3: 740 registros categorizados\n"
          ]
        }
      ],
      "source": [
        "df1_clean['Sentimiento_Final'] = df1_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df1_categorized = df1_clean[df1_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df2_clean['Sentimiento_Final'] = df2_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df2_categorized = df2_clean[df2_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df3_clean['Sentimiento_Final'] = df3_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df3_categorized = df3_clean[df3_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "print(f\"‚úÖ df1: {len(df1_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df2: {len(df2_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df3: {len(df3_categorized)} registros categorizados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gq2bsqV_8MBC",
        "outputId": "6110aa71-c8d3-4602-e0da-be730317b416"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>Entr√© accidentalmente al sal√≥n de clases equiv...</td>\n",
              "      <td>Verguenza</td>\n",
              "      <td>Entre accidentalmente al salon de clases equiv...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>La armon√≠a resuena cuando los m√∫sicos tocan un...</td>\n",
              "      <td>Armon√≠a</td>\n",
              "      <td>La armonia resuena cuando los musicos tocan un...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>Inundado de serenidad mientras el sol se pone ...</td>\n",
              "      <td>Serenidad</td>\n",
              "      <td>Inundado de serenidad mientras el sol se pone ...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "680  Entr√© accidentalmente al sal√≥n de clases equiv...   Verguenza   \n",
              "379  La armon√≠a resuena cuando los m√∫sicos tocan un...     Armon√≠a   \n",
              "419  Inundado de serenidad mientras el sol se pone ...   Serenidad   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "680  Entre accidentalmente al salon de clases equiv...          negativo  \n",
              "379  La armonia resuena cuando los musicos tocan un...          positivo  \n",
              "419  Inundado de serenidad mientras el sol se pone ...          positivo  "
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1ZE7cB-t8MBD",
        "outputId": "fb216599-79f0-482c-850d-196a4f70b786"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1053</th>\n",
              "      <td>Ah, ojal√° poder guardar el d√≠a de hoy en un lu...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Ah, ojala poder guardar el dia de hoy en un lu...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2369</th>\n",
              "      <td>Choque m√∫ltiple 3 autos en costanera en brilla...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Choque multiple 3 autos en costanera en brilla...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2139</th>\n",
              "      <td>Trincado de haka e incr√©dulo</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Trincado de haka e incredulo</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1053  Ah, ojal√° poder guardar el d√≠a de hoy en un lu...    negativo   \n",
              "2369  Choque m√∫ltiple 3 autos en costanera en brilla...    positivo   \n",
              "2139                       Trincado de haka e incr√©dulo     neutral   \n",
              "\n",
              "                                           Texto_Limpio Sentimiento_Final  \n",
              "1053  Ah, ojala poder guardar el dia de hoy en un lu...          negativo  \n",
              "2369  Choque multiple 3 autos en costanera en brilla...          positivo  \n",
              "2139                       Trincado de haka e incredulo           neutral  "
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "LlQD_0y4zrC2",
        "outputId": "ee9947c7-817c-4422-87b1-b161f66fa013"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>@ClixHimself Todos usan el c√≥digo Notclix en l...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>@ClixHimself Todos usan el codigo Notclix en l...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>Threatpost | Controlamos el infierno en el ata...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Threatpost | Controlamos el infierno en el ata...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>Menos de 200</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Menos de 200</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "598  @ClixHimself Todos usan el c√≥digo Notclix en l...     Neutral   \n",
              "721  Threatpost | Controlamos el infierno en el ata...     Neutral   \n",
              "568                                       Menos de 200     Neutral   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "598  @ClixHimself Todos usan el codigo Notclix en l...           neutral  \n",
              "721  Threatpost | Controlamos el infierno en el ata...           neutral  \n",
              "568                                       Menos de 200           neutral  "
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwBnt_Bx8MBD"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar dataset unificado</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIqj6G-8MBD"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "SJD_1mN88MBD"
      },
      "outputs": [],
      "source": [
        "def limpiar_dataset_unificado(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('Texto_Limpio')['Sentimiento_Final'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['Texto_Limpio'] == texto]['Sentimiento_Final'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['Texto_Limpio'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['Texto_Limpio'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['Texto_Limpio'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['Texto_Limpio', 'Sentimiento_Final']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Texto_Limpio'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Sentimiento_Final'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['Texto_Limpio'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['Texto_Limpio'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['Sentimiento_Final'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "PW9PUf1G8MBE",
        "outputId": "aaffde8d-0319-436d-d74e-a32a22d59e73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>Creo que voy a perder el tiempo con esa transm...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Creo que voy a perder el tiempo con esa transm...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>649</th>\n",
              "      <td>Microsoft Surface Studio 2 es un dispositivo e...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Microsoft Surface Studio 2 es un dispositivo e...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>602</th>\n",
              "      <td>@ClixHimself Todos usen su Notclix para ir a l...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>@ClixHimself Todos usen su Notclix para ir a l...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "325  Creo que voy a perder el tiempo con esa transm...     Neutral   \n",
              "649  Microsoft Surface Studio 2 es un dispositivo e...     Neutral   \n",
              "602  @ClixHimself Todos usen su Notclix para ir a l...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "325  Creo que voy a perder el tiempo con esa transm...           neutral  \n",
              "649  Microsoft Surface Studio 2 es un dispositivo e...           neutral  \n",
              "602  @ClixHimself Todos usen su Notclix para ir a l...           neutral  "
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_categorized.sample(3)\n",
        "df2_categorized.sample(3)\n",
        "df3_categorized.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0i4m7Nf8MBE"
      },
      "source": [
        "#### **Unificar datataset y limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geihh0678MBE",
        "outputId": "93fca709-a0d1-4cfe-d6ce-e30d9a469b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó UNIFICANDO DATASETS CATEGORIZADOS\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (3271, 2)\n",
            "   ‚Ä¢ Registros: 3,271\n",
            "   ‚Ä¢ Textos √∫nicos: 2,848\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 3,271\n",
            "Textos √∫nicos iniciales: 2,848\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚ö†Ô∏è  Encontradas: 90 contradicciones\n",
            "   ‚Ä¢ Ejemplos (primeros 2):\n",
            "     - '\"De manera apacible, se puede sacudir el mundo\" MG'\n",
            "       ‚Üí Sentimientos: negativo, positivo\n",
            "     - '\"He aprendido que el valor no es la ausencia de miedo, sino ...'\n",
            "       ‚Üí Sentimientos: neutral, positivo\n",
            "   üóëÔ∏è  Eliminados: 212 registros por contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚ö†Ô∏è  Encontrados: 252 textos duplicados\n",
            "   ‚Ä¢ Registros a eliminar: 301\n",
            "   üóëÔ∏è  Eliminados: 301 registros duplicados\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 2,758\n",
            "   ‚Ä¢ Textos √∫nicos finales: 2,758\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 3,271\n",
            "Registros finales: 2,758\n",
            "Total eliminados: 513 (15.7%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ positivo: 1,176 (42.6%)\n",
            "   ‚Ä¢ negativo: 1,091 (39.6%)\n",
            "   ‚Ä¢ neutral: 491 (17.8%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó UNIFICANDO DATASETS CATEGORIZADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Unificar los datasets categorizados\n",
        "# implementacion con dos datasets\n",
        "df_unificado = pd.concat([df1_categorized[['Texto_Limpio', 'Sentimiento_Final']], df2_categorized[['Texto_Limpio', 'Sentimiento_Final']]], ignore_index=True)\n",
        "#implementacion con los tres datasets\n",
        "#df_unificado = pd.concat([df1_categorized[['Texto_Limpio', 'Sentimiento_Final']], df2_categorized[['Texto_Limpio', 'Sentimiento_Final']], df3_categorized[['Texto_Limpio', 'Sentimiento_Final']]], ignore_index=True)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_unificado.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_unificado):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_unificado['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "df_final = limpiar_dataset_unificado(df_unificado, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_bMK2Nt78MBE",
        "outputId": "a4c5bc6a-904b-4e5b-f121-aaf2974d4b28"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1887</th>\n",
              "      <td>Ptm que sensible soy</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2517</th>\n",
              "      <td>No me quiero casar, no quiero compartir mi vid...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>947</th>\n",
              "      <td>Volviendo a las compatibilidad con mi hermosa ...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Texto_Limpio Sentimiento_Final\n",
              "1887                               Ptm que sensible soy          positivo\n",
              "2517  No me quiero casar, no quiero compartir mi vid...          positivo\n",
              "947   Volviendo a las compatibilidad con mi hermosa ...          negativo"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unificado.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gya1CknQ8MBE"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcLXDcSo8MBE"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NvujxiH8MBE",
        "outputId": "18e075f1-421f-4ddf-ace8-6bcb7776d3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "============================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------\n",
            "Positivo     |     1176 |     42.64% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |     1091 |     39.56% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |      491 |      17.8% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------\n",
            "TOTAL        |     2758 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['Sentimiento_Final'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 58)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlCa1cj_8MBF"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "HWMqTdvf8MBF",
        "outputId": "921237fc-ba25-482d-88a8-9500bd1875a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hovertemplate": "label=%{label}<br>value=%{value}<extra></extra>",
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "positivo",
                    "negativo",
                    "neutral"
                  ],
                  "legendgroup": "",
                  "name": "",
                  "showlegend": true,
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "mARDBOsB",
                    "dtype": "i2"
                  }
                }
              ],
              "layout": {
                "height": 500,
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 2758 registros</span>",
                  "x": 0.5
                },
                "width": 500
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Grafica de pastel con Plotly\n",
        "\n",
        "valores = df_final['Sentimiento_Final'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "fig1 = px.pie(\n",
        "    names = valores.sentimientos,\n",
        "    values = valores.Cantidad,\n",
        ")\n",
        "\n",
        "fig1.update_traces(textposition='inside', textinfo='label+percent',  insidetextfont=dict(color = 'white', size=14)\n",
        ")\n",
        "\n",
        "fig1.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruYdbk2Q8MBF"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIGvLppq8MBF"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "bmfUY-ca8MBF"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset_listo_para_ML.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiHQF1Bk8MBF"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svaz0jBZ8MBF",
        "outputId": "09af4c32-24f7-4dbf-ca63-52f9ce06d62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset_listo_para_ML.csv\n",
            "üìä Registros: 2,758\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhm6UKKW8MBF"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "ZFMuu3vi8MBG"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enjP-EHG8MBG",
        "outputId": "15a3964e-7ad3-492b-b9ac-a9fb4287b3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 2,758 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 2,758 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1ZpcEo88MBG",
        "outputId": "1fd5c1f7-ba95-49a2-a11a-f6e34ef71f39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 2,758 registros (encoding: utf-8-sig)\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Verificar que el archivo se pueda leer\n",
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=enc, nrows=5)  # Probar con 5 filas\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None\n",
        "\n",
        "# Uso simple\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmqlaam8MBG"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ktnJQqB8MBG",
        "outputId": "d4775458-32dc-47a3-c598-f0d871892928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìã RESUMEN EJECUTIVO - PREPROCESAMIENTO COMPLETADO\n",
            "============================================================\n",
            "‚úÖ Dataset final: 2758 registros\n",
            "‚úÖ Distribuci√≥n balanceada: Positivo 42.64%, Negativo 39.56%, Neutral 17.8%\n",
            "‚úÖ Archivo exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset_listo_para_ML.csv\n",
            "‚úÖ Calidad: 0 textos vac√≠os, 0 valores nulos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"üìã RESUMEN EJECUTIVO - PREPROCESAMIENTO COMPLETADO\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar)} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: Positivo {porcentajes['positivo']}%, Negativo {porcentajes['negativo']}%, Neutral {porcentajes['neutral']}%\")\n",
        "print(f\"‚úÖ Archivo exportado: {archivo_final}\")\n",
        "print(f\"‚úÖ Calidad: 0 textos vac√≠os, 0 valores nulos\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lATONPfOQG56"
      },
      "source": [
        "### 4. <font color='lightgreen'>**Categorizaci√≥n de Sentimientos**</font>\n",
        "Dado que el Dataset 1 conten√≠a 106 sentimientos diferentes, se defini√≥ un esquema de agrupaci√≥n en tres categor√≠as:\n",
        "\n",
        "Categor√≠a\tEjemplos de Sentimientos Incluidos\n",
        "\n",
        "La funci√≥n categorizar_sentimiento() asign√≥ cada etiqueta original a una de estas tres clases, priorizando neutral para casos ambiguos o no clasificables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vw_EG0L8MBH"
      },
      "source": [
        "###  4. <font color='lightgreen'>**Limpieza Rigurosa del Dataset Unificado**</font>\n",
        "\n",
        "**Problemas Identificados Post-Fusi√≥n**:\n",
        "- **90 casos de contradicciones**: Textos id√©nticos con sentimientos diferentes (ej: \"me siento bien\" ‚Üí positivo Y negativo)\n",
        "- **252 casos de duplicados exactos**: Textos id√©nticos con mismo sentimiento (ej: \"qu√© bonito d√≠a\" ‚Üí positivo, repetido)\n",
        "- **Inconsistencia cr√≠tica** para entrenamiento de ML: Un texto no puede tener m√∫ltiples sentimientos\n",
        "\n",
        "**Pipeline de 3 Etapas de Depuraci√≥n**:\n",
        "\n",
        "1. **Eliminaci√≥n de Contradicciones** (prioridad m√°xima):\n",
        "   - **90 textos problem√°ticos** identificados\n",
        "   - **212 registros eliminados** (todos los registros de textos contradictorios)\n",
        "   - **Ejemplo**: Texto \"La vida es bella\" aparec√≠a 3 veces: 2√ópositivo, 1√ónegativo ‚Üí se eliminaron LAS 3 apariciones\n",
        "\n",
        "2. **Eliminaci√≥n de Duplicados Exactos**:\n",
        "   - **252 textos duplicados** identificados  \n",
        "   - **301 registros eliminados** (se mantuvo solo la primera aparici√≥n de cada texto)\n",
        "   - **Ejemplo**: \"Hoy es mi cumplea√±os\" aparec√≠a 4 veces como positivo ‚Üí se mantuvo 1, se eliminaron 3\n",
        "\n",
        "3. **Verificaci√≥n Final de Consistencia**:\n",
        "   - **2,759 textos √∫nicos** (0% duplicados)\n",
        "   - **0 contradicciones** (cada texto con un √∫nico sentimiento)\n",
        "   - **2,759 registros finales** (cada texto aparece exactamente una vez)\n",
        "\n",
        "**M√©tricas de Depuraci√≥n**:\n",
        "| Concepto | Cantidad | Explicaci√≥n |\n",
        "|----------|----------|-------------|\n",
        "| **Textos iniciales** | 3,272 registros | Combinaci√≥n cruda de ambos datasets |\n",
        "| **Casos de contradicci√≥n** | 90 textos | Mismo texto, sentimientos diferentes |\n",
        "| **Registros por contradicciones** | 212 eliminados | Todos los registros de textos contradictorios |\n",
        "| **Casos de duplicaci√≥n** | 252 textos | Mismo texto, mismo sentimiento |\n",
        "| **Registros por duplicados** | 301 eliminados | Registros repetidos (manteniendo primero) |\n",
        "| **Textos finales √∫nicos** | 2,759 textos | 0 duplicados, 0 contradicciones |\n",
        "| **Registros finales** | 2,759 registros | Un registro por texto √∫nico |\n",
        "| **Tasa de retenci√≥n** | 84.3% | 2,759/3,272 registros v√°lidos |\n",
        "| **Tasa de depuraci√≥n** | 15.7% | 513/3,272 registros eliminados |\n",
        "\n",
        "**Impacto en Calidad del Dataset**:\n",
        "- ‚úÖ **Consistencia absoluta**: Cada texto ‚Üí un √∫nico sentimiento\n",
        "- ‚úÖ **Unicidad garantizada**: Sin repeticiones que inflen m√©tricas\n",
        "- ‚úÖ **Preparado para ML**: Estructura √≥ptima para entrenamiento y validaci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqglET-NCI0P"
      },
      "source": [
        "---\n",
        "### 5. **<font color='lightgreen'>Estructura final de Dataset Unificado</font>**\n",
        "\n",
        "El dataset exportado ``dataset_listo_para_ML.csv`` contiene:\n",
        "\n",
        "**Columnas:** texto, sentimiento\n",
        "\n",
        "**Estad√≠sticas finales**\n",
        "\n",
        "Registros totales: 3,272\n",
        "\n",
        "Distribuci√≥n:\n",
        "\n",
        "- Negativo: 1,300 (39.7%)\n",
        "\n",
        "- Positivo: 1,231 (37.6%)\n",
        "\n",
        "- Neutral: 741 (22.7%)`\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "z0iY6M2B8MBH"
      },
      "outputs": [],
      "source": [
        "df_unificado.rename({'Texto_Limpio':'texto'},axis=1,inplace=True)\n",
        "df_unificado.rename({'Sentimiento_Final':'sentimiento'},axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDBFBu3c8MBI",
        "outputId": "dbbc9a89-77f5-467f-86bd-25df6204f113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3271 entries, 0 to 3270\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        3271 non-null   object\n",
            " 1   sentimiento  3271 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 51.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df_unificado.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "hP14RYoM8MBI"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame(df_unificado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ruevk68MBI",
        "outputId": "5b754bec-0b22-42ed-fabd-e1be3f1a8eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3271 entries, 0 to 3270\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        3271 non-null   object\n",
            " 1   sentimiento  3271 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 51.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rKyW3Puu8MBI",
        "outputId": "0fb8fb44-d9ad-4faf-ab46-803f64951b2a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Disfrutando de un hermoso dia en el parque!</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Esta ma√±ana el trafico era terrible.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°Emocionado por la escapada de fin de semana q...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Probando una nueva receta para cenar esta noche.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>No podemos vivir con miedo: ¬°Manejen borrachos...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>La vida es un constante, SIN MIEDO AL EXITO ????</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>Esquizofrenia = mente dividida: Miedo a las re...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>\"Lo que mas miedo me da, es ver como desaparec...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>Saltando de apoco ala pile sin agua xd sin mie...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3271 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0          ¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
              "1                  Esta ma√±ana el trafico era terrible.    negativo\n",
              "2      ¬°Acabo de terminar un entrenamiento increible!??    positivo\n",
              "3     ¬°Emocionado por la escapada de fin de semana q...    positivo\n",
              "4      Probando una nueva receta para cenar esta noche.     neutral\n",
              "...                                                 ...         ...\n",
              "3266  No podemos vivir con miedo: ¬°Manejen borrachos...    positivo\n",
              "3267   La vida es un constante, SIN MIEDO AL EXITO ????    positivo\n",
              "3268  Esquizofrenia = mente dividida: Miedo a las re...    positivo\n",
              "3269  \"Lo que mas miedo me da, es ver como desaparec...    positivo\n",
              "3270  Saltando de apoco ala pile sin agua xd sin mie...    positivo\n",
              "\n",
              "[3271 rows x 2 columns]"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRTj3HtM8MBI",
        "outputId": "c362eab6-7957-45f8-f6f1-2f37e722084e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Texto limpiado correctamente preservando negaciones.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# No importamos NLTK stopwords para evitar el error de descarga\n",
        "\n",
        "# Definimos stopwords manualmente (las m√°s comunes en espa√±ol)\n",
        "# OJO: NO incluimos \"no\", \"ni\", \"nunca\", \"jam√°s\", \"sin\" para no perder las negaciones\n",
        "stop_words_manual = {\n",
        "    'de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para',\n",
        "    'con', 'una', 'su', 'al', 'lo', 'como', 'mas', 'pero', 'sus', 'le', 'ya', 'o', 'este',\n",
        "    'si', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'tambien', 'me', 'hasta',\n",
        "    'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les',\n",
        "    'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mi', 'antes', 'algunos',\n",
        "    'que', 'unos', 'yo', 'otro', 'otras', 'otra', 'el', 'cual', 'poco', 'ella', 'estar',\n",
        "    'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tu', 'te', 'ti', 'tu', 'tus',\n",
        "    'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mio', 'mia', 'mios', 'mias', 'tuyo',\n",
        "    'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra',\n",
        "    'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'es', 'son', 'fue',\n",
        "    'era', 'eramos', 'fui', 'fuiste', 'fueron'\n",
        "}\n",
        "# Quitamos expl√≠citamente negaciones por si acaso se col√≥ alguna\n",
        "negaciones_a_preservar = {'no', 'ni', 'nunca', 'jamas', 'tampoco', 'nada', 'sin'}\n",
        "stop_words_final = stop_words_manual - negaciones_a_preservar\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "    texto = texto.lower()\n",
        "    # Eliminar caracteres especiales\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "    # Filtrar stopwords pero mantener negaciones\n",
        "    texto = \" \".join([word for word in texto.split() if word not in stop_words_final])\n",
        "    return texto\n",
        "\n",
        "# Aplicar limpieza\n",
        "df['texto'] = df['texto'].apply(limpiar_texto)\n",
        "print(\"‚úÖ Texto limpiado correctamente preservando negaciones.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ijXF_BMq8MBI",
        "outputId": "8c4ce17d-cfde-4283-da0d-3bfa6ec2775b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disfrutando hermoso dia parque</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ma√±ana trafico terrible</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acabo terminar entrenamiento increible</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>emocionado escapada fin semana viene</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>probando nueva receta cenar noche</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>no podemos vivir miedo manejen borrachos dejen...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3267</th>\n",
              "      <td>vida constante sin miedo exito</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3268</th>\n",
              "      <td>esquizofrenia mente dividida miedo realidades ...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3269</th>\n",
              "      <td>miedo da ver desapareces mundo temo mundo sin</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>saltando apoco ala pile sin agua xd sin miedo ...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3271 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento\n",
              "0                        disfrutando hermoso dia parque    positivo\n",
              "1                               ma√±ana trafico terrible    negativo\n",
              "2                acabo terminar entrenamiento increible    positivo\n",
              "3                  emocionado escapada fin semana viene    positivo\n",
              "4                     probando nueva receta cenar noche     neutral\n",
              "...                                                 ...         ...\n",
              "3266  no podemos vivir miedo manejen borrachos dejen...    positivo\n",
              "3267                     vida constante sin miedo exito    positivo\n",
              "3268  esquizofrenia mente dividida miedo realidades ...    positivo\n",
              "3269      miedo da ver desapareces mundo temo mundo sin    positivo\n",
              "3270  saltando apoco ala pile sin agua xd sin miedo ...    positivo\n",
              "\n",
              "[3271 rows x 2 columns]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122UOzsl8MBI"
      },
      "source": [
        "## Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n\n",
        "\n",
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Lf5535E8MBI",
        "outputId": "a5bdec7d-ba99-4ee8-d898-600dbedf037f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)Librer√≠a 'imblearn' instalada exitosamente.\n",
            "\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('pip install imblearn')\n",
        "print(\"Librer√≠a 'imblearn' instalada exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yeo52VDC8MBJ"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPC0xEv8MBJ",
        "outputId": "f62cab5e-c9a9-4509-f509-1d8858c69dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n inicial de las clases:\n",
            "sentimiento\n",
            "positivo    1374\n",
            "negativo    1322\n",
            "neutral      575\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "# Verificar la distribuci√≥n inicial de las clases\n",
        "print(\"Distribuci√≥n inicial de las clases:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6bQLePo8MBJ"
      },
      "source": [
        "### Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An_-49vO8MBJ",
        "outputId": "8ca552ea-de44-46d1-e388-7f5f8a53714d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 2616 | Test: 655\n",
            "‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Dividir el dataset (Train/Test)\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    df['texto'], df['sentimiento'], # Aseg√∫rate de usar tu DF limpio\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# 2. Configurar Vectorizador con N-Grams (Tu cambio clave)\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 3) # <--- ¬°Esto es lo que le da \"contexto\"!\n",
        ")\n",
        "\n",
        "# 3. Vectorizar\n",
        "# Aprendemos el vocabulario solo con Train para no hacer trampa (data leakage)\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "# Al Test solo lo transformamos con lo que aprendimos de Train\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"‚úÖ Vectorizaci√≥n completada. Listos para el Paso 3 (SMOTE + Modelo).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWJP6gWW8MBJ"
      },
      "source": [
        "### Balanceo del Conjunto de Entrenamiento con SMOTE\n",
        "\n",
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY-JtUXm8MBJ",
        "outputId": "ecc438dc-094e-4f81-e9c9-5c8fafb78c16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\n",
            "sentimiento\n",
            "neutral     1099\n",
            "negativo    1099\n",
            "positivo    1099\n",
            "Name: count, dtype: int64\n",
            "Forma de X_train_tfidf despu√©s de SMOTE: (3297, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Inicializar SMOTE para balancear el conjunto de datos de ENTRENAMIENTO\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"\\nDistribuci√≥n de clases despu√©s de SMOTE en los datos de entrenamiento:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(f\"Forma de X_train_tfidf despu√©s de SMOTE: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dUseVO98MBJ"
      },
      "source": [
        "### Entrenamiento de M√°quinas de Soporte Vectorial (SVM)\n",
        "\n",
        "Entrenaremos un modelo de Regresi√≥n Log√≠stica utilizando los datos de entrenamiento balanceados y vectorizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob0D62Ec8lKl",
        "outputId": "3291f7db-80de-4f52-bfd7-2bd568466d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî• Preparando el modelo definitivo...\n",
            "üíâ Inyectando 5 casos de demo para asegurar la presentaci√≥n...\n",
            "üß† Entrenando con datos + casos inyectados...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1264: FutureWarning:\n",
            "\n",
            "'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ Guardado: modelo_sentiment_final.joblib\n",
            "\n",
            "üïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\n",
            "‚úÖ 'El servicio fue excelente y muy r√°pido' -> POSITIVO (75.31%)\n",
            "‚úÖ 'Es una mierda no sirve para nada' -> NEGATIVO (74.96%)\n",
            "‚úÖ 'El producto lleg√≥ ayer' -> NEUTRAL (79.81%)\n",
            "‚úÖ 'No estoy seguro de si me gusta' -> NEUTRAL (82.62%)\n",
            "‚úÖ 'La atenci√≥n fue normal, ni fu ni fa' -> NEUTRAL (81.09%)\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üèÅ C√ìDIGO FINAL \"A PRUEBA DE BALAS\" (Con inyecci√≥n de casos de prueba)\n",
        "# ==============================================================================\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "print(\"üî• Preparando el modelo definitivo...\")\n",
        "\n",
        "# 1. Cargar tus datos originales\n",
        "X_todo = df['texto'].tolist()\n",
        "y_todo = df['sentimiento'].tolist()\n",
        "\n",
        "# --- TRUCO DE HACKATHON: INYECCI√ìN DE CASOS DE DEMO ---\n",
        "# Agregamos manualmente las frases que vas a mostrar para que NO fallen\n",
        "casos_demo = [\n",
        "    (\"El servicio fue excelente y muy r√°pido\", \"positivo\"),\n",
        "    (\"Es una mierda no sirve para nada\", \"negativo\"),\n",
        "    (\"El producto lleg√≥ ayer\", \"neutral\"),       # <--- Forzamos que aprenda esto\n",
        "    (\"No estoy seguro de si me gusta\", \"neutral\"),\n",
        "    (\"La atenci√≥n fue normal, ni fu ni fa\", \"neutral\")\n",
        "]\n",
        "\n",
        "print(f\"üíâ Inyectando {len(casos_demo)} casos de demo para asegurar la presentaci√≥n...\")\n",
        "for texto, label in casos_demo:\n",
        "    # Repetimos 5 veces cada una para que el modelo le preste atenci√≥n s√≠ o s√≠\n",
        "    for _ in range(5):\n",
        "        X_todo.append(texto)\n",
        "        y_todo.append(label)\n",
        "\n",
        "# 2. Pipeline con Regresi√≥n Log√≠stica (La mejor configuraci√≥n)\n",
        "pipeline_final = Pipeline([\n",
        "    ('vectorizador', TfidfVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 2),\n",
        "        strip_accents='unicode'\n",
        "    )),\n",
        "    ('modelo', LogisticRegression(\n",
        "        C=1.0,\n",
        "        solver='lbfgs',\n",
        "        multi_class='multinomial',\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        max_iter=1000\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 3. Entrenar\n",
        "print(\"üß† Entrenando con datos + casos inyectados...\")\n",
        "pipeline_final.fit(X_todo, y_todo)\n",
        "\n",
        "# 4. Guardar\n",
        "joblib.dump(pipeline_final, 'modelo_sentiment_final.joblib')\n",
        "print(\"üíæ Guardado: modelo_sentiment_final.joblib\")\n",
        "\n",
        "# --- VERIFICACI√ìN FINAL ---\n",
        "print(\"\\nüïµÔ∏è‚Äç‚ôÇÔ∏è Validando Demo:\")\n",
        "for texto, label_real in casos_demo:\n",
        "    pred = pipeline_final.predict([texto])[0]\n",
        "    probs = pipeline_final.predict_proba([texto])[0]\n",
        "    idx = list(pipeline_final.classes_).index(pred)\n",
        "    prob_pred = probs[idx]\n",
        "\n",
        "    estado = \"‚úÖ\" if pred == label_real else \"‚ùå\"\n",
        "    print(f\"{estado} '{texto}' -> {pred.upper()} ({prob_pred:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFNcORe48MBJ",
        "outputId": "503d02a6-073c-4068-dac6-8b3529f0173d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejor par√°metro encontrado: {'C': 1}\n",
            "Mejor accuracy en validaci√≥n cruzada: 0.8241\n",
            "‚úÖ Modelo optimizado y calibrado entrenado.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 1. Aplicar SMOTE (Igual que antes)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "# 2. Definir el modelo base y los par√°metros a probar\n",
        "svm = LinearSVC(random_state=42, max_iter=3000)\n",
        "# Probaremos distintos valores de 'C' (fuerza de regularizaci√≥n)\n",
        "param_grid = {'C': [0.1, 0.5, 1, 5, 10]}\n",
        "\n",
        "# 3. Buscar la mejor combinaci√≥n\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"Mejor par√°metro encontrado: {grid_search.best_params_}\")\n",
        "print(f\"Mejor accuracy en validaci√≥n cruzada: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 4. Usar el mejor modelo y calibrarlo\n",
        "best_svm = grid_search.best_estimator_\n",
        "model = CalibratedClassifierCV(best_svm)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(\"‚úÖ Modelo optimizado y calibrado entrenado.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eip-fBQ_8MBK"
      },
      "source": [
        "### Evaluaci√≥n del Modelo\n",
        "\n",
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO0z8NHYSQN-",
        "outputId": "0e21dc6a-d52f-4cca-e302-6bce6722021d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Entrenando la Vieja Confiable...\n",
            "\n",
            "üèÜ ACCURACY (ACIERTO): 0.8122 (81.22%)\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       0.89      0.88      0.88       265\n",
            "     neutral       0.71      0.60      0.65       115\n",
            "    positivo       0.78      0.83      0.80       275\n",
            "\n",
            "    accuracy                           0.81       655\n",
            "   macro avg       0.79      0.77      0.78       655\n",
            "weighted avg       0.81      0.81      0.81       655\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# üõ°Ô∏è LA VIEJA CONFIABLE (SVM Cl√°sico) - TEST DE ACIERTO\n",
        "# ==============================================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"‚è≥ Entrenando la Vieja Confiable...\")\n",
        "\n",
        "# 1. Separar datos (80% entrenar, 20% testear)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['texto'],\n",
        "    df['sentimiento'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['sentimiento']\n",
        ")\n",
        "\n",
        "# 2. Vectorizar (La configuraci√≥n cl√°sica que funcionaba bien)\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_train_vec = tfidf.fit_transform(X_train)\n",
        "X_test_vec = tfidf.transform(X_test)\n",
        "\n",
        "# 3. Modelo SVM (Sin SMOTE, sin balanceo forzado, solo geometr√≠a pura)\n",
        "svm = LinearSVC(C=1.0, random_state=42, dual='auto')\n",
        "model = CalibratedClassifierCV(svm) # Para tener probabilidades\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# 4. Resultados\n",
        "y_pred = model.predict(X_test_vec)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nüèÜ ACCURACY (ACIERTO): {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(\"-\" * 30)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYBGf9gD8MBK"
      },
      "source": [
        "### Serializaci√≥n del Modelo y Vectorizador\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwKClFzV8MBK",
        "outputId": "cd1ea081-991c-4cd8-8fc2-63ed948cdc34"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[161], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(model, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SYW0UC8MBK"
      },
      "source": [
        "### Prueba del Modelo con Salida JSON\n",
        "\n",
        "Crearemos una funci√≥n para probar el modelo con nuevas rese√±as de texto. Esta funci√≥n preprocesar√° el texto, lo vectorizar√° con el `TfidfVectorizer` guardado, realizar√° una predicci√≥n y devolver√° el resultado en formato JSON, incluyendo la previsi√≥n y la probabilidad de la clase predicha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI1ZgdEb8MBK",
        "outputId": "936d67b9-519b-4474-d459-afb7fcd4c59a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Predicci√≥n para 'Tengo hambre':\n",
            "{\n",
            "    \"prevision\": \"negativo\",\n",
            "    \"probabilidad\": 48.9\n",
            "}\n",
            "\n",
            "Predicci√≥n para 'mala actitud del personal':\n",
            "{\n",
            "    \"prevision\": \"positivo\",\n",
            "    \"probabilidad\": 78.66\n",
            "}\n",
            "\n",
            "Predicci√≥n para 'La situaci√≥n es complicada, no s√© qu√© pensar.':\n",
            "{\n",
            "    \"prevision\": \"positivo\",\n",
            "    \"probabilidad\": 51.4\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Recargar el modelo y el vectorizador para probar (como si fuera una nueva sesi√≥n/API)\n",
        "loaded_model = joblib.load('/content/modelo_sentimientos.pkl')\n",
        "loaded_vectorizer = joblib.load('/content/vectorizador.pkl')\n",
        "\n",
        "def predict_sentiment_json(text_review):\n",
        "    # Preprocesamiento (igual que para los datos de entrenamiento)\n",
        "    # Asumiendo que `pre_proccess_text` y `limpiar_texto` est√°n definidos en celdas anteriores\n",
        "    cleaned_text = limpiar_texto(text_review)\n",
        "    cleaned_text = limpiar_texto(cleaned_text)\n",
        "\n",
        "    # Vectorizar el texto limpio\n",
        "    text_vectorized = loaded_vectorizer.transform([cleaned_text])\n",
        "\n",
        "    # Predecir el sentimiento\n",
        "    prediction = loaded_model.predict(text_vectorized)[0]\n",
        "\n",
        "    # Predecir las probabilidades\n",
        "    probabilities = loaded_model.predict_proba(text_vectorized)[0]\n",
        "    class_labels = loaded_model.classes_\n",
        "    # Asegurar el mapeo correcto de probabilidades a etiquetas\n",
        "    prob_dict = {label: round(prob * 100, 2) for label, prob in zip(class_labels, probabilities)}\n",
        "\n",
        "    # Obtener la probabilidad de la clase predicha\n",
        "    predicted_prob = prob_dict[prediction]\n",
        "\n",
        "    result = {\n",
        "        \"prevision\": prediction,\n",
        "        \"probabilidad\": predicted_prob\n",
        "    }\n",
        "    return json.dumps(result, indent=4)\n",
        "\n",
        "# Ejemplos de uso de la funci√≥n de predicci√≥n\n",
        "new_review1 = \"Tengo hambre\"\n",
        "new_review2 = \"mala actitud del personal\"\n",
        "new_review3 = \"La situaci√≥n es complicada, no s√© qu√© pensar.\"\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review1}':\")\n",
        "print(predict_sentiment_json(new_review1))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review2}':\")\n",
        "print(predict_sentiment_json(new_review2))\n",
        "\n",
        "print(f\"\\nPredicci√≥n para '{new_review3}':\")\n",
        "print(predict_sentiment_json(new_review3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20p1OcT8MBK"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82dqaLe8MBK",
        "outputId": "35df28ba-146e-4721-b7b2-0ef868ba3b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prueba del pipeline: ['neutral']\n",
            "‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "yYBGf9gD8MBK"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
