{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "from io import StringIO\n",
        "import urllib.response\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de los datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yOwHw3xtYJEg"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "def importar_dataset(url, separator=';'):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL detectando encoding autom√°ticamente.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Descargar contenido una sola vez\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "\n",
        "        # 2. Detectar encoding\n",
        "        result = chardet.detect(content)\n",
        "        encoding = result['encoding']\n",
        "        print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "\n",
        "        # 3. Decodificar y cargar en DataFrame\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        data = pd.read_csv(StringIO(decoded_content), sep=separator)\n",
        "\n",
        "        print(\"‚úÖ Archivo cargado correctamente\")\n",
        "        print(f\"üìä Tama√±o del dataset: {data.shape}\")\n",
        "        print(\"\\nüîç Muestra aleatoria (3 registros):\")\n",
        "        print(data.sample(3))\n",
        "\n",
        "        return data\n",
        "\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e}\")\n",
        "        return None\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ùå Error al parsear CSV: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZW5B7jk5-x"
      },
      "source": [
        "#### **Dataset1: sentimentdataset_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iWgPb0VhYeKT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 72.97%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (731, 15)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "     Unnamed: 0.1  Unnamed: 0  \\\n",
            "648           650         654   \n",
            "173           174         176   \n",
            "623           625         629   \n",
            "\n",
            "                                                  Text   Sentiment  \\\n",
            "648  Intentando dominar el kickflip perfecto en mi ...  Excitaci√≥n   \n",
            "173  La envidia me devora cuando veo la prosperidad...     Envidia   \n",
            "623  Comenz√≥ un jard√≠n comunitario, cultivando no s...     Alegr√≠a   \n",
            "\n",
            "            Timestamp                User   Platform  \\\n",
            "648  08-08-2023 16:00  SkateProHighSchool    Twitter   \n",
            "173  07-11-2018 11:30        CovetousMind  Instagram   \n",
            "623  03-07-2023 12:45    GreenThumbSenior    Twitter   \n",
            "\n",
            "                             Hashtags  Retweets  Likes Country  Year  Month  \\\n",
            "648     #SkaterLife #HighSchoolSkater        30     60  Canad√°  2023      8   \n",
            "173                   #Envidia #Deseo        10     20  Canad√°  2018     11   \n",
            "623  #GardenFriends #SeniorGreenThumb        28     55  Canad√°  2023      7   \n",
            "\n",
            "     Day  Hour  \n",
            "648    8    16  \n",
            "173    7    11  \n",
            "623    3    12  \n"
          ]
        }
      ],
      "source": [
        "df1_raw = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/sentimentdataset_es.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKr3W1NEaBrP"
      },
      "source": [
        "#### **Dataset2: sentiment_analysis_dataset.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d2eRhM-MYh6L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (2540, 3)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "                                                  texto  label sentimiento\n",
            "2274  En 'Existir√≠amos el mar', B. Gopegui propone \"...      2    positivo\n",
            "2468  mira que te voy a patear deja de hacerte el lo...      2    positivo\n",
            "1764  Una mujer observa su cuerpo intranquila, como ...      2    positivo\n"
          ]
        }
      ],
      "source": [
        "df2_raw = importar_dataset(\"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/refs/heads/feature/data-science-marely/data-science/datasets/datasets-origin/sentiment_analysis_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9qa7fqEjJagA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: UTF-8-SIG (confianza: 100.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (74682, 4)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "          id            plataforma sentimiento  \\\n",
            "70537  10884  TomClancysGhostRecon    Negativo   \n",
            "14790   2934                 Dota2    Positivo   \n",
            "70137  10817  TomClancysGhostRecon    Negativo   \n",
            "\n",
            "                                                   texto  \n",
            "70537  @GhostRecon tendr√°s que banear a los jugadores...  \n",
            "14790             Bonita actualizaci√≥n gaben, muy bonita  \n",
            "70137  @GhostRecon sigue siendo expulsado con un erro...  \n"
          ]
        }
      ],
      "source": [
        "df3_raw = importar_dataset(\"https://github.com/eduardotec05/datasets/raw/refs/heads/main/twitter_training_esp_convertido%20(2).csv\", separator=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Dataset3: Twitter_training.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nY1nIBYtKA9g"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>plataforma</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Estoy llegando a Borderlands y los asesinar√© a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a las fronteras y os matar√© a todos,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a Borderlands y los matar√© a todos.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a Borderlands y los asesinar√© a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Me estoy metiendo en Borderlands 2 y os voy a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id   plataforma sentimiento  \\\n",
              "0  2401  Borderlands    Positivo   \n",
              "1  2401  Borderlands    Positivo   \n",
              "2  2401  Borderlands    Positivo   \n",
              "3  2401  Borderlands    Positivo   \n",
              "4  2401  Borderlands    Positivo   \n",
              "\n",
              "                                               texto  \n",
              "0  Estoy llegando a Borderlands y los asesinar√© a...  \n",
              "1  Voy a llegar a las fronteras y os matar√© a todos,  \n",
              "2   Voy a llegar a Borderlands y los matar√© a todos.  \n",
              "3  Voy a llegar a Borderlands y los asesinar√© a t...  \n",
              "4  Me estoy metiendo en Borderlands 2 y os voy a ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2hn5BGLpl8eS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 1\n",
            "============================================================\n",
            "üìä Forma: (731, 15)\n",
            "üìù Columnas: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
            "üî§ Columnas de texto: ['Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Country']\n",
            "\n",
            "üìù Analizando columna: 'Text'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     '¬°Disfrutando de un hermoso d√≠a en el parque!'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'Esta ma√±ana el tr√°fico era terrible.'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     '¬°Acabo de terminar un entrenamiento incre√≠ble!??'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     '¬°Emocionado por la escapada de fin de semana que viene!'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Probando una nueva receta para cenar esta noche.'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 2\n",
            "============================================================\n",
            "üìä Forma: (2540, 3)\n",
            "üìù Columnas: ['texto', 'label', 'sentimiento']\n",
            "üî§ Columnas de texto: ['texto', 'sentimiento']\n",
            "\n",
            "üìù Analizando columna: 'texto'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'termine bien abrumado despu√©s de hoy'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'me siento abrumado'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Me siento un poco abrumado por la cantidad de cosas que quiero dibujar, ver, jug...'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Salvador la √∫nica persona que no la ha abrumado de versiones???? #NadieComoT√∫'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Denme un helado o algo que ando full abrumado.'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 3\n",
            "============================================================\n",
            "üìä Forma: (74682, 4)\n",
            "üìù Columnas: ['id', 'plataforma', 'sentimiento', 'texto']\n",
            "üî§ Columnas de texto: ['plataforma', 'sentimiento', 'texto']\n",
            "\n",
            "üìù Analizando columna: 'plataforma'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def verificar_calidad_importacion(df, nombre_dataset):\n",
        "    \"\"\"\n",
        "    Verifica que no se haya perdido informaci√≥n durante la importaci√≥n.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD: {nombre_dataset}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if df is None:\n",
        "        print(\"‚ùå Dataset es None\")\n",
        "        return False\n",
        "\n",
        "    # 1. Informaci√≥n b√°sica\n",
        "    print(f\"üìä Forma: {df.shape}\")\n",
        "    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "\n",
        "    # 2. Buscar columnas de texto\n",
        "    columnas_texto = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    print(f\"üî§ Columnas de texto: {columnas_texto}\")\n",
        "\n",
        "    if not columnas_texto:\n",
        "        print(\"‚ö†Ô∏è  No se encontraron columnas de texto\")\n",
        "        return True\n",
        "\n",
        "    # 3. Analizar una columna de texto (usar la primera)\n",
        "    col_texto = columnas_texto[0]\n",
        "    print(f\"\\nüìù Analizando columna: '{col_texto}'\")\n",
        "\n",
        "    # Muestra de textos\n",
        "    textos = df[col_texto].dropna().head(5).tolist()\n",
        "\n",
        "    problemas = []\n",
        "\n",
        "    for i, texto in enumerate(textos):\n",
        "        if isinstance(texto, str):\n",
        "            # Buscar caracteres de reemplazo (ÔøΩ) que indican problemas\n",
        "            caracteres_problema = texto.count('ÔøΩ')\n",
        "            if caracteres_problema > 0:\n",
        "                problemas.append(f\"Texto {i+1} tiene {caracteres_problema} caracteres de reemplazo (ÔøΩ)\")\n",
        "\n",
        "            # Buscar emojis\n",
        "            emojis = [c for c in texto if unicodedata.category(c)[0] in ['S', 'So']]\n",
        "            if emojis:\n",
        "                print(f\"  Texto {i+1}: ‚úÖ Tiene {len(emojis)} emoji(s): {''.join(emojis[:3])}\")\n",
        "            else:\n",
        "                print(f\"  Texto {i+1}: üìÑ Sin emojis\")\n",
        "\n",
        "            # Mostrar fragmento\n",
        "            preview = texto[:80] + \"...\" if len(texto) > 80 else texto\n",
        "            print(f\"     '{preview}'\")\n",
        "\n",
        "    # 4. Resumen\n",
        "    if problemas:\n",
        "        print(f\"\\n‚ö†Ô∏è  PROBLEMAS ENCONTRADOS:\")\n",
        "        for problema in problemas:\n",
        "            print(f\"   ‚Ä¢ {problema}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\")\n",
        "        return True\n",
        "\n",
        "verificar_calidad_importacion(df1_raw, \"Dataset 1\")\n",
        "verificar_calidad_importacion(df2_raw, \"Dataset 2\")\n",
        "verificar_calidad_importacion(df3_raw, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvsjkC76PuLm"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6X6oJxnAPuLm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 texto sentimiento\n",
            "105  Emoci√≥n por un viaje por carretera de fin de s...  Excitaci√≥n\n",
            "366  Orgullo de lograr un hito personal en la progr...     Orgullo\n",
            "245  Impulsado por la curiosidad, se aventura en re...  Curiosidad\n",
            "363  Una sensaci√≥n de logro despu√©s de completar un...       Logro\n",
            "407  Emb√°rcate en una odisea culinaria, saboreando ...     Neutral\n",
            "                                                  texto sentimiento\n",
            "1870                                      senti firmeza     neutral\n",
            "2436  Como v√≠ en tiktok que hay que ocuparse en vez ...    positivo\n",
            "2154  La mejor venganza es no buscar venganza, mej√≥r...     neutral\n",
            "1745                               Trabajo asegurado ??    positivo\n",
            "64                                Dios estoy desbordado    negativo\n",
            "                                                   texto  sentimiento\n",
            "5894   Siento que Amazon siempre me cobra cantidades ...     Negativo\n",
            "72836  En Pretty nos complace colaborar con KovaaK 2....      Neutral\n",
            "2132   ¬°Nos complace anunciar algunas caracter√≠sticas...     Positivo\n",
            "61357                     Todo es mejor cuando es negro.  Irrelevante\n",
            "46312  Hoy usar√© el plan prepago de @Verizon para mi ...     Positivo\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n filtrar dataset\n",
        "def filtrar_dataset(data):\n",
        "    data_filtro = data[['texto', 'sentimiento']]\n",
        "    data_filtro = data_filtro[data_filtro['texto'].str.strip() != \"\"]\n",
        "    print(data_filtro.sample(5))\n",
        "    return data_filtro\n",
        "\n",
        "# Reemplazar nombre columnas Text por texto, Sentiment por sentimiento\n",
        "df1_raw.rename({'Text':'texto', 'Sentiment':'sentimiento'}, axis=1, inplace=True)\n",
        "df1_filtrado = filtrar_dataset(df1_raw)\n",
        "df2_filtrado = filtrar_dataset(df2_raw)\n",
        "df3_filtrado = filtrar_dataset(df3_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmazYt9QBYT"
      },
      "source": [
        "### <font size= 12 color=\"lightgreen\" >Explorando los datasets<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_sb3UjtYPuLn"
      },
      "outputs": [],
      "source": [
        "# Crear funci√≥n para explorar datasets\n",
        "def explorar_dataset(data):\n",
        "    print('Filas: ' + str(data.shape[0]))\n",
        "    print('Columnas: ' + str(data.shape[1]))\n",
        "    print('\\nColumnas: \\n' + str(data.columns.tolist()))\n",
        "    print('\\nTipo de datos: \\n' + str(data.dtypes))\n",
        "    print('\\nValores nulos: \\n' + str(data.isnull().sum()))\n",
        "    print('\\nMuestra aleatoria (5 registros): \\n' + str(data.sample(5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-OpMWf0l8DM"
      },
      "source": [
        "#### **Explorando Data1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D0SICtaLs770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 731\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto    sentimiento\n",
            "481  Rodeado de los colores de la alegr√≠a, un lienz...        Alegr√≠a\n",
            "558  En medio de un partido de f√∫tbol, ??un gol en ...  Desesperaci√≥n\n",
            "426  Tormenta emocional, un torbellino detristeza e...        Emoci√≥n\n",
            "627  Inici√≥ un club de lectura para personas mayore...        Alegr√≠a\n",
            "193  El resentimiento se pudre, una herida que se n...  Resentimiento\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfglf1PjDfz"
      },
      "source": [
        "#### **Explorando data2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AvetNKaKfI3X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 731\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto    sentimiento\n",
            "507  Al bajar esquiando por las laderas de los Alpe...        Neutral\n",
            "430  Decepci√≥n desgarradora, esperanzas destrozadas...      Decepci√≥n\n",
            "204  Enfrentar los desaf√≠os de frente, una determin...  Determinaci√≥n\n",
            "189  Hundi√©ndome en la desesperaci√≥n, cada d√≠a m√°s ...  Desesperaci√≥n\n",
            "267  Una escapada l√∫dica al carnaval de la vida, ri...       Positivo\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pq-p1Ii7NhwV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 74682\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          41\n",
            "sentimiento     0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                   texto  sentimiento\n",
            "46319  <unk>, @Verizon! @thecoronadophx es mi incre√≠b...      Neutral\n",
            "39178  Hoy se transmitir√° el Hearthstone de Nice. La ...     Positivo\n",
            "47501  @GovMurphy Denle algo a Nueva Jersey... Los pa...     Negativo\n",
            "66897  Johnson Memorial Johnson detuvo los ensayos de...      Neutral\n",
            "15124                          Antiguos tiempos romanos.  Irrelevante\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df3_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "    # Mostrar resultados estad√≠sticos de la limpieza.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62jGtD-PuLo"
      },
      "source": [
        "#### **An√°lisis proceso de limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gs5CRWmVPuLo"
      },
      "outputs": [],
      "source": [
        "def analizar_limpieza_sentimientos(df_antes, df_despues, nombre):\n",
        "    \"\"\"\n",
        "    An√°lisis espec√≠fico para tu funci√≥n limpiar_texto_para_sentimientos\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç AN√ÅLISIS ESPEC√çFICO: {nombre}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Cambios en caracteres espec√≠ficos del espa√±ol\n",
        "    cambios_especificos = {\n",
        "        'tildes_eliminadas': 0,\n",
        "        '√±_preservadas': 0,\n",
        "        'urls_eliminadas': 0,\n",
        "        'mayusculas_preservadas': 0\n",
        "    }\n",
        "\n",
        "    # Muestra de 50 textos para an√°lisis detallado\n",
        "    muestra = min(50, len(df_antes))\n",
        "\n",
        "    for i in range(muestra):\n",
        "        if i < len(df_despues):\n",
        "            texto_antes = str(df_antes.iloc[i]['texto'])\n",
        "            texto_despues = str(df_despues.iloc[i]['texto'])\n",
        "\n",
        "            # Contar √± preservadas\n",
        "            if '√±' in texto_antes.lower() and '√±' in texto_despues.lower():\n",
        "                cambios_especificos['√±_preservadas'] += 1\n",
        "\n",
        "            # Contar URLs eliminadas\n",
        "            import re\n",
        "            urls_antes = len(re.findall(r'https?://\\S+', texto_antes))\n",
        "            urls_despues = len(re.findall(r'https?://\\S+', texto_despues))\n",
        "            if urls_antes > urls_despues:\n",
        "                cambios_especificos['urls_eliminadas'] += (urls_antes - urls_despues)\n",
        "\n",
        "            # Verificar may√∫sculas preservadas\n",
        "            mayus_antes = sum(1 for c in texto_antes if c.isupper())\n",
        "            mayus_despues = sum(1 for c in texto_despues if c.isupper())\n",
        "            if mayus_antes > 0 and mayus_despues > 0:\n",
        "                cambios_especificos['mayusculas_preservadas'] += 1\n",
        "\n",
        "    print(\"üìä Cambios espec√≠ficos de tu limpiador:\")\n",
        "    for cambio, cantidad in cambios_especificos.items():\n",
        "        print(f\"   ‚Ä¢ {cambio.replace('_', ' ').title()}: {cantidad} de {muestra} textos\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OJST9GAJPuLo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÅ Dataset 1\n",
            "   Registros: 731\n",
            "   Muestra (3 textos):\n",
            "                                                 texto  \\\n",
            "246  Envuelto en el manto del entumecimiento emocio...   \n",
            "437  La oscuridad desciende y envuelve el alma en l...   \n",
            "649  Vincul√°ndose con amigos a trav√©s de la √∫ltima ...   \n",
            "\n",
            "                                          Texto_Limpio  \n",
            "246  Envuelto en el manto del entumecimiento emocio...  \n",
            "437  La oscuridad desciende y envuelve el alma en l...  \n",
            "649  Vinculandose con amigos a traves de la ultima ...  \n",
            "\n",
            "üìÅ Dataset 2\n",
            "   Registros: 2,540\n",
            "   Muestra (3 textos):\n",
            "                                                  texto  \\\n",
            "513   Lo hermoso que es el RE4 me hab√≠a olvidado tot...   \n",
            "1350  Envidia ?? Envidia les tengo a todos los que s...   \n",
            "2302  Qu√© cosa la junta de lindos con lindos y linda...   \n",
            "\n",
            "                                           Texto_Limpio  \n",
            "513   Lo hermoso que es el RE4 me habia olvidado tot...  \n",
            "1350  Envidia ?? Envidia les tengo a todos los que s...  \n",
            "2302  Que cosa la junta de lindos con lindos y linda...  \n",
            "\n",
            "üìÅ Dataset 3\n",
            "   Registros: 74,682\n",
            "   Muestra (3 textos):\n",
            "                                                   texto  \\\n",
            "66653               ¬øDemasiado bueno para comer todav√≠a?   \n",
            "1539   Jugando Borderlands 2<unk> porque me odio a m√≠...   \n",
            "68511  Los negros est√°n impresionados por ese est√∫pid...   \n",
            "\n",
            "                                            Texto_Limpio  \n",
            "66653               ¬øDemasiado bueno para comer todavia?  \n",
            "1539   Jugando Borderlands 2<unk> porque me odio a mi...  \n",
            "68511  Los negros estan impresionados por ese estupid...  \n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 1\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 5 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 50 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 2\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 7 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 43 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 3\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 13 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 49 de 50 textos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Lista de dataframes para procesar\n",
        "dataframes = [\n",
        "    (df1_filtrado, \"Dataset 1\"),\n",
        "    (df2_filtrado, \"Dataset 2\"),\n",
        "    (df3_filtrado, \"Dataset 3\")\n",
        "]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for df, nombre in dataframes:\n",
        "    # Aplicar limpieza\n",
        "    df['Texto_Limpio'] = df['texto'].apply(limpiar_texto_sentimientos)\n",
        "\n",
        "    # Guardar copia limpia\n",
        "    resultados[nombre] = df.copy()\n",
        "\n",
        "    # Mostrar info\n",
        "    print(f\"\\nüìÅ {nombre}\")\n",
        "    print(f\"   Registros: {len(df):,}\")\n",
        "    print(f\"   Muestra (3 textos):\")\n",
        "    print(df[['texto', 'Texto_Limpio']].sample(3))\n",
        "\n",
        "# Asignar a variables originales\n",
        "df1_clean = resultados[\"Dataset 1\"]\n",
        "df2_clean = resultados[\"Dataset 2\"]\n",
        "df3_clean = resultados[\"Dataset 3\"]\n",
        "\n",
        "analizar_limpieza_sentimientos(df1_filtrado, df1_clean, \"Dataset 1\")\n",
        "analizar_limpieza_sentimientos(df2_filtrado, df2_clean, \"Dataset 2\")\n",
        "analizar_limpieza_sentimientos(df3_filtrado, df3_clean, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uj1j4hVnPuLo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Esperanza de un ma√±ana mejor, a pesar de los d...</td>\n",
              "      <td>Esperanza</td>\n",
              "      <td>Esperanza de un ma√±ana mejor, a pesar de los d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>La frustraci√≥n aumenta, una tormenta de emocio...</td>\n",
              "      <td>Frustraci√≥n</td>\n",
              "      <td>La frustracion aumenta, una tormenta de emocio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>Vagando por el cementerio de los sue√±os perdid...</td>\n",
              "      <td>Soledad</td>\n",
              "      <td>Vagando por el cementerio de los sue√±os perdid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto  sentimiento  \\\n",
              "114  Esperanza de un ma√±ana mejor, a pesar de los d...    Esperanza   \n",
              "194  La frustraci√≥n aumenta, una tormenta de emocio...  Frustraci√≥n   \n",
              "465  Vagando por el cementerio de los sue√±os perdid...      Soledad   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "114  Esperanza de un ma√±ana mejor, a pesar de los d...  \n",
              "194  La frustracion aumenta, una tormenta de emocio...  \n",
              "465  Vagando por el cementerio de los sue√±os perdid...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jiA1uCrfPuLo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1384</th>\n",
              "      <td>Hey me sorprende de verdad que vean como refer...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Hey me sorprende de verdad que vean como refer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>967</th>\n",
              "      <td>Cuando el hombre cayere, no quedar√° postrado,P...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Cuando el hombre cayere, no quedara postrado,P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>Tenemos muchos mensajes represados y un inconv...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Tenemos muchos mensajes represados y un inconv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1384  Hey me sorprende de verdad que vean como refer...    positivo   \n",
              "967   Cuando el hombre cayere, no quedar√° postrado,P...    negativo   \n",
              "1209  Tenemos muchos mensajes represados y un inconv...    positivo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "1384  Hey me sorprende de verdad que vean como refer...  \n",
              "967   Cuando el hombre cayere, no quedara postrado,P...  \n",
              "1209  Tenemos muchos mensajes represados y un inconv...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uBXLrjxHOWwS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55415</th>\n",
              "      <td>@Activision necesita reiniciar estos servidore...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>@Activision necesita reiniciar estos servidore...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62824</th>\n",
              "      <td>¬øQu√© clase de mierda de GTA V es esta? pic.twi...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>¬øQue clase de mierda de GTA V es esta? pic.twi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55815</th>\n",
              "      <td>¬øNo tienes MP? La campa√±a fue incre√≠ble, pero ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>¬øNo tienes MP? La campa√±a fue increible, pero ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "55415  @Activision necesita reiniciar estos servidore...    Negativo   \n",
              "62824  ¬øQu√© clase de mierda de GTA V es esta? pic.twi...    Negativo   \n",
              "55815  ¬øNo tienes MP? La campa√±a fue incre√≠ble, pero ...     Neutral   \n",
              "\n",
              "                                            Texto_Limpio  \n",
              "55415  @Activision necesita reiniciar estos servidore...  \n",
              "62824  ¬øQue clase de mierda de GTA V es esta? pic.twi...  \n",
              "55815  ¬øNo tienes MP? La campa√±a fue increible, pero ...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Limpieza de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Sentimientos √∫nicos (sin limpiar): 111\n",
            "Muestra (primeros 10): ['Abrumado', 'Aburrimiento', 'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Aislamiento', 'Alegr√≠a', 'Amabilidad', 'Amargura']\n",
            "\n",
            "üìä Sentimientos √∫nicos (limpios): 105\n",
            "Muestra (primeros 10): ['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura']\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n simple para limpiar (igual que usar√°s despu√©s)\n",
        "def limpiar_sentimiento_simple(sentimiento):\n",
        "    \"\"\"Convierte a min√∫sculas y quita espacios extras.\"\"\"\n",
        "    return ' '.join(str(sentimiento).lower().strip().split())\n",
        "\n",
        "# 1. Obtener sentimientos √∫nicos de ambos datasets\n",
        "sentimientos_unicos = sorted(list(df1_clean['sentimiento'].unique()) + list(df2_clean['sentimiento'].unique()) + list(df3_clean['sentimiento'].unique()))\n",
        "\n",
        "print(f\"üìä Sentimientos √∫nicos (sin limpiar): {len(sentimientos_unicos)}\")\n",
        "print(f\"Muestra (primeros 10): {sentimientos_unicos[:10]}\")\n",
        "\n",
        "# 2. Limpiar la lista de sentimientos √∫nicos\n",
        "sentimientos_unicos_limpios = [limpiar_sentimiento_simple(s) for s in sentimientos_unicos]\n",
        "\n",
        "# 3. Eliminar duplicados que aparezcan despu√©s de limpiar\n",
        "sentimientos_unicos_limpios = sorted(set(sentimientos_unicos_limpios))\n",
        "\n",
        "print(f\"\\nüìä Sentimientos √∫nicos (limpios): {len(sentimientos_unicos_limpios)}\")\n",
        "print(f\"Muestra (primeros 10): {sentimientos_unicos_limpios[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ_i8f3tPuLp"
      },
      "source": [
        "#### **Categor√≠as Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pq_HYQiePuLp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos √∫nicos: 105\n",
            "['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura', 'ambivalencia', 'amistad', 'amor', 'angustia', 'anhelo', 'ansiedad', 'anticipaci√≥n', 'apreciaci√≥n', 'aprensivo', 'armon√≠a', 'arrepentimiento', 'asco', 'asombro', 'cautivaci√≥n', 'celebraci√≥n', 'colorido', 'confiado', 'confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'curiosidad', 'decepci√≥n', 'desamor', 'descubrimiento', 'desesperaci√≥n', 'deslumbrar', 'despectivo', 'determinaci√≥n', 'devastado', 'disfrute', 'diversi√≥n', 'dolor', 'elegancia', 'emoci√≥n', 'empoderamiento', 'emp√°tico', 'encantamiento', 'energ√≠a', 'enojo', 'entumecimiento', 'entusiasmo', 'envidia', 'envidioso', 'esperanza', 'euforia', 'excitaci√≥n', 'felicidad', 'frustraci√≥n', 'frustrado', 'grandeza', 'gratitud', 'inspiraci√≥n', 'inspirado', 'intimidaci√≥n', 'irrelevante', 'juguet√≥n', 'logro', 'l√°stima', 'malo', 'maravilla', 'melancol√≠a', 'mel√≥dico', 'miedo', 'motivaci√≥n', 'negativo', 'neutral', 'obst√°culo', 'odiar', 'optimismo', 'orgullo', 'pena', 'positividad', 'positivo', 'p√©rdida', 'reconfortante', 'reflexi√≥n', 'resentimiento', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfacci√≥n', 'serenidad', 'soledad', 'sorpresa', 'sufrimiento', 'temeroso', 'ternura', 'traici√≥n', 'tristeza', 'triunfo', 'verguenza', '√°nimo', '√©xito']\n",
            "Sentimientos positivos: 62\n",
            "Sentimientos negativos: 39\n",
            "Sentimientos neutros: 5\n",
            "\n",
            "‚úÖ Total clasificado: 106/105\n",
            "   - Positivos: 62 (58.5%)\n",
            "   - Negativos: 39 (36.8%)\n",
            "   - Neutros: 5 (4.7%)\n",
            "Total: 106\n",
            "\n",
            "‚ùå Sentimiento no encontrado en el dataset: elaci√≥n\n",
            "‚ùå Sentimiento no encontrado en el dataset: √©xtasis\n",
            "‚ùå Sentimiento no clasificado: irrelevante\n"
          ]
        }
      ],
      "source": [
        "# 1. Definimos las listas de sentimientos seg√∫n su categor√≠a\n",
        "print(f\"Total de sentimientos √∫nicos: {len(sentimientos_unicos_limpios)}\")\n",
        "print(sentimientos_unicos_limpios)\n",
        "\n",
        "# 2. SENTIMIENTOS POSITIVOS COMPLETOS (Bienestar, √©xito, alegr√≠a, admiraci√≥n)\n",
        "positivos = [\n",
        "    'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'alegr√≠a', 'amabilidad', 'amor', 'amistad', 'apreciaci√≥n', 'armon√≠a', 'asombro', 'cautivaci√≥n', 'celebraci√≥n', 'colorido', 'confiado','confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'descubrimiento', 'deslumbrar', 'determinaci√≥n', 'disfrute','diversi√≥n', 'elegancia', 'emoci√≥n', 'emp√°tico', 'empoderamiento',\n",
        "    'encantamiento', 'energ√≠a', 'entusiasmo', 'esperanza', 'euforia', 'excitaci√≥n', 'felicidad', 'grandeza', 'gratitud', 'inspiraci√≥n', 'inspirado', 'intimidaci√≥n', 'juguet√≥n', 'logro','maravilla', 'mel√≥dico', 'motivaci√≥n', 'optimismo', 'orgullo',\n",
        "    'positividad', 'positivo', 'reconfortante', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfacci√≥n', 'serenidad','ternura', 'triunfo', '√°nimo', '√©xito']\n",
        "\n",
        "print(f'Sentimientos positivos: {len(positivos)}'),\n",
        "\n",
        "# 3. SENTIMIENTOS NEGATIVOS COMPLETOS (Dolor, ira, miedo, estr√©s, p√©rdida)\n",
        "negativos = ['abrumado', 'aburrimiento', 'aislamiento', 'amargura', 'angustia', 'anhelo', 'ansiedad', 'aprensivo', 'arrepentimiento', 'asco',  'decepci√≥n', 'desamor', 'desesperaci√≥n', 'despectivo', 'devastado',\n",
        "    'dolor', 'enojo', 'entumecimiento', 'envidia', 'envidioso', 'frustraci√≥n', 'frustrado', 'l√°stima', 'obst√°culo', 'malo', 'melancol√≠a', 'miedo', 'negativo', 'odiar', 'pena', 'p√©rdida', 'reflexi√≥n', 'resentimiento', 'soledad', 'sufrimiento', 'temeroso', 'traici√≥n' , \t'tristeza' , \t'verguenza']\n",
        "\n",
        "print(f'Sentimientos negativos: {len(negativos)}')\n",
        "\n",
        "# 4. SENTIMIENTOS NEUTRALES (Estados ambiguos o contemplativos)\n",
        "neutros =  ['ambivalencia', 'curiosidad', 'neutral','sorpresa','anticipaci√≥n']\n",
        "print(f'Sentimientos neutros: {len(neutros)}')\n",
        "\n",
        "categorias = [positivos, negativos, neutros]\n",
        "\n",
        "# Verificaci√≥n del total\n",
        "total_clasificados = len(positivos) + len(negativos) + len(neutros)\n",
        "print(f'\\n‚úÖ Total clasificado: {total_clasificados}/{len(sentimientos_unicos_limpios)}')\n",
        "print(f'   - Positivos: {len(positivos)} ({len(positivos)/106*100:.1f}%)')\n",
        "print(f'   - Negativos: {len(negativos)} ({len(negativos)/106*100:.1f}%)')\n",
        "print(f'   - Neutros: {len(neutros)} ({len(neutros)/106*100:.1f}%)')\n",
        "print(f'Total: {len(positivos) + len(negativos) + len(neutros)}')\n",
        "print()\n",
        "\n",
        "# Verificar si existen elementos en las listas que no se encuentran en la lista sentimientos_unicos\n",
        "for sentimiento in negativos + positivos + neutros:\n",
        "    if sentimiento not in sentimientos_unicos_limpios:\n",
        "        print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "\n",
        "# for sentimiento in negativos + positivos + neutros:\n",
        "#     if sentimiento not in sentimientos_2:\n",
        "#         print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "# Verificar si todos los sentimientos del dataset est√°n clasificados\n",
        "for sentimiento in sentimientos_unicos_limpios:\n",
        "    if sentimiento not in positivos + negativos + neutros:\n",
        "        print(f\"‚ùå Sentimiento no clasificado: {sentimiento}\")\n",
        "# else:\n",
        "#     print(\"‚úÖ Todos los sentimientos del dataset est√°n clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12vkocMMPuLp"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hAy-90rDPuLp"
      },
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias):\n",
        "    \"\"\"\n",
        "    Categoriza sentimientos solo si est√°n en las listas definidas.\n",
        "    Devuelve None para sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    sent = str(sentimiento).strip().lower()\n",
        "\n",
        "    if sent in positivos:\n",
        "        return 'positivo'\n",
        "    elif sent in negativos:\n",
        "        return 'negativo'\n",
        "    elif sent in neutros:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        # Devolvemos None para posterior filtrado\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XgFiRtKtPuLp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Furioso de ira despu√©s de una acalorada discus...</td>\n",
              "      <td>Enojo</td>\n",
              "      <td>Furioso de ira despues de una acalorada discus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Sentida tristeza tras despedirnos de un querid...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Sentida tristeza tras despedirnos de un querid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>Al experimentar una serie de derrotas en la te...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Al experimentar una serie de derrotas en la te...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "76   Furioso de ira despu√©s de una acalorada discus...       Enojo   \n",
              "78   Sentida tristeza tras despedirnos de un querid...    Negativo   \n",
              "555  Al experimentar una serie de derrotas en la te...     Neutral   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "76   Furioso de ira despues de una acalorada discus...  \n",
              "78   Sentida tristeza tras despedirnos de un querid...  \n",
              "555  Al experimentar una serie de derrotas en la te...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rKZfkztUPuLp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>estoy desbordado</td>\n",
              "      <td>negativo</td>\n",
              "      <td>estoy desbordado</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1894</th>\n",
              "      <td>Creo que lo m√°s afectivamente positivo cuando ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Creo que lo mas afectivamente positivo cuando ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>Hola buenos d√≠as, siempre somos y seremos inve...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Hola buenos dias, siempre somos y seremos inve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "63                                     estoy desbordado    negativo   \n",
              "1894  Creo que lo m√°s afectivamente positivo cuando ...     neutral   \n",
              "1987  Hola buenos d√≠as, siempre somos y seremos inve...     neutral   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "63                                     estoy desbordado  \n",
              "1894  Creo que lo mas afectivamente positivo cuando ...  \n",
              "1987  Hola buenos dias, siempre somos y seremos inve...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20690</th>\n",
              "      <td>Pens√© que les ahorrar√≠a una decepci√≥n. Entonce...</td>\n",
              "      <td>Irrelevante</td>\n",
              "      <td>Pense que les ahorraria una decepcion. Entonce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46018</th>\n",
              "      <td>Las pol√≠ticas de construcci√≥n de tiendas de @V...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Las politicas de construccion de tiendas de @V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34289</th>\n",
              "      <td>I</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto  sentimiento  \\\n",
              "20690  Pens√© que les ahorrar√≠a una decepci√≥n. Entonce...  Irrelevante   \n",
              "46018  Las pol√≠ticas de construcci√≥n de tiendas de @V...     Negativo   \n",
              "34289                                                  I      Neutral   \n",
              "\n",
              "                                            Texto_Limpio  \n",
              "20690  Pense que les ahorraria una decepcion. Entonce...  \n",
              "46018  Las politicas de construccion de tiendas de @V...  \n",
              "34289                                                  I  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT9snuZtPuLq"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DRuHBnaFPuLq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ df1: 731 registros categorizados\n",
            "‚úÖ df2: 2540 registros categorizados\n",
            "‚úÖ df3: 61692 registros categorizados\n"
          ]
        }
      ],
      "source": [
        "df1_clean['Sentimiento_Final'] = df1_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df1_categorized = df1_clean[df1_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df2_clean['Sentimiento_Final'] = df2_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df2_categorized = df2_clean[df2_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df3_clean['Sentimiento_Final'] = df3_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df3_categorized = df3_clean[df3_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "print(f\"‚úÖ df1: {len(df1_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df2: {len(df2_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df3: {len(df3_categorized)} registros categorizados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2Q8euH7QPuLq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Acabo de publicar una nueva entrada en el blog...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Acabo de publicar una nueva entrada en el blog...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>Impresionado por el impresionante amanecer sob...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Impresionado por el impresionante amanecer sob...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>Una determinaci√≥n ardiente arde en su interior...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Una determinacion ardiente arde en su interior...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "10   Acabo de publicar una nueva entrada en el blog...    Positivo   \n",
              "332  Impresionado por el impresionante amanecer sob...    Positivo   \n",
              "224  Una determinaci√≥n ardiente arde en su interior...    Positivo   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "10   Acabo de publicar una nueva entrada en el blog...          positivo  \n",
              "332  Impresionado por el impresionante amanecer sob...          positivo  \n",
              "224  Una determinacion ardiente arde en su interior...          positivo  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "onq_zeNRPuLt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>Adem√°s de su visi√≥n como empresario, la genero...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Ademas de su vision como empresario, la genero...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191</th>\n",
              "      <td>Que r√°pido volviste a buscar su consuelo</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Que rapido volviste a buscar su consuelo</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2526</th>\n",
              "      <td>A los de JxC, y \"Periodistas\" que estan defend...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>A los de JxC, y \"Periodistas\" que estan defend...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1485  Adem√°s de su visi√≥n como empresario, la genero...    positivo   \n",
              "1191           Que r√°pido volviste a buscar su consuelo    positivo   \n",
              "2526  A los de JxC, y \"Periodistas\" que estan defend...    positivo   \n",
              "\n",
              "                                           Texto_Limpio Sentimiento_Final  \n",
              "1485  Ademas de su vision como empresario, la genero...          positivo  \n",
              "1191           Que rapido volviste a buscar su consuelo          positivo  \n",
              "2526  A los de JxC, y \"Periodistas\" que estan defend...          positivo  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7nhxLa6SPxL4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57117</th>\n",
              "      <td>Me encanta meterme en problemas, pero tener un...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Me encanta meterme en problemas, pero tener un...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47075</th>\n",
              "      <td>Oh Dios m√≠o, esta es la mejor comparaci√≥n que ...</td>\n",
              "      <td>Irrelevante</td>\n",
              "      <td>Oh Dios mio, esta es la mejor comparacion que ...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59952</th>\n",
              "      <td>PREMIOS PYD 2020. El Gran Premio no es el √∫nic...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>PREMIOS PYD 2020. El Gran Premio no es el unic...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto  sentimiento  \\\n",
              "57117  Me encanta meterme en problemas, pero tener un...     Negativo   \n",
              "47075  Oh Dios m√≠o, esta es la mejor comparaci√≥n que ...  Irrelevante   \n",
              "59952  PREMIOS PYD 2020. El Gran Premio no es el √∫nic...      Neutral   \n",
              "\n",
              "                                            Texto_Limpio Sentimiento_Final  \n",
              "57117  Me encanta meterme en problemas, pero tener un...          negativo  \n",
              "47075  Oh Dios mio, esta es la mejor comparacion que ...              None  \n",
              "59952  PREMIOS PYD 2020. El Gran Premio no es el unic...           neutral  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfhg_fBXPuLt"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar dataset unificado</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEB_qDA3PuLt"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "W19ms-90PuLu"
      },
      "outputs": [],
      "source": [
        "def limpiar_dataset_unificado(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('Texto_Limpio')['Sentimiento_Final'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['Texto_Limpio'] == texto]['Sentimiento_Final'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['Texto_Limpio'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['Texto_Limpio'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['Texto_Limpio'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['Texto_Limpio', 'Sentimiento_Final']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Texto_Limpio'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Sentimiento_Final'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['Texto_Limpio'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['Texto_Limpio'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['Sentimiento_Final'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "n8a2z5ZNPuLu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39123</th>\n",
              "      <td>Extra√É¬±o cuando Hearthstone era√¢‚Ç¨¬¶</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>ExtraA¬±o cuando Hearthstone eraa‚Ç¨¬¶</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11957</th>\n",
              "      <td>Que los jugadores de @NBA2K representan una ra...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Que los jugadores de @NBA2K representan una ra...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70236</th>\n",
              "      <td>@GhostRecon 5 veces al intentar acceder a la t...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>@GhostRecon 5 veces al intentar acceder a la t...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "39123                 Extra√É¬±o cuando Hearthstone era√¢‚Ç¨¬¶    Negativo   \n",
              "11957  Que los jugadores de @NBA2K representan una ra...    Negativo   \n",
              "70236  @GhostRecon 5 veces al intentar acceder a la t...    Negativo   \n",
              "\n",
              "                                            Texto_Limpio Sentimiento_Final  \n",
              "39123                 ExtraA¬±o cuando Hearthstone eraa‚Ç¨¬¶          negativo  \n",
              "11957  Que los jugadores de @NBA2K representan una ra...          negativo  \n",
              "70236  @GhostRecon 5 veces al intentar acceder a la t...          negativo  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_categorized.sample(3)\n",
        "df2_categorized.sample(3)\n",
        "df3_categorized.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4d4Mra2PuLu"
      },
      "source": [
        "#### **Unificar datataset y limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "CJeTAgAkPuLu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó UNIFICANDO DATASETS CATEGORIZADOS\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (64963, 2)\n",
            "   ‚Ä¢ Registros: 64,963\n",
            "   ‚Ä¢ Textos √∫nicos: 57,744\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 64,963\n",
            "Textos √∫nicos iniciales: 57,744\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚ö†Ô∏è  Encontradas: 209 contradicciones\n",
            "   ‚Ä¢ Ejemplos (primeros 2):\n",
            "     - ''\n",
            "       ‚Üí Sentimientos: neutral, positivo, negativo\n",
            "     - '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...'\n",
            "       ‚Üí Sentimientos: negativo, neutral\n",
            "   üóëÔ∏è  Eliminados: 2,633 registros por contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚ö†Ô∏è  Encontrados: 3,377 textos duplicados\n",
            "   ‚Ä¢ Registros a eliminar: 4,795\n",
            "   üóëÔ∏è  Eliminados: 4,795 registros duplicados\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 57,535\n",
            "   ‚Ä¢ Textos √∫nicos finales: 57,535\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 64,963\n",
            "Registros finales: 57,535\n",
            "Total eliminados: 7,428 (11.4%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ negativo: 21,326 (37.1%)\n",
            "   ‚Ä¢ positivo: 19,219 (33.4%)\n",
            "   ‚Ä¢ neutral: 16,990 (29.5%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó UNIFICANDO DATASETS CATEGORIZADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Unificar los datasets categorizados\n",
        "df_unificado = pd.concat([df1_categorized[['Texto_Limpio', 'Sentimiento_Final']], df2_categorized[['Texto_Limpio', 'Sentimiento_Final']], df3_categorized[['Texto_Limpio','Sentimiento_Final']]], ignore_index=True)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_unificado.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_unificado):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_unificado['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "df_final = limpiar_dataset_unificado(df_unificado, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PiaR4I5zPuLu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49011</th>\n",
              "      <td>@ Rainbow6Game Por favor, haz una serie de Rai...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24584</th>\n",
              "      <td>Odio la mierda moderna de asesinos.</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55202</th>\n",
              "      <td>@EAMaddenNFL arregla tus servidores, los desaf...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Texto_Limpio Sentimiento_Final\n",
              "49011  @ Rainbow6Game Por favor, haz una serie de Rai...          positivo\n",
              "24584                Odio la mierda moderna de asesinos.          negativo\n",
              "55202  @EAMaddenNFL arregla tus servidores, los desaf...          negativo"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unificado.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOG13F7lPuLv"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5DwJkdPuLv"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2VLH0dQePuLv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "============================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------\n",
            "Positivo     |    19219 |      33.4% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |    21326 |     37.07% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |    16990 |     29.53% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------\n",
            "TOTAL        |    57535 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['Sentimiento_Final'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 58)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6Bpu2ZPuLv"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "INsd0XvNPuLv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hovertemplate": "label=%{label}<br>value=%{value}<extra></extra>",
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "negativo",
                    "positivo",
                    "neutral"
                  ],
                  "legendgroup": "",
                  "name": "",
                  "showlegend": true,
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "TlMTS15C",
                    "dtype": "i2"
                  }
                }
              ],
              "layout": {
                "height": 500,
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 57535 registros</span>",
                  "x": 0.5
                },
                "width": 500
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Grafica de pastel con Plotly\n",
        "\n",
        "valores = df_final['Sentimiento_Final'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "fig1 = px.pie(\n",
        "    names = valores.sentimientos,\n",
        "    values = valores.Cantidad,\n",
        ")\n",
        "\n",
        "fig1.update_traces(textposition='inside', textinfo='label+percent',  insidetextfont=dict(color = 'white', size=14)\n",
        ")\n",
        "\n",
        "fig1.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMplULMaPuLv"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwSlmvXSPuLv"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "esUzQFjnPuLv"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9kZOcK7PuLv"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WSBwUlWgPuLw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset.csv\n",
            "üìä Registros: 57,535\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"2.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\",\n",
        "        \"twitter_trainnig.csv\"    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxLqWrOWPuLw"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YB9ZY3b3PuLw"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PwJXRfMxPuLw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 57,535 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 57,535 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eBDe0CPbl8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 57,535 registros (encoding: utf-8-sig)\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Verificar que el archivo se pueda leer\n",
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=enc, nrows=5)  # Probar con 5 filas\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None\n",
        "\n",
        "# Uso simple\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL-DDylhPuLw"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MQcqcJa0PuLx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\n",
            "======================================================================\n",
            "‚úÖ Dataset final: 57,535 registros\n",
            "‚úÖ Distribuci√≥n balanceada: 33.4% üëç | 37.07% üëé | 29.53% üòê\n",
            "‚úÖ Calidad del dataset:\n",
            "   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\n",
            "   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\n",
            "   ‚Ä¢ 0 valores nulos\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar):,} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: {porcentajes['positivo']}% üëç | {porcentajes['negativo']}% üëé | {porcentajes['neutral']}% üòê\")\n",
        "print(f\"‚úÖ Calidad del dataset:\")\n",
        "print(f\"   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\")\n",
        "print(f\"   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\")\n",
        "print(f\"   ‚Ä¢ 0 valores nulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "- https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "- https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n",
        "\n",
        "- https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "3K2ezd_nPuLy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 57535 entries, 0 to 64962\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        57535 non-null  object\n",
            " 1   sentimiento  57535 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzFpQ4smRcug"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Machine Learning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Z6MSbMjXPuLy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61877</th>\n",
              "      <td>Terminado... @GhostRecon</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          texto sentimiento\n",
              "61877  Terminado... @GhostRecon    positivo"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Cdy77Lknl9pd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\marely\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Limpieza de texto mejorada aplicada\n",
            "\n",
            "Muestra de textos limpios:\n",
            "                                                   texto sentimiento\n",
            "42042                  home depot cayo 5 - invst.lyqgfit     neutral\n",
            "6686   molesta gente? solo cuestion accesibilidad. si...     neutral\n",
            "55995  deshaun watson 86? malditos negros irrespetuos...    negativo\n",
            "39249  cajas llenas tabletas llenan biblioteca escuel...     neutral\n",
            "41284  navegando sitio web office depot vaya, hoy una...    positivo\n"
          ]
        }
      ],
      "source": [
        "# Descargar stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def limpiar_texto_mejorado(texto):\n",
        "    \"\"\"\n",
        "    Limpieza de texto m√°s conservadora que preserva palabras  de negaci√≥n\n",
        "    y modificadores de intensidad.\n",
        "    \"\"\"\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Eliminar caracteres especiales PERO preservar puntuaci√≥n emocional\n",
        "    texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±0-9\\s!?.,\\-]', '', texto)\n",
        "\n",
        "    # Stopwords espa√±olas\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "    # PALABRAS CR√çTICAS A MANTENER (expandida vs. original)\n",
        "    palabras_criticas = {\n",
        "        # Negaciones\n",
        "        'no', 'ni', 'sin', 'nunca', 'jamas', 'tampoco', 'nada', 'nadie',\n",
        "        # Intensificadores\n",
        "        'muy', 'mucho', 'poco', 'mas', 'menos', 'demasiado', 'bastante',\n",
        "        # Modales\n",
        "        'pero', 'aunque', 'sino', 'si',\n",
        "        # Adjetivos de sentimiento\n",
        "        'malo', 'mala', 'mal', 'bien', 'bueno', 'buena', 'mejor', 'peor',\n",
        "        'horrible', 'terrible', 'excelente', 'pesimo', 'p√©simo',\n",
        "        # Verbos de sentimiento\n",
        "        'odio', 'amo', 'encanta', 'disgusta', 'molesta',\n",
        "        # Otros\n",
        "        'contra', 'hacia'\n",
        "    }\n",
        "\n",
        "    # Remover stopwords EXCEPTO las cr√≠ticas\n",
        "    stop_words = stop_words - palabras_criticas\n",
        "\n",
        "    palabras = texto.split()\n",
        "    palabras_filtradas = [palabra for palabra in palabras if palabra not in stop_words]\n",
        "\n",
        "    return ' '.join(palabras_filtradas)\n",
        "\n",
        "# Aplicar limpieza mejorada\n",
        "df['texto'] = df['texto'].apply(limpiar_texto_mejorado)\n",
        "\n",
        "print(\"‚úÖ Limpieza de texto mejorada aplicada\")\n",
        "print(f\"\\nMuestra de textos limpios:\")\n",
        "print(df[['texto', 'sentimiento']].sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3SJfTa-EPuLy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56437</th>\n",
              "      <td>guau! extra√±o blitz, pero llego tiempo navidad...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15403</th>\n",
              "      <td>dota2 acaso importa base jugadores? tener punt...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52036</th>\n",
              "      <td>facebook vuelto completamente estupido adoptar...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28816</th>\n",
              "      <td>encantan incentivos prounk</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2318</th>\n",
              "      <td>bendecido cigarros sabor naranja.</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento\n",
              "56437  guau! extra√±o blitz, pero llego tiempo navidad...    positivo\n",
              "15403  dota2 acaso importa base jugadores? tener punt...    negativo\n",
              "52036  facebook vuelto completamente estupido adoptar...    negativo\n",
              "28816                         encantan incentivos prounk    positivo\n",
              "2318                   bendecido cigarros sabor naranja.    positivo"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LH5NgVcQKEx"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGMacHrPuLy"
      },
      "source": [
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NpuPPs85PuLy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Librer√≠a 'imblearn' instalada exitosamente.\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('pip install imblearn') # type: ignore\n",
        "print(\"Librer√≠a 'imblearn' instalada exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx2DlzvEPuLz"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uFz0LAY_PuLz"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "djlXVfUUl9pe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n de clases:\n",
            "sentimiento\n",
            "negativo    21326\n",
            "positivo    19219\n",
            "neutral     16990\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Train: 46028 | Test: 11507\n",
            "\n",
            "‚úÖ Vectorizaci√≥n completada\n",
            "   Dimensiones: (46028, 10000)\n",
            "   Vocabulario: 10000 t√©rminos\n"
          ]
        }
      ],
      "source": [
        "# Separar X e y\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "print(\"Distribuci√≥n de clases:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Divisi√≥n train/test\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# üÜï TF-IDF MEJORADO\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,      # ‚¨Ü Aumentado de 5000\n",
        "    ngram_range=(1, 3),      # ‚¨Ü Trigramas (antes solo bigramas)\n",
        "    min_df=2,                # üÜï Nuevo\n",
        "    max_df=0.95,             # üÜï Nuevo\n",
        "    sublinear_tf=True        # üÜï Nuevo\n",
        ")\n",
        "\n",
        "X_train_tfidf_unbalanced = vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\n‚úÖ Vectorizaci√≥n completada\")\n",
        "print(f\"   Dimensiones: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"   Vocabulario: {len(vectorizer.get_feature_names_out())} t√©rminos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIbtwkkQhx0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbfr-opZPuLz"
      },
      "source": [
        "\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "FoyoVnuNPuLz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tama√±o del conjunto de entrenamiento (desbalanceado): 46028 muestras\n",
            "Tama√±o del conjunto de prueba: 11507 muestras\n",
            "Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\n",
            "sentimiento\n",
            "negativo    17061\n",
            "positivo    15375\n",
            "neutral     13592\n",
            "Name: count, dtype: int64\n",
            "Distribuci√≥n de clases en el conjunto de prueba:\n",
            "sentimiento\n",
            "negativo    4265\n",
            "positivo    3844\n",
            "neutral     3398\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\n",
            "Forma de X_train_tfidf_unbalanced: (46028, 5000)\n",
            "Forma de X_test_tfidf: (11507, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Dividir el dataset en conjuntos de entrenamiento y prueba ANTES de aplicar SMOTE\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTama√±o del conjunto de entrenamiento (desbalanceado): {len(X_train_unbalanced)} muestras\")\n",
        "print(f\"Tama√±o del conjunto de prueba: {len(X_test)} muestras\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\\n{y_train_unbalanced.value_counts()}\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de prueba:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Inicializar TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(1,2)) # Limitando las caracter√≠sticas para eficiencia\n",
        "\n",
        "# Ajustar y transformar X_train_unbalanced, y transformar X_test\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nVectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\")\n",
        "print(f\"Forma de X_train_tfidf_unbalanced: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"Forma de X_test_tfidf: {X_test_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpTP-d7RHYa"
      },
      "source": [
        "### <font size=12 color=lightgreen> Balanceo del Conjunto de Entrenamiento con SMOTE</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_FmuXRPuLz"
      },
      "source": [
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "DHm0iiw1PuLz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SMOTE aplicado\n",
            "\n",
            "Distribuci√≥n despu√©s de SMOTE:\n",
            "sentimiento\n",
            "neutral     17061\n",
            "positivo    17061\n",
            "negativo    17061\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Nuevas dimensiones: (51183, 5000)\n"
          ]
        }
      ],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"‚úÖ SMOTE aplicado\")\n",
        "print(f\"\\nDistribuci√≥n despu√©s de SMOTE:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(f\"\\nNuevas dimensiones: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5mkvXaQlFi"
      },
      "source": [
        "### <font size=12 color=lightgreen> Entrenamiento del Modelo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_cggSuxPuLz"
      },
      "source": [
        "\n",
        "# Entrenamiento de M√∫ltiples Modelos\n",
        "\n",
        "Entrenaremos 3 modelos y compararemos:\n",
        "1. **Logistic Regression** (baseline mejorado)\n",
        "2. **SVM** (Support Vector Machine)\n",
        "3. **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4cR6qbPuLz",
        "outputId": "03a3f76d-7c06-4d83-b8af-149723dc4ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/3] Entrenando Logistic Regression...\n",
            "‚úÖ Logistic Regression entrenado\n",
            "\n",
            "[2/3] Entrenando SVM...\n",
            "‚úÖ SVM entrenado\n",
            "\n",
            "[3/3] Entrenando Random Forest...\n",
            "‚úÖ Random Forest entrenado\n",
            "\n",
            "============================================================\n",
            "‚úÖ TODOS LOS MODELOS ENTRENADOS\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 1. Logistic Regression (mejorado)\n",
        "print(\"[1/3] Entrenando Logistic Regression...\")\n",
        "model_lr = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    random_state=42,\n",
        "    C=1.0,\n",
        "    solver='lbfgs',\n",
        "    multi_class='multinomial'\n",
        ")\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ Logistic Regression entrenado\")\n",
        "\n",
        "# 2. SVM\n",
        "print(\"\\n[2/3] Entrenando SVM...\")\n",
        "model_svm = SVC(\n",
        "    kernel='linear',\n",
        "    C=1.0,\n",
        "    probability=True,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ SVM entrenado\")\n",
        "\n",
        "# 3. Random Forest\n",
        "print(\"\\n[3/3] Entrenando Random Forest...\")\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "model_rf.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ Random Forest entrenado\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ TODOS LOS MODELOS ENTRENADOS\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq-wLkyQmaI"
      },
      "source": [
        "### <font size=12 color=lightgreen>Evaluaci√≥n de Modelos:</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNhozE5IPuLz"
      },
      "source": [
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "NYZ2qppwlC0z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUACI√ìN: Logistic Regression (Mejorado)\n",
            "============================================================\n",
            "\n",
            "üìä Accuracy: 0.7230 (72.30%)\n",
            "\n",
            "üìã Reporte de Clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo     0.7726    0.7615    0.7670      4265\n",
            "     neutral     0.6653    0.6886    0.6768      3398\n",
            "    positivo     0.7213    0.7105    0.7159      3844\n",
            "\n",
            "    accuracy                         0.7230     11507\n",
            "   macro avg     0.7198    0.7202    0.7199     11507\n",
            "weighted avg     0.7238    0.7230    0.7233     11507\n",
            "\n",
            "\n",
            "üî¢ Matriz de Confusi√≥n:\n",
            "[[3248  545  472]\n",
            " [ 475 2340  583]\n",
            " [ 481  632 2731]]\n",
            "\n",
            "üíØ Probabilidad promedio (correctas): 0.7273 (72.73%)\n",
            "\n",
            "============================================================\n",
            "EVALUACI√ìN: SVM\n",
            "============================================================\n",
            "\n",
            "üìä Accuracy: 0.7306 (73.06%)\n",
            "\n",
            "üìã Reporte de Clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo     0.7713    0.7672    0.7692      4265\n",
            "     neutral     0.6787    0.6951    0.6868      3398\n",
            "    positivo     0.7326    0.7214    0.7270      3844\n",
            "\n",
            "    accuracy                         0.7306     11507\n",
            "   macro avg     0.7276    0.7279    0.7277     11507\n",
            "weighted avg     0.7311    0.7306    0.7308     11507\n",
            "\n",
            "\n",
            "üî¢ Matriz de Confusi√≥n:\n",
            "[[3272  543  450]\n",
            " [ 474 2362  562]\n",
            " [ 496  575 2773]]\n",
            "\n",
            "üíØ Probabilidad promedio (correctas): 0.7795 (77.95%)\n",
            "\n",
            "============================================================\n",
            "EVALUACI√ìN: Random Forest\n",
            "============================================================\n",
            "\n",
            "üìä Accuracy: 0.7931 (79.31%)\n",
            "\n",
            "üìã Reporte de Clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo     0.8022    0.8281    0.8150      4265\n",
            "     neutral     0.8050    0.7398    0.7710      3398\n",
            "    positivo     0.7737    0.8012    0.7872      3844\n",
            "\n",
            "    accuracy                         0.7931     11507\n",
            "   macro avg     0.7936    0.7897    0.7911     11507\n",
            "weighted avg     0.7935    0.7931    0.7927     11507\n",
            "\n",
            "\n",
            "üî¢ Matriz de Confusi√≥n:\n",
            "[[3532  298  435]\n",
            " [ 418 2514  466]\n",
            " [ 453  311 3080]]\n",
            "\n",
            "üíØ Probabilidad promedio (correctas): 0.6705 (67.05%)\n"
          ]
        }
      ],
      "source": [
        "def evaluar_modelo(model, X_test, y_test, nombre):\n",
        "    \"\"\"Evaluaci√≥n detallada de un modelo\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUACI√ìN: {nombre}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nüìä Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nüìã Reporte de Clasificaci√≥n:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    print(f\"\\nüî¢ Matriz de Confusi√≥n:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    # Probabilidad promedio\n",
        "    predicciones_correctas = y_pred == y_test\n",
        "    probabilidades_correctas = []\n",
        "\n",
        "    for i, correcto in enumerate(predicciones_correctas):\n",
        "        if correcto:\n",
        "            clase_predicha = y_pred[i]\n",
        "            clase_idx = list(model.classes_).index(clase_predicha)\n",
        "            probabilidades_correctas.append(y_pred_proba[i][clase_idx])\n",
        "\n",
        "    if probabilidades_correctas:\n",
        "        prob_promedio = np.mean(probabilidades_correctas)\n",
        "        print(f\"\\nüíØ Probabilidad promedio (correctas): {prob_promedio:.4f} ({prob_promedio*100:.2f}%)\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "acc_lr = evaluar_modelo(model_lr, X_test_tfidf, y_test, \"Logistic Regression (Mejorado)\")\n",
        "acc_svm = evaluar_modelo(model_svm, X_test_tfidf, y_test, \"SVM\")\n",
        "acc_rf = evaluar_modelo(model_rf, X_test_tfidf, y_test, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye01V19FQn7Z"
      },
      "source": [
        "### <font size=12 color=lightgreen> Serializaci√≥n del Modelo y Vectorizadors</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r68b_Sx6PuL0"
      },
      "source": [
        "\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "meOQ2yohPuL0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m mejor_modelo \u001b[38;5;241m=\u001b[39m model_svm\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmejor_modelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Based on evaluation, SVM was the best model, so we'll use it for serialization.\n",
        "mejor_modelo = model_svm\n",
        "\n",
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(mejor_modelo, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx1ScQ4um7vg"
      },
      "outputs": [],
      "source": [
        "# Tabla comparativa\n",
        "comparacion = pd.DataFrame({\n",
        "    'Modelo': ['Logistic Regression', 'SVM', 'Random Forest'],\n",
        "    'Accuracy': [acc_lr, acc_svm, acc_rf]\n",
        "})\n",
        "\n",
        "comparacion['Accuracy %'] = comparacion['Accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "comparacion['Mejora vs. Original'] = comparacion['Accuracy'].apply(lambda x: f\"+{(x - 0.79)*100:.2f}%\")\n",
        "comparacion = comparacion.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä COMPARACI√ìN DE MODELOS\")\n",
        "print(\"=\"*70)\n",
        "print(comparacion.to_string(index=False))\n",
        "print(\"\\nüî∏ Modelo original (baseline): 79.00%\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "mejor_accuracy = comparacion['Accuracy'].max()\n",
        "if mejor_accuracy >= 0.83:\n",
        "    print(\"\\n‚úÖ META DE FASE 1 ALCANZADA (83-85%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Casi alcanzado (falta {(0.83 - mejor_accuracy)*100:.2f}%)\")\n",
        "\n",
        "comparacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKTLn4ylPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Pruebas con Casos Espec√≠ficos</font>\n",
        "\n",
        "Validar que ahora clasifica correctamente los casos problem√°ticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q-eYggXPuL0"
      },
      "outputs": [],
      "source": [
        "# Seleccionar el mejor modelo\n",
        "modelos_dict = {\n",
        "    'Logistic Regression': model_lr,\n",
        "    'SVM': model_svm,\n",
        "    'Random Forest': model_rf\n",
        "}\n",
        "\n",
        "nombre_mejor = comparacion.iloc[0]['Modelo']\n",
        "mejor_modelo = modelos_dict[nombre_mejor]\n",
        "\n",
        "print(f\"üèÜ Mejor modelo: {nombre_mejor}\")\n",
        "print(f\"üìä Accuracy: {comparacion.iloc[0]['Accuracy %']}\")\n",
        "\n",
        "# Casos de prueba\n",
        "casos_prueba = [\n",
        "    (\"mala atenci√≥n\", \"negativo\"),\n",
        "    (\"mal comportamiento de los empleado\", \"negativo\"),\n",
        "    (\"la empresa esta perdida en lo que hace\", \"negativo\"),\n",
        "    (\"p√©simo servicio\", \"negativo\"),\n",
        "    (\"nunca vuelvo\", \"negativo\"),\n",
        "    (\"excelente servicio\", \"positivo\"),\n",
        "    (\"me encant√≥\", \"positivo\"),\n",
        "    (\"muy buena atenci√≥n\", \"positivo\"),\n",
        "    (\"es normal, nada especial\", \"neutral\"),\n",
        "    (\"est√° bien\", \"neutral\"),\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PRUEBAS CON CASOS ESPEC√çFICOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "aciertos = 0\n",
        "\n",
        "for texto, esperado in casos_prueba:\n",
        "    # Preprocesar\n",
        "    texto_limpio = limpiar_texto_mejorado(texto)\n",
        "\n",
        "    # Vectorizar y predecir\n",
        "    texto_vectorizado = tfidf_vectorizer.transform([texto_limpio])\n",
        "    prediccion = mejor_modelo.predict(texto_vectorizado)[0]\n",
        "    probabilidades = mejor_modelo.predict_proba(texto_vectorizado)[0]\n",
        "\n",
        "    clase_idx = list(mejor_modelo.classes_).index(prediccion)\n",
        "    prob_prediccion = probabilidades[clase_idx]\n",
        "\n",
        "    es_correcto = prediccion == esperado\n",
        "    if es_correcto:\n",
        "        aciertos += 1\n",
        "        emoji = \"‚úÖ\"\n",
        "    else:\n",
        "        emoji = \"‚ùå\"\n",
        "\n",
        "    print(f\"\\n{emoji} '{texto}'\")\n",
        "    print(f\"   Esperado: {esperado} | Predicho: {prediccion} | Confianza: {prob_prediccion*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"RESULTADO: {aciertos}/{len(casos_prueba)} correctos ({aciertos/len(casos_prueba)*100:.1f}%\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYeFtgokPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1xQz3UgPuL0"
      },
      "outputs": [],
      "source": [
        "from pyexpat import model\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "# Este es el archivo que debes subir a la carpeta de tu microservicio\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEPArdRuz5sC"
      },
      "source": [
        "********************************************************************************************************************************************************************************************************************"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
