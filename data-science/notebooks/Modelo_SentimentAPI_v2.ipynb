{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "from io import StringIO\n",
        "import urllib.response\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de los datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "yOwHw3xtYJEg"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "def importar_dataset(url, separator=';'):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL detectando encoding autom√°ticamente.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Descargar contenido una sola vez\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "\n",
        "        # 2. Detectar encoding\n",
        "        result = chardet.detect(content)\n",
        "        encoding = result['encoding']\n",
        "        print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "\n",
        "        # 3. Decodificar y cargar en DataFrame\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        data = pd.read_csv(StringIO(decoded_content), sep=separator)\n",
        "\n",
        "        print(\"‚úÖ Archivo cargado correctamente\")\n",
        "        print(f\"üìä Tama√±o del dataset: {data.shape}\")\n",
        "        print(\"\\nüîç Muestra aleatoria (3 registros):\")\n",
        "        print(data.sample(3))\n",
        "\n",
        "        return data\n",
        "\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e}\")\n",
        "        return None\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ùå Error al parsear CSV: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZW5B7jk5-x"
      },
      "source": [
        "#### **Dataset1: sentimentdataset_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "iWgPb0VhYeKT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 72.97%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (731, 15)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "     Unnamed: 0.1  Unnamed: 0  \\\n",
            "523           525         529   \n",
            "164           165         167   \n",
            "288           289         293   \n",
            "\n",
            "                                                  Text  Sentiment  \\\n",
            "523  En el p√∫blico de una actuaci√≥n de Jay-Z, la le...    Orgullo   \n",
            "164  Abrumado por el dolor, extra√±ando profundament...      Dolor   \n",
            "288  Susurros Esperanzadores del viento, que llevan...  Esperanza   \n",
            "\n",
            "            Timestamp                User   Platform  \\\n",
            "523  10-09-2017 20:15  JayZEmpireListener    Twitter   \n",
            "164  05-07-2022 15:45       MourningHeart  Instagram   \n",
            "288   06-05-2023 7:20       WindWhisperer    Twitter   \n",
            "\n",
            "                             Hashtags  Retweets  Likes Country  Year  Month  \\\n",
            "523              #Orgullo #JayZAnthem        18     35   EE.UU  2017      9   \n",
            "164                   #Duelo #P√©rdida         8     15  Canad√°  2022      7   \n",
            "288  #Esperanza #Ma√±anasM√°sBrillantes        15     30   India  2023      5   \n",
            "\n",
            "     Day  Hour  \n",
            "523   10    20  \n",
            "164    5    15  \n",
            "288    6     7  \n"
          ]
        }
      ],
      "source": [
        "df1_raw = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/sentimentdataset_es.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKr3W1NEaBrP"
      },
      "source": [
        "#### **Dataset2: sentiment_analysis_dataset.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "d2eRhM-MYh6L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (2540, 3)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "                                                  texto  label sentimiento\n",
            "1104  Todo el dia intentando compras las entradas pa...      0    negativo\n",
            "1829         Hoy he decidido, que te tengo que olvidar.      1     neutral\n",
            "1949  Hoy me dijeron que yo era una ni√±a EXITOSA, y ...      1     neutral\n"
          ]
        }
      ],
      "source": [
        "df2_raw = importar_dataset(\"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/refs/heads/feature/data-science-marely/data-science/datasets/datasets-origin/sentiment_analysis_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "9qa7fqEjJagA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: UTF-8-SIG (confianza: 100.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (74682, 4)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "          id              plataforma sentimiento  \\\n",
            "52467  10613  RedDeadRedemption(RDR)     Neutral   \n",
            "14040   2808                   Dota2     Neutral   \n",
            "22172   4194                   CS-GO     Neutral   \n",
            "\n",
            "                                                   texto  \n",
            "52467  Red Dead Redemption. Nuevo en store.playstatio...  \n",
            "14040  La temporada 3 de OGA Dota PIT: Europa/CIS par...  \n",
            "22172  CS: GO: Agrega nuevo banco en Mirage. Smileybs...  \n"
          ]
        }
      ],
      "source": [
        "df3_raw = importar_dataset(\"https://github.com/eduardotec05/datasets/raw/refs/heads/main/twitter_training_esp_convertido%20(2).csv\", separator=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Dataset3: Twitter_training.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "nY1nIBYtKA9g"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>plataforma</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Estoy llegando a Borderlands y los asesinar√© a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a las fronteras y os matar√© a todos,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a Borderlands y los matar√© a todos.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a Borderlands y los asesinar√© a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Me estoy metiendo en Borderlands 2 y os voy a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id   plataforma sentimiento  \\\n",
              "0  2401  Borderlands    Positivo   \n",
              "1  2401  Borderlands    Positivo   \n",
              "2  2401  Borderlands    Positivo   \n",
              "3  2401  Borderlands    Positivo   \n",
              "4  2401  Borderlands    Positivo   \n",
              "\n",
              "                                               texto  \n",
              "0  Estoy llegando a Borderlands y los asesinar√© a...  \n",
              "1  Voy a llegar a las fronteras y os matar√© a todos,  \n",
              "2   Voy a llegar a Borderlands y los matar√© a todos.  \n",
              "3  Voy a llegar a Borderlands y los asesinar√© a t...  \n",
              "4  Me estoy metiendo en Borderlands 2 y os voy a ...  "
            ]
          },
          "execution_count": 220,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "2hn5BGLpl8eS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 1\n",
            "============================================================\n",
            "üìä Forma: (731, 15)\n",
            "üìù Columnas: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
            "üî§ Columnas de texto: ['Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Country']\n",
            "\n",
            "üìù Analizando columna: 'Text'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     '¬°Disfrutando de un hermoso d√≠a en el parque!'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'Esta ma√±ana el tr√°fico era terrible.'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     '¬°Acabo de terminar un entrenamiento incre√≠ble!??'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     '¬°Emocionado por la escapada de fin de semana que viene!'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Probando una nueva receta para cenar esta noche.'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 2\n",
            "============================================================\n",
            "üìä Forma: (2540, 3)\n",
            "üìù Columnas: ['texto', 'label', 'sentimiento']\n",
            "üî§ Columnas de texto: ['texto', 'sentimiento']\n",
            "\n",
            "üìù Analizando columna: 'texto'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'termine bien abrumado despu√©s de hoy'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'me siento abrumado'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Me siento un poco abrumado por la cantidad de cosas que quiero dibujar, ver, jug...'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Salvador la √∫nica persona que no la ha abrumado de versiones???? #NadieComoT√∫'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Denme un helado o algo que ando full abrumado.'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 3\n",
            "============================================================\n",
            "üìä Forma: (74682, 4)\n",
            "üìù Columnas: ['id', 'plataforma', 'sentimiento', 'texto']\n",
            "üî§ Columnas de texto: ['plataforma', 'sentimiento', 'texto']\n",
            "\n",
            "üìù Analizando columna: 'plataforma'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 221,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def verificar_calidad_importacion(df, nombre_dataset):\n",
        "    \"\"\"\n",
        "    Verifica que no se haya perdido informaci√≥n durante la importaci√≥n.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD: {nombre_dataset}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if df is None:\n",
        "        print(\"‚ùå Dataset es None\")\n",
        "        return False\n",
        "\n",
        "    # 1. Informaci√≥n b√°sica\n",
        "    print(f\"üìä Forma: {df.shape}\")\n",
        "    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "\n",
        "    # 2. Buscar columnas de texto\n",
        "    columnas_texto = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    print(f\"üî§ Columnas de texto: {columnas_texto}\")\n",
        "\n",
        "    if not columnas_texto:\n",
        "        print(\"‚ö†Ô∏è  No se encontraron columnas de texto\")\n",
        "        return True\n",
        "\n",
        "    # 3. Analizar una columna de texto (usar la primera)\n",
        "    col_texto = columnas_texto[0]\n",
        "    print(f\"\\nüìù Analizando columna: '{col_texto}'\")\n",
        "\n",
        "    # Muestra de textos\n",
        "    textos = df[col_texto].dropna().head(5).tolist()\n",
        "\n",
        "    problemas = []\n",
        "\n",
        "    for i, texto in enumerate(textos):\n",
        "        if isinstance(texto, str):\n",
        "            # Buscar caracteres de reemplazo (ÔøΩ) que indican problemas\n",
        "            caracteres_problema = texto.count('ÔøΩ')\n",
        "            if caracteres_problema > 0:\n",
        "                problemas.append(f\"Texto {i+1} tiene {caracteres_problema} caracteres de reemplazo (ÔøΩ)\")\n",
        "\n",
        "            # Buscar emojis\n",
        "            emojis = [c for c in texto if unicodedata.category(c)[0] in ['S', 'So']]\n",
        "            if emojis:\n",
        "                print(f\"  Texto {i+1}: ‚úÖ Tiene {len(emojis)} emoji(s): {''.join(emojis[:3])}\")\n",
        "            else:\n",
        "                print(f\"  Texto {i+1}: üìÑ Sin emojis\")\n",
        "\n",
        "            # Mostrar fragmento\n",
        "            preview = texto[:80] + \"...\" if len(texto) > 80 else texto\n",
        "            print(f\"     '{preview}'\")\n",
        "\n",
        "    # 4. Resumen\n",
        "    if problemas:\n",
        "        print(f\"\\n‚ö†Ô∏è  PROBLEMAS ENCONTRADOS:\")\n",
        "        for problema in problemas:\n",
        "            print(f\"   ‚Ä¢ {problema}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\")\n",
        "        return True\n",
        "\n",
        "verificar_calidad_importacion(df1_raw, \"Dataset 1\")\n",
        "verificar_calidad_importacion(df2_raw, \"Dataset 2\")\n",
        "verificar_calidad_importacion(df3_raw, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvsjkC76PuLm"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "6X6oJxnAPuLm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 texto  sentimiento\n",
            "599  Pas√© la tarde en un museo, fingiendo ser culto...   Curiosidad\n",
            "682  Reflexionando sobre los desaf√≠os del a√±o escol...     Tristeza\n",
            "675  Elaboraci√≥n de intrincadas pulseras de la amis...      Alegr√≠a\n",
            "450  Asfixi√°ndose en el silencio de la soledad, don...  Aislamiento\n",
            "496  Viajando a trav√©s de la serenidad de Santorini...    Serenidad\n",
            "                                                  texto sentimiento\n",
            "1864  \"No son momentos de confusi√≥n, son momentos de...     neutral\n",
            "1531  Hay algo de mi por lo que me siento muy orgull...    positivo\n",
            "1957  Gracias Por Su Apoyo Gente Gracias A Ustedes Y...     neutral\n",
            "819   Mi columna de ma√±ana en La Rep√∫blica se llama ...    negativo\n",
            "363   #gelp Pero claro. Ahora hay q tomar sopa.  A p...    negativo\n",
            "                                                   texto  sentimiento\n",
            "70058      @fox_tica Dutch nos advirti√≥ que ten√≠a raz√≥n!      Neutral\n",
            "14054  Geek Fam gana la ONE Esports Dota 2 SEA League...      Neutral\n",
            "23714  Compil√≥ una lista de m√°s de 600 consejos de va...      Neutral\n",
            "22010  Todos los juegos de Tekken. √ê≈ì2. Escapar. Pok√É...     Positivo\n",
            "4504   7 Haciendo 5 flexiones cada vez que perdemos. ...  Irrelevante\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n filtrar dataset\n",
        "def filtrar_dataset(data):\n",
        "    data_filtro = data[['texto', 'sentimiento']]\n",
        "    data_filtro = data_filtro[data_filtro['texto'].str.strip() != \"\"]\n",
        "    print(data_filtro.sample(5))\n",
        "    return data_filtro\n",
        "\n",
        "# Reemplazar nombre columnas Text por texto, Sentiment por sentimiento\n",
        "df1_raw.rename({'Text':'texto', 'Sentiment':'sentimiento'}, axis=1, inplace=True)\n",
        "df1_filtrado = filtrar_dataset(df1_raw)\n",
        "df2_filtrado = filtrar_dataset(df2_raw)\n",
        "df3_filtrado = filtrar_dataset(df3_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmazYt9QBYT"
      },
      "source": [
        "### <font size= 12 color=\"lightgreen\" >Explorando los datasets<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "_sb3UjtYPuLn"
      },
      "outputs": [],
      "source": [
        "# Crear funci√≥n para explorar datasets\n",
        "def explorar_dataset(data):\n",
        "    print('Filas: ' + str(data.shape[0]))\n",
        "    print('Columnas: ' + str(data.shape[1]))\n",
        "    print('\\nColumnas: \\n' + str(data.columns.tolist()))\n",
        "    print('\\nTipo de datos: \\n' + str(data.dtypes))\n",
        "    print('\\nValores nulos: \\n' + str(data.isnull().sum()))\n",
        "    print('\\nMuestra aleatoria (5 registros): \\n' + str(data.sample(5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-OpMWf0l8DM"
      },
      "source": [
        "#### **Explorando Data1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "D0SICtaLs770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 731\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto sentimiento\n",
            "666  Envi√© accidentalmente un mensaje de texto dest...   Verguenza\n",
            "207  Flotando durante el d√≠a con un aire de indifer...     Neutral\n",
            "519  En un concierto de Justin Bieber, los contagio...  Entusiasmo\n",
            "665  Bail√© bajo la lluvia para celebrar el final de...     Alegr√≠a\n",
            "263  Con el coraz√≥n entusiasmado, corriendo por cam...       √Ånimo\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfglf1PjDfz"
      },
      "source": [
        "#### **Explorando data2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "id": "AvetNKaKfI3X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 731\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto sentimiento\n",
            "656  Llevar bocadillos a clase como un profesional....    Positivo\n",
            "384  Susurros de inspiraci√≥n provenientes del susur...     Neutral\n",
            "229  La melancol√≠a pinta el mundo con tonos de nost...     Neutral\n",
            "374  Persiguiendo sue√±os como una cometa volando al...    Positivo\n",
            "556  A pesar del meticuloso entrenamiento, el nadad...    Negativo\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "pq-p1Ii7NhwV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 74682\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          41\n",
            "sentimiento     0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                   texto  sentimiento\n",
            "34187     No s√© si deber√≠an sentirse ofendidos por esto.     Negativo\n",
            "36383  Game Pass est√° muerto, la mejor pel√≠cula que M...     Positivo\n",
            "955    √Ç¬øC√É‚ÄúMO HA SIDO TODO EL A√É‚ÄòO? El a√É¬±o pasado t...     Positivo\n",
            "7399   Podr√≠a volver a jugar a los cl√°sicos de WoW. L...     Negativo\n",
            "42416  Las chicas que tocan en el pub y encienden el ...  Irrelevante\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df3_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCION SEGMENTADA DE LIMPIEZA BASICA PRUEBA.\n",
        "texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "# Preservar √±/√ë\n",
        "texto = texto.replace('n\\\\u0303', '@@@N_TILDE@@@')\n",
        "texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "texto = texto.replace('N\\\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "# Eliminar tildes\n",
        "texto = ''.join(char for char in texto if not unicodedata.combining(char))\n",
        "\n",
        "# Restaurar √±/√ë\n",
        "texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "# Normalizar espacios b√°sico\n",
        "texto = ' '.join(texto.split())\n",
        "texto = texto.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "    # Mostrar resultados estad√≠sticos de la limpieza.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62jGtD-PuLo"
      },
      "source": [
        "#### **An√°lisis proceso de limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "Gs5CRWmVPuLo"
      },
      "outputs": [],
      "source": [
        "def analizar_limpieza_sentimientos(df_antes, df_despues, nombre):\n",
        "    \"\"\"\n",
        "    An√°lisis espec√≠fico para tu funci√≥n limpiar_texto_para_sentimientos\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç AN√ÅLISIS ESPEC√çFICO: {nombre}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Cambios en caracteres espec√≠ficos del espa√±ol\n",
        "    cambios_especificos = {\n",
        "        'tildes_eliminadas': 0,\n",
        "        '√±_preservadas': 0,\n",
        "        'urls_eliminadas': 0,\n",
        "        'mayusculas_preservadas': 0\n",
        "    }\n",
        "\n",
        "    # Muestra de 50 textos para an√°lisis detallado\n",
        "    muestra = min(50, len(df_antes))\n",
        "\n",
        "    for i in range(muestra):\n",
        "        if i < len(df_despues):\n",
        "            texto_antes = str(df_antes.iloc[i]['texto'])\n",
        "            texto_despues = str(df_despues.iloc[i]['texto'])\n",
        "\n",
        "            # Contar √± preservadas\n",
        "            if '√±' in texto_antes.lower() and '√±' in texto_despues.lower():\n",
        "                cambios_especificos['√±_preservadas'] += 1\n",
        "\n",
        "            # Contar URLs eliminadas\n",
        "            import re\n",
        "            urls_antes = len(re.findall(r'https?://\\S+', texto_antes))\n",
        "            urls_despues = len(re.findall(r'https?://\\S+', texto_despues))\n",
        "            if urls_antes > urls_despues:\n",
        "                cambios_especificos['urls_eliminadas'] += (urls_antes - urls_despues)\n",
        "\n",
        "            # Verificar may√∫sculas preservadas\n",
        "            mayus_antes = sum(1 for c in texto_antes if c.isupper())\n",
        "            mayus_despues = sum(1 for c in texto_despues if c.isupper())\n",
        "            if mayus_antes > 0 and mayus_despues > 0:\n",
        "                cambios_especificos['mayusculas_preservadas'] += 1\n",
        "\n",
        "    print(\"üìä Cambios espec√≠ficos de tu limpiador:\")\n",
        "    for cambio, cantidad in cambios_especificos.items():\n",
        "        print(f\"   ‚Ä¢ {cambio.replace('_', ' ').title()}: {cantidad} de {muestra} textos\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "id": "OJST9GAJPuLo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÅ Dataset 1\n",
            "   Registros: 731\n",
            "   Muestra (3 textos):\n",
            "                                                 texto  \\\n",
            "568  Al capturar la esencia de un mercado bullicios...   \n",
            "274  Susurros Esperanzaes del viento, que llevan la...   \n",
            "487  En la celebraci√≥n del √©xito, los fuegos artifi...   \n",
            "\n",
            "                                          Texto_Limpio  \n",
            "568  Al capturar la esencia de un mercado bullicios...  \n",
            "274  Susurros Esperanzaes del viento, que llevan la...  \n",
            "487  En la celebracion del exito, los fuegos artifi...  \n",
            "\n",
            "üìÅ Dataset 2\n",
            "   Registros: 2,540\n",
            "   Muestra (3 textos):\n",
            "                                                  texto  \\\n",
            "2080  He concluido la experiencia de 'La sociedad de...   \n",
            "1554  El soltar con gratitud te abre a nuevas posibi...   \n",
            "2126  saber que con quien estuve rom√°nticamente me f...   \n",
            "\n",
            "                                           Texto_Limpio  \n",
            "2080  He concluido la experiencia de 'La sociedad de...  \n",
            "1554  El soltar con gratitud te abre a nuevas posibi...  \n",
            "2126  saber que con quien estuve romanticamente me f...  \n",
            "\n",
            "üìÅ Dataset 3\n",
            "   Registros: 74,682\n",
            "   Muestra (3 textos):\n",
            "                                                   texto  \\\n",
            "10644  Esto va m√°s all√° de la estupidez, las consolas...   \n",
            "9187   Mi momento m√°s vergonzoso en Overwatch pic.twi...   \n",
            "45197  La bater√≠a del iPhone necesita urgentemente qu...   \n",
            "\n",
            "                                            Texto_Limpio  \n",
            "10644  Esto va mas alla de la estupidez, las consolas...  \n",
            "9187   Mi momento mas vergonzoso en Overwatch pic.twi...  \n",
            "45197  La bateria del iPhone necesita urgentemente qu...  \n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 1\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 5 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 50 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 2\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 7 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 43 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 3\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 13 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 49 de 50 textos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Lista de dataframes para procesar\n",
        "dataframes = [\n",
        "    (df1_filtrado, \"Dataset 1\"),\n",
        "    (df2_filtrado, \"Dataset 2\"),\n",
        "    (df3_filtrado, \"Dataset 3\")\n",
        "]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for df, nombre in dataframes:\n",
        "    # Aplicar limpieza\n",
        "    df['Texto_Limpio'] = df['texto'].apply(limpiar_texto_sentimientos)\n",
        "\n",
        "    # Guardar copia limpia\n",
        "    resultados[nombre] = df.copy()\n",
        "\n",
        "    # Mostrar info\n",
        "    print(f\"\\nüìÅ {nombre}\")\n",
        "    print(f\"   Registros: {len(df):,}\")\n",
        "    print(f\"   Muestra (3 textos):\")\n",
        "    print(df[['texto', 'Texto_Limpio']].sample(3))\n",
        "\n",
        "# Asignar a variables originales\n",
        "df1_clean = resultados[\"Dataset 1\"]\n",
        "df2_clean = resultados[\"Dataset 2\"]\n",
        "df3_clean = resultados[\"Dataset 3\"]\n",
        "\n",
        "analizar_limpieza_sentimientos(df1_filtrado, df1_clean, \"Dataset 1\")\n",
        "analizar_limpieza_sentimientos(df2_filtrado, df2_clean, \"Dataset 2\")\n",
        "analizar_limpieza_sentimientos(df3_filtrado, df3_clean, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "id": "uj1j4hVnPuLo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>El arrepentimiento por las oportunidades perdi...</td>\n",
              "      <td>Arrepentimiento</td>\n",
              "      <td>El arrepentimiento por las oportunidades perdi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>Deslumbrado por la elegancia de los deslumbran...</td>\n",
              "      <td>Deslumbrar</td>\n",
              "      <td>Deslumbrado por la elegancia de los deslumbran...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>Al descubrir una joya escondida en el mundo de...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Al descubrir una joya escondida en el mundo de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto      sentimiento  \\\n",
              "174  El arrepentimiento por las oportunidades perdi...  Arrepentimiento   \n",
              "395  Deslumbrado por la elegancia de los deslumbran...       Deslumbrar   \n",
              "535  Al descubrir una joya escondida en el mundo de...         Positivo   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "174  El arrepentimiento por las oportunidades perdi...  \n",
              "395  Deslumbrado por la elegancia de los deslumbran...  \n",
              "535  Al descubrir una joya escondida en el mundo de...  "
            ]
          },
          "execution_count": 230,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "jiA1uCrfPuLo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>Quiero renunciar solo para tener mi liquidaci√≥...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Quiero renunciar solo para tener mi liquidacio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>Deje para √∫ltima hora un regalo que ten√≠a en m...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Deje para ultima hora un regalo que tenia en m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>@2011rafaelhomez URGENTE detenido capit√°n reti...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>@2011rafaelhomez URGENTE detenido capitan reti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1127  Quiero renunciar solo para tener mi liquidaci√≥...    negativo   \n",
              "1254  Deje para √∫ltima hora un regalo que ten√≠a en m...    positivo   \n",
              "946   @2011rafaelhomez URGENTE detenido capit√°n reti...    negativo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "1127  Quiero renunciar solo para tener mi liquidacio...  \n",
              "1254  Deje para ultima hora un regalo que tenia en m...  \n",
              "946   @2011rafaelhomez URGENTE detenido capitan reti...  "
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "uBXLrjxHOWwS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>Por alguna raz√≥n, mi computadora port√°til pued...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Por alguna razon, mi computadora portatil pued...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>buff.ly/33Q7U7s......</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>buff.ly/33Q7U7s......</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26631</th>\n",
              "      <td>Estoy muy cansado.)</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Estoy muy cansado.)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "182    Por alguna raz√≥n, mi computadora port√°til pued...     Neutral   \n",
              "4797                               buff.ly/33Q7U7s......     Neutral   \n",
              "26631                                Estoy muy cansado.)    Positivo   \n",
              "\n",
              "                                            Texto_Limpio  \n",
              "182    Por alguna razon, mi computadora portatil pued...  \n",
              "4797                               buff.ly/33Q7U7s......  \n",
              "26631                                Estoy muy cansado.)  "
            ]
          },
          "execution_count": 232,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Limpieza de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Lista 'sentimientos_unicos' (sin limpiar): 111\n",
            "Muestra (primeros 10): ['Abrumado', 'Aburrimiento', 'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Aislamiento', 'Alegr√≠a', 'Amabilidad', 'Amargura']\n",
            "üìä Lista 'sentimientos_unicos' (limpios): 105\n",
            "Muestra (primeros 10): ['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura']\n"
          ]
        }
      ],
      "source": [
        "def limpiar_sentimiento_simple(sentimiento):\n",
        "    \"\"\"Convierte a min√∫sculas y quita espacios extras.\"\"\"\n",
        "    return \" \".join(str(sentimiento).lower().strip().split())\n",
        "\n",
        "\n",
        "def limpiar_y_unificar_sentimientos(lista_sentimientos, nombre_lista=\"lista\"):\n",
        "    \"\"\"\n",
        "    Recibe una lista (o iterable) de sentimientos y devuelve\n",
        "    una lista ordenada de sentimientos √∫nicos ya limpios.\n",
        "    Adem√°s imprime un peque√±o resumen.\n",
        "    \"\"\"\n",
        "    # Sentimientos originales\n",
        "    lista_sentimientos = list(lista_sentimientos)\n",
        "    \n",
        "    # Limpiar cada elemento\n",
        "    limpios = (limpiar_sentimiento_simple(s) for s in lista_sentimientos)\n",
        "    \n",
        "    # Eliminar duplicados y ordenar\n",
        "    sentimientos_limpios = sorted(set(limpios))\n",
        "\n",
        "    # Prints usando el nombre de la lista\n",
        "    print(f\"üìä Lista '{nombre_lista}' (sin limpiar): {len(lista_sentimientos)}\")\n",
        "    print(f\"Muestra (primeros 10): {lista_sentimientos[:10]}\")\n",
        "    print(f\"üìä Lista '{nombre_lista}' (limpios): {len(sentimientos_limpios)}\")\n",
        "    print(f\"Muestra (primeros 10): {sentimientos_limpios[:10]}\")\n",
        "\n",
        "    return sentimientos_limpios\n",
        "\n",
        "# 1. Obtener sentimientos √∫nicos de ambos datasets\n",
        "sentimientos_unicos = sorted(\n",
        "    list(df1_clean['sentimiento'].unique())\n",
        "    + list(df2_clean['sentimiento'].unique())\n",
        "    + list(df3_clean['sentimiento'].unique())\n",
        ")\n",
        "\n",
        "# 2. Aplicar la funci√≥n gen√©rica\n",
        "sentimientos_unicos_limpios = limpiar_y_unificar_sentimientos(\n",
        "    sentimientos_unicos,\n",
        "    nombre_lista=\"sentimientos_unicos\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ_i8f3tPuLp"
      },
      "source": [
        "#### **Categor√≠as Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos √∫nicos: 105\n",
            "['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura', 'ambivalencia', 'amistad', 'amor', 'angustia', 'anhelo', 'ansiedad', 'anticipaci√≥n', 'apreciaci√≥n', 'aprensivo', 'armon√≠a', 'arrepentimiento', 'asco', 'asombro', 'cautivaci√≥n', 'celebraci√≥n', 'colorido', 'confiado', 'confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'curiosidad', 'decepci√≥n', 'desamor', 'descubrimiento', 'desesperaci√≥n', 'deslumbrar', 'despectivo', 'determinaci√≥n', 'devastado', 'disfrute', 'diversi√≥n', 'dolor', 'elegancia', 'emoci√≥n', 'empoderamiento', 'emp√°tico', 'encantamiento', 'energ√≠a', 'enojo', 'entumecimiento', 'entusiasmo', 'envidia', 'envidioso', 'esperanza', 'euforia', 'excitaci√≥n', 'felicidad', 'frustraci√≥n', 'frustrado', 'grandeza', 'gratitud', 'inspiraci√≥n', 'inspirado', 'intimidaci√≥n', 'irrelevante', 'juguet√≥n', 'logro', 'l√°stima', 'malo', 'maravilla', 'melancol√≠a', 'mel√≥dico', 'miedo', 'motivaci√≥n', 'negativo', 'neutral', 'obst√°culo', 'odiar', 'optimismo', 'orgullo', 'pena', 'positividad', 'positivo', 'p√©rdida', 'reconfortante', 'reflexi√≥n', 'resentimiento', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfacci√≥n', 'serenidad', 'soledad', 'sorpresa', 'sufrimiento', 'temeroso', 'ternura', 'traici√≥n', 'tristeza', 'triunfo', 'verguenza', '√°nimo', '√©xito']\n"
          ]
        }
      ],
      "source": [
        "# 1. Definimos las listas de sentimientos seg√∫n su categor√≠a\n",
        "print(f\"Total de sentimientos √∫nicos: {len(sentimientos_unicos_limpios)}\")\n",
        "print(sentimientos_unicos_limpios)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/marely/OneDrive/Documentos/Oracle_ONE/Hackaton/SentimentAPI-Project/sentiment-api/data-science/sources/diccionarios/sentimientos_mapeo.json\n",
            "‚úÖ JSON cargado: 109 sentimientos\n",
            "üìä Positivos: 63, Negativos: 40, Neutros: 6\n",
            "\n",
            "üéâ Variables creadas: positivos, negativos, neutros\n",
            "positivos = ['aceptaci√≥n', 'admiracion', 'adoraci√≥n', 'agradecido', 'alegria', 'amabilidad', 'amistad', 'amor', 'apreciacion', 'armonia', 'asombro', 'cautivacion', 'celebracion', 'colorido', 'confiado', 'confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'descubrimiento', 'deslumbrar', 'determinacion', 'disfrute', 'diversion', 'elacion', 'elegancia', 'emocion', 'empoderamiento', 'empat√≠co', 'encantamiento', 'energia', 'entusiasmo', 'esperanza', 'euforia', 'excitacion', 'felicidad', 'grandeza', 'gratitud', 'inspiracion', 'inspirado', 'intimidacion', 'jugueton', 'logro', 'maravilla', 'melodico', 'motivacion', 'optimismo', 'orgullo', 'positividad', 'positivo', 'reconfortante', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfaccion', 'serenidad', 'ternura', 'triunfo', '√°nimo', 'exito', 'extasis', 'positiva']\n",
            "negativos= ['abrumado', 'aburrimiento', 'aislamiento', 'amargura', 'angustia', 'anhelo', 'ansiedad', 'aprensivo', 'arrepentimiento', 'asco', 'decepcion', 'desamor', 'desesperacion', 'despectivo', 'devastado', 'dolor', 'enojo', 'entumecimiento', 'envidia', 'envidioso', 'frustracion', 'frustrado', 'lastima', 'malo', 'melancolia', 'miedo', 'negativo', 'obstaculo', 'odiar', 'pena', 'perdida', 'reflexion', 'resentimiento', 'soledad', 'sufrimiento', 'temeroso', 'traicion', 'tristeza', 'verguenza', 'negativa']\n",
            "neutros= ['ambivalencia', 'anticipacion', 'curiosidad', 'irrelevante', 'neutral', 'sorpresa']\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# üéØ CARGAR SENTIMIENTOS \n",
        "# ==========================================================\n",
        "\n",
        "import json\n",
        "\n",
        "# 1. Nombre del archivo (debe estar en la misma carpeta)\n",
        "\n",
        "archivo = 'C:/Users/marely/OneDrive/Documentos/Oracle_ONE/Hackaton/SentimentAPI-Project/sentiment-api/data-science/sources/diccionarios/sentimientos_mapeo.json'\n",
        "print(archivo)\n",
        "\n",
        "\n",
        "# 2. Intentar cargar\n",
        "try:\n",
        "    with open(archivo, 'r', encoding='utf-8') as f:\n",
        "        datos = json.load(f)\n",
        "    \n",
        "    print(f\"‚úÖ JSON cargado: {len(datos)} sentimientos\")\n",
        "    \n",
        "    # 3. Crear listas directamente\n",
        "    positivos = [k for k, v in datos.items() if v == 'positivo']\n",
        "    negativos = [k for k, v in datos.items() if v == 'negativo']\n",
        "    neutros = [k for k, v in datos.items() if v == 'neutral']\n",
        "    \n",
        "    print(f\"üìä Positivos: {len(positivos)}, Negativos: {len(negativos)}, Neutros: {len(neutros)}\")\n",
        "    \n",
        "except:\n",
        "    print(f\"‚ùå No se pudo cargar '{archivo}'\")\n",
        "    print(\"üí° Creando listas b√°sicas...\")\n",
        "    positivos = ['positivo']\n",
        "    negativos = ['negativo']\n",
        "    neutros = ['neutral']\n",
        "\n",
        "# 4. ¬°YA EST√Å LISTO!\n",
        "print(f\"\\nüéâ Variables creadas: positivos, negativos, neutros\")\n",
        "print('positivos =',positivos)\n",
        "print('negativos=',negativos)\n",
        "print('neutros=',neutros)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Limpieza previa a la categorizaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Lista 'sentimientos_positivos' (sin limpiar): 63\n",
            "Muestra (primeros 10): ['aceptaci√≥n', 'admiracion', 'adoraci√≥n', 'agradecido', 'alegria', 'amabilidad', 'amistad', 'amor', 'apreciacion', 'armonia']\n",
            "üìä Lista 'sentimientos_positivos' (limpios): 63\n",
            "Muestra (primeros 10): ['aceptaci√≥n', 'admiracion', 'adoraci√≥n', 'agradecido', 'alegria', 'amabilidad', 'amistad', 'amor', 'apreciacion', 'armonia']\n"
          ]
        }
      ],
      "source": [
        "# Aplicar la funci√≥n gen√©rica\n",
        "positivos_limpios = limpiar_y_unificar_sentimientos(positivos,nombre_lista=\"sentimientos_positivos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Lista 'sentimientos_negativos' (sin limpiar): 40\n",
            "Muestra (primeros 10): ['abrumado', 'aburrimiento', 'aislamiento', 'amargura', 'angustia', 'anhelo', 'ansiedad', 'aprensivo', 'arrepentimiento', 'asco']\n",
            "üìä Lista 'sentimientos_negativos' (limpios): 40\n",
            "Muestra (primeros 10): ['abrumado', 'aburrimiento', 'aislamiento', 'amargura', 'angustia', 'anhelo', 'ansiedad', 'aprensivo', 'arrepentimiento', 'asco']\n"
          ]
        }
      ],
      "source": [
        "# Aplicar la funci√≥n gen√©rica\n",
        "negativos_limpios = limpiar_y_unificar_sentimientos(negativos,nombre_lista=\"sentimientos_negativos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Lista 'sentimientos_neutros' (sin limpiar): 6\n",
            "Muestra (primeros 10): ['ambivalencia', 'anticipacion', 'curiosidad', 'irrelevante', 'neutral', 'sorpresa']\n",
            "üìä Lista 'sentimientos_neutros' (limpios): 6\n",
            "Muestra (primeros 10): ['ambivalencia', 'anticipacion', 'curiosidad', 'irrelevante', 'neutral', 'sorpresa']\n"
          ]
        }
      ],
      "source": [
        "# Aplicar la funci√≥n gen√©rica\n",
        "neutros_limpios = limpiar_y_unificar_sentimientos(neutros,nombre_lista=\"sentimientos_neutros\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "pq_HYQiePuLp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Total clasificado: 109/105\n",
            "   - Positivos: 63 (59.4%)\n",
            "   - Negativos: 40 (37.7%)\n",
            "   - Neutros: 6 (5.7%)\n",
            "Total: 109\n",
            "\n",
            "‚ùå Sentimiento no encontrado en el dataset: decepcion\n",
            "‚ùå Sentimiento no encontrado en el dataset: desesperacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: frustracion\n",
            "‚ùå Sentimiento no encontrado en el dataset: lastima\n",
            "‚ùå Sentimiento no encontrado en el dataset: melancolia\n",
            "‚ùå Sentimiento no encontrado en el dataset: negativa\n",
            "‚ùå Sentimiento no encontrado en el dataset: obstaculo\n",
            "‚ùå Sentimiento no encontrado en el dataset: perdida\n",
            "‚ùå Sentimiento no encontrado en el dataset: reflexion\n",
            "‚ùå Sentimiento no encontrado en el dataset: traicion\n",
            "‚ùå Sentimiento no encontrado en el dataset: admiracion\n",
            "‚ùå Sentimiento no encontrado en el dataset: alegria\n",
            "‚ùå Sentimiento no encontrado en el dataset: apreciacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: armonia\n",
            "‚ùå Sentimiento no encontrado en el dataset: cautivacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: celebracion\n",
            "‚ùå Sentimiento no encontrado en el dataset: determinacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: diversion\n",
            "‚ùå Sentimiento no encontrado en el dataset: elacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: emocion\n",
            "‚ùå Sentimiento no encontrado en el dataset: empat√≠co\n",
            "‚ùå Sentimiento no encontrado en el dataset: energia\n",
            "‚ùå Sentimiento no encontrado en el dataset: excitacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: exito\n",
            "‚ùå Sentimiento no encontrado en el dataset: extasis\n",
            "‚ùå Sentimiento no encontrado en el dataset: inspiracion\n",
            "‚ùå Sentimiento no encontrado en el dataset: intimidacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: jugueton\n",
            "‚ùå Sentimiento no encontrado en el dataset: melodico\n",
            "‚ùå Sentimiento no encontrado en el dataset: motivacion\n",
            "‚ùå Sentimiento no encontrado en el dataset: positiva\n",
            "‚ùå Sentimiento no encontrado en el dataset: satisfaccion\n",
            "‚ùå Sentimiento no encontrado en el dataset: anticipacion\n",
            "‚ùå Sentimiento no clasificado: admiraci√≥n\n",
            "‚ùå Sentimiento no clasificado: alegr√≠a\n",
            "‚ùå Sentimiento no clasificado: anticipaci√≥n\n",
            "‚ùå Sentimiento no clasificado: apreciaci√≥n\n",
            "‚ùå Sentimiento no clasificado: armon√≠a\n",
            "‚ùå Sentimiento no clasificado: cautivaci√≥n\n",
            "‚ùå Sentimiento no clasificado: celebraci√≥n\n",
            "‚ùå Sentimiento no clasificado: decepci√≥n\n",
            "‚ùå Sentimiento no clasificado: desesperaci√≥n\n",
            "‚ùå Sentimiento no clasificado: determinaci√≥n\n",
            "‚ùå Sentimiento no clasificado: diversi√≥n\n",
            "‚ùå Sentimiento no clasificado: emoci√≥n\n",
            "‚ùå Sentimiento no clasificado: emp√°tico\n",
            "‚ùå Sentimiento no clasificado: energ√≠a\n",
            "‚ùå Sentimiento no clasificado: excitaci√≥n\n",
            "‚ùå Sentimiento no clasificado: frustraci√≥n\n",
            "‚ùå Sentimiento no clasificado: inspiraci√≥n\n",
            "‚ùå Sentimiento no clasificado: intimidaci√≥n\n",
            "‚ùå Sentimiento no clasificado: juguet√≥n\n",
            "‚ùå Sentimiento no clasificado: l√°stima\n",
            "‚ùå Sentimiento no clasificado: melancol√≠a\n",
            "‚ùå Sentimiento no clasificado: mel√≥dico\n",
            "‚ùå Sentimiento no clasificado: motivaci√≥n\n",
            "‚ùå Sentimiento no clasificado: obst√°culo\n",
            "‚ùå Sentimiento no clasificado: p√©rdida\n",
            "‚ùå Sentimiento no clasificado: reflexi√≥n\n",
            "‚ùå Sentimiento no clasificado: satisfacci√≥n\n",
            "‚ùå Sentimiento no clasificado: traici√≥n\n",
            "‚ùå Sentimiento no clasificado: √©xito\n"
          ]
        }
      ],
      "source": [
        "\n",
        "categorias = [positivos_limpios, negativos_limpios, neutros_limpios]\n",
        "\n",
        "# Verificaci√≥n del total\n",
        "total_clasificados = len(positivos_limpios) + len(negativos_limpios) + len(neutros_limpios)\n",
        "print(f'\\n‚úÖ Total clasificado: {total_clasificados}/{len(sentimientos_unicos_limpios)}')\n",
        "print(f'   - Positivos: {len(positivos_limpios)} ({len(positivos_limpios)/106*100:.1f}%)')\n",
        "print(f'   - Negativos: {len(negativos_limpios)} ({len(negativos_limpios)/106*100:.1f}%)')\n",
        "print(f'   - Neutros: {len(neutros_limpios)} ({len(neutros_limpios)/106*100:.1f}%)')\n",
        "print(f'Total: {len(positivos_limpios) + len(negativos_limpios) + len(neutros_limpios)}')\n",
        "print()\n",
        "\n",
        "# Verificar si existen elementos en las listas que no se encuentran en la lista sentimientos_unicos\n",
        "for sentimiento in negativos_limpios + positivos_limpios + neutros_limpios:\n",
        "    if sentimiento not in sentimientos_unicos_limpios:\n",
        "        print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "\n",
        "\n",
        "for sentimiento in sentimientos_unicos_limpios:\n",
        "    if sentimiento not in positivos_limpios + negativos_limpios + neutros_limpios:\n",
        "        print(f\"‚ùå Sentimiento no clasificado: {sentimiento}\")\n",
        "# else:\n",
        "#     print(\"‚úÖ Todos los sentimientos del dataset est√°n clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12vkocMMPuLp"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "hAy-90rDPuLp"
      },
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias):\n",
        "    \"\"\"\n",
        "    Categoriza sentimientos solo si est√°n en las listas definidas.\n",
        "    Devuelve None para sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    sent = str(sentimiento).strip().lower()\n",
        "\n",
        "    if sent in positivos:\n",
        "        return 'positivo'\n",
        "    elif sent in negativos:\n",
        "        return 'negativo'\n",
        "    elif sent in neutros:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        # Devolvemos None para posterior filtrado\n",
        "        return None\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "XgFiRtKtPuLp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>Ojos envidiosos fijos en el premio dorado, una...</td>\n",
              "      <td>Envidioso</td>\n",
              "      <td>Ojos envidiosos fijos en el premio dorado, una...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Acabo de terminar una rutina de ejercicios des...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Acabo de terminar una rutina de ejercicios des...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Llega el aburrimiento, el d√≠a se siente infini...</td>\n",
              "      <td>Aburrimiento</td>\n",
              "      <td>Llega el aburrimiento, el dia se siente infini...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto   sentimiento  \\\n",
              "306  Ojos envidiosos fijos en el premio dorado, una...     Envidioso   \n",
              "23   Acabo de terminar una rutina de ejercicios des...      Positivo   \n",
              "169  Llega el aburrimiento, el d√≠a se siente infini...  Aburrimiento   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "306  Ojos envidiosos fijos en el premio dorado, una...  \n",
              "23   Acabo de terminar una rutina de ejercicios des...  \n",
              "169  Llega el aburrimiento, el dia se siente infini...  "
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "rKZfkztUPuLp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2318</th>\n",
              "      <td>Bueno, en unos a√±itos como que se les va a cum...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>Bueno, en unos a√±itos como que se les va a cum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1774</th>\n",
              "      <td>el ojo blindado que me has regalado me mira mal</td>\n",
              "      <td>positivo</td>\n",
              "      <td>el ojo blindado que me has regalado me mira mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>937</th>\n",
              "      <td>Es distinto estar solo a estar en solitario ??</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Es distinto estar solo a estar en solitario ??</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "2318  Bueno, en unos a√±itos como que se les va a cum...    positivo   \n",
              "1774    el ojo blindado que me has regalado me mira mal    positivo   \n",
              "937      Es distinto estar solo a estar en solitario ??    negativo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "2318  Bueno, en unos a√±itos como que se les va a cum...  \n",
              "1774    el ojo blindado que me has regalado me mira mal  \n",
              "937      Es distinto estar solo a estar en solitario ??  "
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26251</th>\n",
              "      <td>Ropa de la Hermandad</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Ropa de la Hermandad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21901</th>\n",
              "      <td>#VALUE!</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>#VALUE!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42437</th>\n",
              "      <td>Informe de pubg fallido en.be/Qz00Pth41sw v√≠a 2</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Informe de pubg fallido en.be/Qz00Pth41sw via 2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "26251                             Ropa de la Hermandad    Positivo   \n",
              "21901                                          #VALUE!    Positivo   \n",
              "42437  Informe de pubg fallido en.be/Qz00Pth41sw v√≠a 2    Negativo   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "26251                             Ropa de la Hermandad  \n",
              "21901                                          #VALUE!  \n",
              "42437  Informe de pubg fallido en.be/Qz00Pth41sw via 2  "
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT9snuZtPuLq"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "DRuHBnaFPuLq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ df1: 563 registros categorizados\n",
            "‚úÖ df2: 2540 registros categorizados\n",
            "‚úÖ df3: 74682 registros categorizados\n"
          ]
        }
      ],
      "source": [
        "df1_clean['Sentimiento_Final'] = df1_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df1_categorized = df1_clean[df1_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df2_clean['Sentimiento_Final'] = df2_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df2_categorized = df2_clean[df2_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df3_clean['Sentimiento_Final'] = df3_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df3_categorized = df3_clean[df3_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "print(f\"‚úÖ df1: {len(df1_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df2: {len(df2_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df3: {len(df3_categorized)} registros categorizados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "2Q8euH7QPuLq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>Al navegar por el laberinto de los pensamiento...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Al navegar por el laberinto de los pensamiento...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>Intrigado por la sinfon√≠a de colores en una ex...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Intrigado por la sinfonia de colores en una ex...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>Recibi√≥ una calificaci√≥n no tan buena en un pr...</td>\n",
              "      <td>Malo</td>\n",
              "      <td>Recibio una calificacion no tan buena en un pr...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "227  Al navegar por el laberinto de los pensamiento...     Neutral   \n",
              "371  Intrigado por la sinfon√≠a de colores en una ex...     Neutral   \n",
              "687  Recibi√≥ una calificaci√≥n no tan buena en un pr...        Malo   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "227  Al navegar por el laberinto de los pensamiento...           neutral  \n",
              "371  Intrigado por la sinfonia de colores en una ex...           neutral  \n",
              "687  Recibio una calificacion no tan buena en un pr...          negativo  "
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "onq_zeNRPuLt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2291</th>\n",
              "      <td>???????? \"Al mundo entero quiero dar un mensaj...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>???????? \"Al mundo entero quiero dar un mensaj...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>Tal vez te vea ma√±ana, y eso me asusta demasia...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Tal vez te vea ma√±ana, y eso me asusta demasia...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Vamos a jugar a 20 corazones...bueno 20 son mu...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Vamos a jugar a 20 corazones...bueno 20 son mu...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "2291  ???????? \"Al mundo entero quiero dar un mensaj...    positivo   \n",
              "480   Tal vez te vea ma√±ana, y eso me asusta demasia...    negativo   \n",
              "361   Vamos a jugar a 20 corazones...bueno 20 son mu...    negativo   \n",
              "\n",
              "                                           Texto_Limpio Sentimiento_Final  \n",
              "2291  ???????? \"Al mundo entero quiero dar un mensaj...          positivo  \n",
              "480   Tal vez te vea ma√±ana, y eso me asusta demasia...          negativo  \n",
              "361   Vamos a jugar a 20 corazones...bueno 20 son mu...          negativo  "
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "7nhxLa6SPxL4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6734</th>\n",
              "      <td>¬°Ay, todas esas polillas locas! Se agotaron en...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>¬°Ay, todas esas polillas locas! Se agotaron en...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58519</th>\n",
              "      <td>¬°La diversi√≥n contin√∫a! ¬°Gracias por animarnos...</td>\n",
              "      <td>Irrelevante</td>\n",
              "      <td>¬°La diversion continua! ¬°Gracias por animarnos...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54008</th>\n",
              "      <td>El nuevo parche no puede durar m√°s de 3 rondas...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>El nuevo parche no puede durar mas de 3 rondas...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto  sentimiento  \\\n",
              "6734   ¬°Ay, todas esas polillas locas! Se agotaron en...     Negativo   \n",
              "58519  ¬°La diversi√≥n contin√∫a! ¬°Gracias por animarnos...  Irrelevante   \n",
              "54008  El nuevo parche no puede durar m√°s de 3 rondas...     Negativo   \n",
              "\n",
              "                                            Texto_Limpio Sentimiento_Final  \n",
              "6734   ¬°Ay, todas esas polillas locas! Se agotaron en...          negativo  \n",
              "58519  ¬°La diversion continua! ¬°Gracias por animarnos...           neutral  \n",
              "54008  El nuevo parche no puede durar mas de 3 rondas...          negativo  "
            ]
          },
          "execution_count": 247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfhg_fBXPuLt"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar dataset unificado</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEB_qDA3PuLt"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "W19ms-90PuLu"
      },
      "outputs": [],
      "source": [
        "def limpiar_dataset_unificado(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('Texto_Limpio')['Sentimiento_Final'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['Texto_Limpio'] == texto]['Sentimiento_Final'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['Texto_Limpio'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['Texto_Limpio'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['Texto_Limpio'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['Texto_Limpio', 'Sentimiento_Final']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Texto_Limpio'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Sentimiento_Final'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['Texto_Limpio'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['Texto_Limpio'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['Sentimiento_Final'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "n8a2z5ZNPuLu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53189</th>\n",
              "      <td>RED DEAD REDEMPTION 7..</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>RED DEAD REDEMPTION 7..</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5817</th>\n",
              "      <td>@amazon ¬°Acabo de presionar sin querer la opci...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>@amazon ¬°Acabo de presionar sin querer la opci...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25817</th>\n",
              "      <td>√Ç¬°JODER C√É‚ÄúMO!</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>A¬°JODER CA‚ÄúMO!</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "53189                            RED DEAD REDEMPTION 7..     Neutral   \n",
              "5817   @amazon ¬°Acabo de presionar sin querer la opci...     Neutral   \n",
              "25817                                     √Ç¬°JODER C√É‚ÄúMO!    Positivo   \n",
              "\n",
              "                                            Texto_Limpio Sentimiento_Final  \n",
              "53189                            RED DEAD REDEMPTION 7..           neutral  \n",
              "5817   @amazon ¬°Acabo de presionar sin querer la opci...           neutral  \n",
              "25817                                     A¬°JODER CA‚ÄúMO!          positivo  "
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_categorized.sample(3)\n",
        "df2_categorized.sample(3)\n",
        "df3_categorized.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4d4Mra2PuLu"
      },
      "source": [
        "#### **Unificar datataset y limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "CJeTAgAkPuLu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó UNIFICANDO DATASETS CATEGORIZADOS\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (77785, 2)\n",
            "   ‚Ä¢ Registros: 77,785\n",
            "   ‚Ä¢ Textos √∫nicos: 69,306\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 77,785\n",
            "Textos √∫nicos iniciales: 69,306\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚ö†Ô∏è  Encontradas: 224 contradicciones\n",
            "   ‚Ä¢ Ejemplos (primeros 2):\n",
            "     - ''\n",
            "       ‚Üí Sentimientos: neutral, positivo, negativo\n",
            "     - '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...'\n",
            "       ‚Üí Sentimientos: negativo, neutral\n",
            "   üóëÔ∏è  Eliminados: 3,141 registros por contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚ö†Ô∏è  Encontrados: 3,987 textos duplicados\n",
            "   ‚Ä¢ Registros a eliminar: 5,562\n",
            "   üóëÔ∏è  Eliminados: 5,562 registros duplicados\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 69,082\n",
            "   ‚Ä¢ Textos √∫nicos finales: 69,082\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 77,785\n",
            "Registros finales: 69,082\n",
            "Total eliminados: 8,703 (11.2%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ neutral: 28,715 (41.6%)\n",
            "   ‚Ä¢ negativo: 21,287 (30.8%)\n",
            "   ‚Ä¢ positivo: 19,080 (27.6%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó UNIFICANDO DATASETS CATEGORIZADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Unificar los datasets categorizados\n",
        "df_unificado = pd.concat([df1_categorized[['Texto_Limpio', 'Sentimiento_Final']], df2_categorized[['Texto_Limpio', 'Sentimiento_Final']], df3_categorized[['Texto_Limpio','Sentimiento_Final']]], ignore_index=True)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_unificado.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_unificado):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_unificado['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "df_final = limpiar_dataset_unificado(df_unificado, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "PiaR4I5zPuLu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62398</th>\n",
              "      <td>Los fanA¬°ticos de una pelA cula conspirativa p...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7068</th>\n",
              "      <td>Si van al centro del satelite por cualquier mo...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18964</th>\n",
              "      <td>Tome el servidor del mar</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Texto_Limpio Sentimiento_Final\n",
              "62398  Los fanA¬°ticos de una pelA cula conspirativa p...           neutral\n",
              "7068   Si van al centro del satelite por cualquier mo...           neutral\n",
              "18964                           Tome el servidor del mar          positivo"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unificado.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOG13F7lPuLv"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5DwJkdPuLv"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "id": "2VLH0dQePuLv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "============================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------\n",
            "Positivo     |    19080 |     27.62% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |    21287 |     30.81% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |    28715 |     41.57% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------\n",
            "TOTAL        |    69082 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['Sentimiento_Final'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 58)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6Bpu2ZPuLv"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "INsd0XvNPuLv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hovertemplate": "label=%{label}<br>value=%{value}<extra></extra>",
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "neutral",
                    "negativo",
                    "positivo"
                  ],
                  "legendgroup": "",
                  "name": "",
                  "showlegend": true,
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "K3AnU4hK",
                    "dtype": "i2"
                  }
                }
              ],
              "layout": {
                "height": 500,
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 69082 registros</span>",
                  "x": 0.5
                },
                "width": 500
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Grafica de pastel con Plotly\n",
        "\n",
        "valores = df_final['Sentimiento_Final'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "fig1 = px.pie(\n",
        "    names = valores.sentimientos,\n",
        "    values = valores.Cantidad,\n",
        ")\n",
        "\n",
        "fig1.update_traces(textposition='inside', textinfo='label+percent',  insidetextfont=dict(color = 'white', size=14)\n",
        ")\n",
        "\n",
        "fig1.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMplULMaPuLv"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwSlmvXSPuLv"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "esUzQFjnPuLv"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9kZOcK7PuLv"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "WSBwUlWgPuLw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset.csv\n",
            "üìä Registros: 69,082\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"2.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\",\n",
        "        \"twitter_trainnig.csv\"    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxLqWrOWPuLw"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "YB9ZY3b3PuLw"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "PwJXRfMxPuLw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 69,082 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 69,082 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "eBDe0CPbl8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 69,082 registros (encoding: utf-8-sig)\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                       texto sentimiento\n",
            "¬°Disfrutando de un hermoso dia en el parque!    positivo\n",
            "        Esta ma√±ana el trafico era terrible.    negativo\n"
          ]
        }
      ],
      "source": [
        "# Verificar que el archivo se pueda leer\n",
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=enc, nrows=5)  # Probar con 5 filas\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None\n",
        "\n",
        "# Uso simple\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL-DDylhPuLw"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "MQcqcJa0PuLx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\n",
            "======================================================================\n",
            "‚úÖ Dataset final: 69,082 registros\n",
            "‚úÖ Distribuci√≥n balanceada: 27.62% üëç | 30.81% üëé | 41.57% üòê\n",
            "‚úÖ Calidad del dataset:\n",
            "   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\n",
            "   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\n",
            "   ‚Ä¢ 0 valores nulos\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar):,} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: {porcentajes['positivo']}% üëç | {porcentajes['negativo']}% üëé | {porcentajes['neutral']}% üòê\")\n",
        "print(f\"‚úÖ Calidad del dataset:\")\n",
        "print(f\"   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\")\n",
        "print(f\"   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\")\n",
        "print(f\"   ‚Ä¢ 0 valores nulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "- https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "- https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n",
        "\n",
        "- https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "3K2ezd_nPuLy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 69082 entries, 0 to 77784\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        69082 non-null  object\n",
            " 1   sentimiento  69082 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzFpQ4smRcug"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Machine Learning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "Z6MSbMjXPuLy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14615</th>\n",
              "      <td>Eso fue absolutamente genial por parte de Xbox...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento\n",
              "14615  Eso fue absolutamente genial por parte de Xbox...    positivo"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "Cdy77Lknl9pd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\marely\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Limpieza de texto mejorada aplicada\n",
            "\n",
            "Muestra de textos limpios:\n",
            "                                                   texto sentimiento\n",
            "17781  gameflip re alguien abusa codigo descuento mer...     neutral\n",
            "22496  primera vez vida, paparazzi atacaron despues c...     neutral\n",
            "32894  clasificacian tra brandon rob. juegos accian a...     neutral\n",
            "33971                          recien enfrentado ceguera    negativo\n",
            "8536   informacian, algoritmos no estan dando cradito...    negativo\n"
          ]
        }
      ],
      "source": [
        "# Descargar stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def limpiar_texto_mejorado(texto):\n",
        "    \"\"\"\n",
        "    Limpieza de texto m√°s conservadora que preserva palabras  de negaci√≥n\n",
        "    y modificadores de intensidad.\n",
        "    \"\"\"\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Eliminar caracteres especiales PERO preservar puntuaci√≥n emocional\n",
        "    texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±0-9\\s!?.,\\-]', '', texto)\n",
        "\n",
        "    # Stopwords espa√±olas\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "    # PALABRAS CR√çTICAS A MANTENER (expandida vs. original)\n",
        "    palabras_criticas = {\n",
        "        # Negaciones\n",
        "        'no', 'ni', 'sin', 'nunca', 'jamas', 'tampoco', 'nada', 'nadie',\n",
        "        # Intensificadores\n",
        "        'muy', 'mucho', 'poco', 'mas', 'menos', 'demasiado', 'bastante',\n",
        "        # Modales\n",
        "        'pero', 'aunque', 'sino', 'si',\n",
        "        # Adjetivos de sentimiento\n",
        "        'malo', 'mala', 'mal', 'bien', 'bueno', 'buena', 'mejor', 'peor',\n",
        "        'horrible', 'terrible', 'excelente', 'pesimo', 'p√©simo',\n",
        "        # Verbos de sentimiento\n",
        "        'odio', 'amo', 'encanta', 'disgusta', 'molesta',\n",
        "        # Otros\n",
        "        'contra', 'hacia'\n",
        "    }\n",
        "\n",
        "    # Remover stopwords EXCEPTO las cr√≠ticas\n",
        "    stop_words = stop_words - palabras_criticas\n",
        "\n",
        "    palabras = texto.split()\n",
        "    palabras_filtradas = [palabra for palabra in palabras if palabra not in stop_words]\n",
        "\n",
        "    return ' '.join(palabras_filtradas)\n",
        "\n",
        "# Aplicar limpieza mejorada\n",
        "df['texto'] = df['texto'].apply(limpiar_texto_mejorado)\n",
        "\n",
        "print(\"‚úÖ Limpieza de texto mejorada aplicada\")\n",
        "print(f\"\\nMuestra de textos limpios:\")\n",
        "print(df[['texto', 'sentimiento']].sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "3SJfTa-EPuLy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23672</th>\n",
              "      <td>arrastrandose...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61868</th>\n",
              "      <td>facebook lleva segundo dia impidiendome compar...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24400</th>\n",
              "      <td>personalmente creo comunidad csgo gran problem...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29343</th>\n",
              "      <td>no puedo esperar credo asesino valhalla.</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11290</th>\n",
              "      <td>playoverwatch desconecto cada juego juegos alg...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento\n",
              "23672                                   arrastrandose...     neutral\n",
              "61868  facebook lleva segundo dia impidiendome compar...    negativo\n",
              "24400  personalmente creo comunidad csgo gran problem...    negativo\n",
              "29343           no puedo esperar credo asesino valhalla.    positivo\n",
              "11290  playoverwatch desconecto cada juego juegos alg...    negativo"
            ]
          },
          "execution_count": 263,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LH5NgVcQKEx"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGMacHrPuLy"
      },
      "source": [
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "id": "NpuPPs85PuLy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Librer√≠a 'imblearn' instalada exitosamente.\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('pip install imblearn') # type: ignore\n",
        "print(\"Librer√≠a 'imblearn' instalada exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx2DlzvEPuLz"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "uFz0LAY_PuLz"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "djlXVfUUl9pe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n de clases:\n",
            "sentimiento\n",
            "neutral     28715\n",
            "negativo    21287\n",
            "positivo    19080\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Train: 55265 | Test: 13817\n",
            "\n",
            "‚úÖ Vectorizaci√≥n completada\n",
            "   Dimensiones: (55265, 10000)\n",
            "   Vocabulario: 10000 t√©rminos\n"
          ]
        }
      ],
      "source": [
        "# Separar X e y\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "print(\"Distribuci√≥n de clases:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Divisi√≥n train/test\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# üÜï TF-IDF MEJORADO\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,      # ‚¨Ü Aumentado de 5000\n",
        "    ngram_range=(1, 3),      # ‚¨Ü Trigramas (antes solo bigramas)\n",
        "    min_df=2,                # üÜï Nuevo\n",
        "    max_df=0.95,             # üÜï Nuevo\n",
        "    sublinear_tf=True        # üÜï Nuevo\n",
        ")\n",
        "\n",
        "X_train_tfidf_unbalanced = vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\n‚úÖ Vectorizaci√≥n completada\")\n",
        "print(f\"   Dimensiones: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"   Vocabulario: {len(vectorizer.get_feature_names_out())} t√©rminos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIbtwkkQhx0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbfr-opZPuLz"
      },
      "source": [
        "\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "FoyoVnuNPuLz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tama√±o del conjunto de entrenamiento (desbalanceado): 55265 muestras\n",
            "Tama√±o del conjunto de prueba: 13817 muestras\n",
            "Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\n",
            "sentimiento\n",
            "neutral     22972\n",
            "negativo    17029\n",
            "positivo    15264\n",
            "Name: count, dtype: int64\n",
            "Distribuci√≥n de clases en el conjunto de prueba:\n",
            "sentimiento\n",
            "neutral     5743\n",
            "negativo    4258\n",
            "positivo    3816\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\n",
            "Forma de X_train_tfidf_unbalanced: (55265, 5000)\n",
            "Forma de X_test_tfidf: (13817, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Dividir el dataset en conjuntos de entrenamiento y prueba ANTES de aplicar SMOTE\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTama√±o del conjunto de entrenamiento (desbalanceado): {len(X_train_unbalanced)} muestras\")\n",
        "print(f\"Tama√±o del conjunto de prueba: {len(X_test)} muestras\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\\n{y_train_unbalanced.value_counts()}\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de prueba:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Inicializar TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(1,2)) # Limitando las caracter√≠sticas para eficiencia\n",
        "\n",
        "# Ajustar y transformar X_train_unbalanced, y transformar X_test\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nVectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\")\n",
        "print(f\"Forma de X_train_tfidf_unbalanced: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"Forma de X_test_tfidf: {X_test_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpTP-d7RHYa"
      },
      "source": [
        "### <font size=12 color=lightgreen> Balanceo del Conjunto de Entrenamiento con SMOTE</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_FmuXRPuLz"
      },
      "source": [
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "id": "DHm0iiw1PuLz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SMOTE aplicado\n",
            "\n",
            "Distribuci√≥n despu√©s de SMOTE:\n",
            "sentimiento\n",
            "neutral     22972\n",
            "negativo    22972\n",
            "positivo    22972\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Nuevas dimensiones: (68916, 5000)\n"
          ]
        }
      ],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"‚úÖ SMOTE aplicado\")\n",
        "print(f\"\\nDistribuci√≥n despu√©s de SMOTE:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(f\"\\nNuevas dimensiones: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5mkvXaQlFi"
      },
      "source": [
        "### <font size=12 color=lightgreen> Entrenamiento del Modelo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_cggSuxPuLz"
      },
      "source": [
        "\n",
        "# Entrenamiento de M√∫ltiples Modelos\n",
        "\n",
        "Entrenaremos 3 modelos y compararemos:\n",
        "1. **Logistic Regression** (baseline mejorado)\n",
        "2. **SVM** (Support Vector Machine)\n",
        "3. **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4cR6qbPuLz",
        "outputId": "03a3f76d-7c06-4d83-b8af-149723dc4ef1"
      },
      "outputs": [],
      "source": [
        "# # 1. Logistic Regression (mejorado)\n",
        "# print(\"[1/3] Entrenando Logistic Regression...\")\n",
        "# model_lr = LogisticRegression(\n",
        "#     max_iter=2000,\n",
        "#     random_state=42,\n",
        "#     C=1.0,\n",
        "#     solver='lbfgs',\n",
        "#     multi_class='multinomial'\n",
        "# )\n",
        "# model_lr.fit(X_train_tfidf, y_train)\n",
        "# print(\"‚úÖ Logistic Regression entrenado\")\n",
        "\n",
        "# # 2. SVM\n",
        "# print(\"\\n[2/3] Entrenando SVM...\")\n",
        "# model_svm = SVC(\n",
        "#     kernel='linear',\n",
        "#     C=1.0,\n",
        "#     probability=True,\n",
        "#     random_state=42,\n",
        "#     class_weight='balanced'\n",
        "# )\n",
        "# model_svm.fit(X_train_tfidf, y_train)\n",
        "# print(\"‚úÖ SVM entrenado\")\n",
        "\n",
        "# # 3. Random Forest\n",
        "# print(\"\\n[3/3] Entrenando Random Forest...\")\n",
        "# model_rf = RandomForestClassifier(\n",
        "#     n_estimators=200,\n",
        "#     max_depth=None,\n",
        "#     min_samples_split=5,\n",
        "#     min_samples_leaf=2,\n",
        "#     random_state=42,\n",
        "#     n_jobs=-1,\n",
        "#     class_weight='balanced'\n",
        "# )\n",
        "# model_rf.fit(X_train_tfidf, y_train)\n",
        "# print(\"‚úÖ Random Forest entrenado\")\n",
        "\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"‚úÖ TODOS LOS MODELOS ENTRENADOS\")\n",
        "# print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq-wLkyQmaI"
      },
      "source": [
        "### <font size=12 color=lightgreen>Evaluaci√≥n de Modelos:</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNhozE5IPuLz"
      },
      "source": [
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "NYZ2qppwlC0z"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model_lr' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[270], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluar todos los modelos\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m acc_lr \u001b[38;5;241m=\u001b[39m evaluar_modelo(\u001b[43mmodel_lr\u001b[49m, X_test_tfidf, y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression (Mejorado)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m acc_svm \u001b[38;5;241m=\u001b[39m evaluar_modelo(model_svm, X_test_tfidf, y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m acc_rf \u001b[38;5;241m=\u001b[39m evaluar_modelo(model_rf, X_test_tfidf, y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'model_lr' is not defined"
          ]
        }
      ],
      "source": [
        "def evaluar_modelo(model, X_test, y_test, nombre):\n",
        "    \"\"\"Evaluaci√≥n detallada de un modelo\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUACI√ìN: {nombre}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nüìä Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nüìã Reporte de Clasificaci√≥n:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    print(f\"\\nüî¢ Matriz de Confusi√≥n:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    # Probabilidad promedio\n",
        "    predicciones_correctas = y_pred == y_test\n",
        "    probabilidades_correctas = []\n",
        "\n",
        "    for i, correcto in enumerate(predicciones_correctas):\n",
        "        if correcto:\n",
        "            clase_predicha = y_pred[i]\n",
        "            clase_idx = list(model.classes_).index(clase_predicha)\n",
        "            probabilidades_correctas.append(y_pred_proba[i][clase_idx])\n",
        "\n",
        "    if probabilidades_correctas:\n",
        "        prob_promedio = np.mean(probabilidades_correctas)\n",
        "        print(f\"\\nüíØ Probabilidad promedio (correctas): {prob_promedio:.4f} ({prob_promedio*100:.2f}%)\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "acc_lr = evaluar_modelo(model_lr, X_test_tfidf, y_test, \"Logistic Regression (Mejorado)\")\n",
        "acc_svm = evaluar_modelo(model_svm, X_test_tfidf, y_test, \"SVM\")\n",
        "acc_rf = evaluar_modelo(model_rf, X_test_tfidf, y_test, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye01V19FQn7Z"
      },
      "source": [
        "### <font size=12 color=lightgreen> Serializaci√≥n del Modelo y Vectorizadors</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r68b_Sx6PuL0"
      },
      "source": [
        "\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meOQ2yohPuL0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m mejor_modelo \u001b[38;5;241m=\u001b[39m model_svm\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmejor_modelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Based on evaluation, SVM was the best model, so we'll use it for serialization.\n",
        "mejor_modelo = model_svm\n",
        "\n",
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(mejor_modelo, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx1ScQ4um7vg"
      },
      "outputs": [],
      "source": [
        "# Tabla comparativa\n",
        "comparacion = pd.DataFrame({\n",
        "    'Modelo': ['Logistic Regression', 'SVM', 'Random Forest'],\n",
        "    'Accuracy': [acc_lr, acc_svm, acc_rf]\n",
        "})\n",
        "\n",
        "comparacion['Accuracy %'] = comparacion['Accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "comparacion['Mejora vs. Original'] = comparacion['Accuracy'].apply(lambda x: f\"+{(x - 0.79)*100:.2f}%\")\n",
        "comparacion = comparacion.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä COMPARACI√ìN DE MODELOS\")\n",
        "print(\"=\"*70)\n",
        "print(comparacion.to_string(index=False))\n",
        "print(\"\\nüî∏ Modelo original (baseline): 79.00%\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "mejor_accuracy = comparacion['Accuracy'].max()\n",
        "if mejor_accuracy >= 0.83:\n",
        "    print(\"\\n‚úÖ META DE FASE 1 ALCANZADA (83-85%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Casi alcanzado (falta {(0.83 - mejor_accuracy)*100:.2f}%)\")\n",
        "\n",
        "comparacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKTLn4ylPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Pruebas con Casos Espec√≠ficos</font>\n",
        "\n",
        "Validar que ahora clasifica correctamente los casos problem√°ticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q-eYggXPuL0"
      },
      "outputs": [],
      "source": [
        "# Seleccionar el mejor modelo\n",
        "modelos_dict = {\n",
        "    'Logistic Regression': model_lr,\n",
        "    'SVM': model_svm,\n",
        "    'Random Forest': model_rf\n",
        "}\n",
        "\n",
        "nombre_mejor = comparacion.iloc[0]['Modelo']\n",
        "mejor_modelo = modelos_dict[nombre_mejor]\n",
        "\n",
        "print(f\"üèÜ Mejor modelo: {nombre_mejor}\")\n",
        "print(f\"üìä Accuracy: {comparacion.iloc[0]['Accuracy %']}\")\n",
        "\n",
        "# Casos de prueba\n",
        "casos_prueba = [\n",
        "    (\"mala atenci√≥n\", \"negativo\"),\n",
        "    (\"mal comportamiento de los empleado\", \"negativo\"),\n",
        "    (\"la empresa esta perdida en lo que hace\", \"negativo\"),\n",
        "    (\"p√©simo servicio\", \"negativo\"),\n",
        "    (\"nunca vuelvo\", \"negativo\"),\n",
        "    (\"excelente servicio\", \"positivo\"),\n",
        "    (\"me encant√≥\", \"positivo\"),\n",
        "    (\"muy buena atenci√≥n\", \"positivo\"),\n",
        "    (\"es normal, nada especial\", \"neutral\"),\n",
        "    (\"est√° bien\", \"neutral\"),\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PRUEBAS CON CASOS ESPEC√çFICOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "aciertos = 0\n",
        "\n",
        "for texto, esperado in casos_prueba:\n",
        "    # Preprocesar\n",
        "    texto_limpio = limpiar_texto_mejorado(texto)\n",
        "\n",
        "    # Vectorizar y predecir\n",
        "    texto_vectorizado = tfidf_vectorizer.transform([texto_limpio])\n",
        "    prediccion = mejor_modelo.predict(texto_vectorizado)[0]\n",
        "    probabilidades = mejor_modelo.predict_proba(texto_vectorizado)[0]\n",
        "\n",
        "    clase_idx = list(mejor_modelo.classes_).index(prediccion)\n",
        "    prob_prediccion = probabilidades[clase_idx]\n",
        "\n",
        "    es_correcto = prediccion == esperado\n",
        "    if es_correcto:\n",
        "        aciertos += 1\n",
        "        emoji = \"‚úÖ\"\n",
        "    else:\n",
        "        emoji = \"‚ùå\"\n",
        "\n",
        "    print(f\"\\n{emoji} '{texto}'\")\n",
        "    print(f\"   Esperado: {esperado} | Predicho: {prediccion} | Confianza: {prob_prediccion*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"RESULTADO: {aciertos}/{len(casos_prueba)} correctos ({aciertos/len(casos_prueba)*100:.1f}%\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYeFtgokPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1xQz3UgPuL0"
      },
      "outputs": [],
      "source": [
        "from pyexpat import model\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "# Este es el archivo que debes subir a la carpeta de tu microservicio\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEPArdRuz5sC"
      },
      "source": [
        "********************************************************************************************************************************************************************************************************************"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
