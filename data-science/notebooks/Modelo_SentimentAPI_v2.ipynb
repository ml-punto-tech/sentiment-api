{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJ3Iy0IKFDG"
      },
      "source": [
        "# <font size=35 color=lightgreen>** Sentiment API **<font>ü•≤\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1WimRtik1c6"
      },
      "source": [
        "### <font size=12 color=lightgreen>Configuraci√≥n Inicial (Librer√≠as)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3A7xMRl-DP"
      },
      "source": [
        "#### 1. Procesamiento y Manipulaci√≥n de Datos\n",
        "* **`pandas`**\n",
        "    * Nos ayuda con la manipulaci√≥n y an√°lisis de datos estructurados.\n",
        "    * Carga el dataset (CSV), gestiona el DataFrame y permite filtrar o limpiar registros.\n",
        "* **`numpy`**\n",
        "    * Realiza las operaciones matem√°ticas y manejo de arrays eficientes.\n",
        "    * Soporte num√©rico fundamental para las transformaciones vectoriales de los textos.\n",
        "\n",
        "#### 2. Visualizaci√≥n y An√°lisis Exploratorio\n",
        "\n",
        "* **`matplotlib.pyplot`**\n",
        "    * Generaci√≥n de gr√°ficos est√°ticos.\n",
        "    * Visualizaci√≥n b√°sica de la distribuci√≥n de clases (Positivo vs. Negativo).\n",
        "* **`seaborn`**\n",
        "    * Visualizaci√≥n de datos estad√≠sticos avanzada.\n",
        "    * Generaci√≥n de matrices de confusi√≥n y gr√°ficos de distribuci√≥n est√©ticos para la presentaci√≥n.\n",
        "\n",
        "#### 3. Procesamiento de Lenguaje Natural (NLP) y Limpieza\n",
        "\n",
        "* **`re`** (Regular Expressions)\n",
        "    * Manejo de expresiones regulares.\n",
        "    * Eliminaci√≥n de ruido en el texto: URLs, menciones (@usuario), hashtags (#) y caracteres especiales no alfanum√©ricos.\n",
        "* **`string`**\n",
        "    * Constantes de cadenas comunes.\n",
        "    * Provee listas est√°ndar de signos de puntuaci√≥n para su eliminaci√≥n eficiente.\n",
        "\n",
        "#### 4. Modelado y Machine Learning (Core)\n",
        "\n",
        "* **`scikit-learn`**\n",
        "    * Biblioteca principal de Machine Learning.\n",
        "    * **`TfidfVectorizer`**: Transforma el texto limpio en vectores num√©ricos.\n",
        "    * **`LogisticRegression`**: Algoritmo de clasificaci√≥n supervisada.\n",
        "    * **`metrics`**: C√°lculo de precisi√≥n, recall y F1-score.\n",
        "    * **`Pipeline`**: Encapsulamiento de los pasos de transformaci√≥n y predicci√≥n.\n",
        "\n",
        "#### 5. Persistencia e Integraci√≥n\n",
        "Herramientas para conectar el modelo con el Backend.\n",
        "\n",
        "* **`joblib`**\n",
        "    * Serializaci√≥n eficiente de objetos Python.\n",
        "    * Exportar (`dump`) el pipeline entrenado a un archivo `.joblib` y cargarlo (`load`) en la API para realizar predicciones.\n",
        "* **`fastapi` & `uvicorn`**\n",
        "    * Framework web moderno de alto rendimiento.\n",
        "    * Exponer el modelo entrenado como un microservicio REST (endpoint `/predict`) para ser consumido por el Backend en Java.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tELAqUZeOA7W"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VengB6XbODtf"
      },
      "source": [
        "### <font size=16  color=lightgreen> Importando librer√≠as <font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0LqeO8Iig4ZI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import chardet\n",
        "import sklearn\n",
        "import fastapi\n",
        "import joblib\n",
        "import nltk\n",
        "import unicodedata\n",
        "import urllib.request\n",
        "from io import StringIO\n",
        "import urllib.response\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEXpMdxbOQAV"
      },
      "source": [
        "### <font size = 8 color=\"lightgreen\">Importaci√≥n de los datasets<font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpgAk4eZxyY"
      },
      "source": [
        "#### **Funci√≥n importaci√≥n dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yOwHw3xtYJEg"
      },
      "outputs": [],
      "source": [
        "def importar_dataset(url, separator=';'):\n",
        "    \"\"\"\n",
        "    Importa dataset desde URL detectando encoding autom√°ticamente.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Descargar contenido una sola vez\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            content = response.read()\n",
        "\n",
        "        # 2. Detectar encoding\n",
        "        result = chardet.detect(content)\n",
        "        encoding = result['encoding']\n",
        "        print(f\"üîç Encoding detectado: {encoding} (confianza: {result['confidence']:.2%})\")\n",
        "\n",
        "        # 3. Decodificar y cargar en DataFrame\n",
        "        decoded_content = content.decode(encoding, errors='replace')\n",
        "        data = pd.read_csv(StringIO(decoded_content), sep=separator)\n",
        "\n",
        "        print(\"‚úÖ Archivo cargado correctamente\")\n",
        "        print(f\"üìä Tama√±o del dataset: {data.shape}\")\n",
        "        print(\"\\nüîç Muestra aleatoria (3 registros):\")\n",
        "        print(data.sample(3))\n",
        "\n",
        "        return data\n",
        "\n",
        "    except urllib.error.URLError as e:\n",
        "        print(f\"‚ùå Error de URL: {e}\")\n",
        "        return None\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"‚ùå Error al parsear CSV: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error inesperado: {type(e).__name__}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDZW5B7jk5-x"
      },
      "source": [
        "#### **Dataset1: sentimentdataset_es.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iWgPb0VhYeKT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 72.97%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (732, 15)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "     Unnamed: 0.1  Unnamed: 0  \\\n",
            "304            71          73   \n",
            "386           371         375   \n",
            "538           659         663   \n",
            "\n",
            "                                                  Text      Sentiment  \\\n",
            "304   Encontrar la calma en medio de un d√≠a ajetreado.        Neutral   \n",
            "386  Hipnotizado por la danza c√≥smica de luci√©rnaga...  Encantamiento   \n",
            "538  Organizar una fiesta de pijamas con amigos est...     Excitaci√≥n   \n",
            "\n",
            "            Timestamp                     User   Platform  \\\n",
            "304   18-02-2023 9:30                ZenMaster    Twitter   \n",
            "386  10-08-2022 22:00         NightSkyObserver  Instagram   \n",
            "538  17-08-2023 22:15  SleepoverHostHighSchool    Twitter   \n",
            "\n",
            "                                              Hashtags  Retweets  Likes  \\\n",
            "304                                 #Calma #MenteEnPaz        15     30   \n",
            "386               #Encantamiento #Luci√©rnagas C√≥smicas        25     50   \n",
            "538  #Fiesta de pijamas divertida #Recuerdos de la ...        18     35   \n",
            "\n",
            "         Country  Year  Month  Day  Hour  \n",
            "304        India  2023      2   18     9  \n",
            "386       Brasil  2022      8   10    22  \n",
            "538  Reino Unido  2023      8   17    22  \n"
          ]
        }
      ],
      "source": [
        "df1_raw = importar_dataset(\"https://github.com/ml-punto-tech/sentiment-api/raw/refs/heads/dev/data-science/datasets/datasets-origin/sentimentdataset_es.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKr3W1NEaBrP"
      },
      "source": [
        "#### **Dataset2: sentiment_analysis_dataset.csv**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d2eRhM-MYh6L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: Windows-1252 (confianza: 73.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (2540, 3)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "                                                  texto  label sentimiento\n",
            "2272  ¬øPor qu√© mierda de todos los personajes y de t...      2    positivo\n",
            "2025  Nada mas satisfactorio que darse cuenta de tod...      1     neutral\n",
            "1765  Busco una calma inalcanzable La atm√≥sfera aqu√≠...      2    positivo\n"
          ]
        }
      ],
      "source": [
        "df2_raw = importar_dataset(\"https://raw.githubusercontent.com/ml-punto-tech/sentiment-api/refs/heads/feature/data-science-marely/data-science/datasets/datasets-origin/sentiment_analysis_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9qa7fqEjJagA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Encoding detectado: UTF-8-SIG (confianza: 100.00%)\n",
            "‚úÖ Archivo cargado correctamente\n",
            "üìä Tama√±o del dataset: (74682, 4)\n",
            "\n",
            "üîç Muestra aleatoria (3 registros):\n",
            "          id plataforma sentimiento  \\\n",
            "9134    9569  Overwatch     Neutral   \n",
            "4982      56     Amazon     Neutral   \n",
            "46323  11949    Verizon    Negativo   \n",
            "\n",
            "                                                   texto  \n",
            "9134   gente normal: f pagar a los cosmonautas humano...  \n",
            "4982   Lo √∫ltimo que necesitan es ir a trabajar a dis...  \n",
            "46323  Es muy solitario estar en la cima porque no ha...  \n"
          ]
        }
      ],
      "source": [
        "df3_raw = importar_dataset(\"https://github.com/eduardotec05/datasets/raw/refs/heads/main/twitter_training_esp_convertido%20(2).csv\", separator=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nY1nIBYtKA9g"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>plataforma</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Estoy llegando a Borderlands y los asesinar√© a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a las fronteras y os matar√© a todos,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a Borderlands y los matar√© a todos.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Voy a llegar a Borderlands y los asesinar√© a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Me estoy metiendo en Borderlands 2 y os voy a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id   plataforma sentimiento  \\\n",
              "0  2401  Borderlands    Positivo   \n",
              "1  2401  Borderlands    Positivo   \n",
              "2  2401  Borderlands    Positivo   \n",
              "3  2401  Borderlands    Positivo   \n",
              "4  2401  Borderlands    Positivo   \n",
              "\n",
              "                                               texto  \n",
              "0  Estoy llegando a Borderlands y los asesinar√© a...  \n",
              "1  Voy a llegar a las fronteras y os matar√© a todos,  \n",
              "2   Voy a llegar a Borderlands y los matar√© a todos.  \n",
              "3  Voy a llegar a Borderlands y los asesinar√© a t...  \n",
              "4  Me estoy metiendo en Borderlands 2 y os voy a ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2hn5BGLpl8eS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 1\n",
            "============================================================\n",
            "üìä Forma: (732, 15)\n",
            "üìù Columnas: ['Unnamed: 0.1', 'Unnamed: 0', 'Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Retweets', 'Likes', 'Country', 'Year', 'Month', 'Day', 'Hour']\n",
            "üî§ Columnas de texto: ['Text', 'Sentiment', 'Timestamp', 'User', 'Platform', 'Hashtags', 'Country']\n",
            "\n",
            "üìù Analizando columna: 'Text'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     '¬°Acabo de adoptar a un lindo amigo peludo!??'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     '¬°Acabo de terminar un entrenamiento incre√≠ble!??'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     '¬°Adoraci√≥n desbordante por un lindo cachorro rescatado!??'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     '¬°A√±o nuevo, nuevos objetivos de fitness!??'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     '¬°Celebrando el cumplea√±os de un amigo esta noche!??'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 2\n",
            "============================================================\n",
            "üìä Forma: (2540, 3)\n",
            "üìù Columnas: ['texto', 'label', 'sentimiento']\n",
            "üî§ Columnas de texto: ['texto', 'sentimiento']\n",
            "\n",
            "üìù Analizando columna: 'texto'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'termine bien abrumado despu√©s de hoy'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'me siento abrumado'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Me siento un poco abrumado por la cantidad de cosas que quiero dibujar, ver, jug...'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Salvador la √∫nica persona que no la ha abrumado de versiones???? #NadieComoT√∫'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Denme un helado o algo que ando full abrumado.'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n",
            "\n",
            "üîç VERIFICACI√ìN DE CALIDAD: Dataset 3\n",
            "============================================================\n",
            "üìä Forma: (74682, 4)\n",
            "üìù Columnas: ['id', 'plataforma', 'sentimiento', 'texto']\n",
            "üî§ Columnas de texto: ['plataforma', 'sentimiento', 'texto']\n",
            "\n",
            "üìù Analizando columna: 'plataforma'\n",
            "  Texto 1: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 2: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 3: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 4: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "  Texto 5: üìÑ Sin emojis\n",
            "     'Borderlands'\n",
            "\n",
            "‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def verificar_calidad_importacion(df, nombre_dataset):\n",
        "    \"\"\"\n",
        "    Verifica que no se haya perdido informaci√≥n durante la importaci√≥n.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç VERIFICACI√ìN DE CALIDAD: {nombre_dataset}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if df is None:\n",
        "        print(\"‚ùå Dataset es None\")\n",
        "        return False\n",
        "\n",
        "    # 1. Informaci√≥n b√°sica\n",
        "    print(f\"üìä Forma: {df.shape}\")\n",
        "    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "\n",
        "    # 2. Buscar columnas de texto\n",
        "    columnas_texto = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    print(f\"üî§ Columnas de texto: {columnas_texto}\")\n",
        "\n",
        "    if not columnas_texto:\n",
        "        print(\"‚ö†Ô∏è  No se encontraron columnas de texto\")\n",
        "        return True\n",
        "\n",
        "    # 3. Analizar una columna de texto (usar la primera)\n",
        "    col_texto = columnas_texto[0]\n",
        "    print(f\"\\nüìù Analizando columna: '{col_texto}'\")\n",
        "\n",
        "    # Muestra de textos\n",
        "    textos = df[col_texto].dropna().head(5).tolist()\n",
        "\n",
        "    problemas = []\n",
        "\n",
        "    for i, texto in enumerate(textos):\n",
        "        if isinstance(texto, str):\n",
        "            # Buscar caracteres de reemplazo (ÔøΩ) que indican problemas\n",
        "            caracteres_problema = texto.count('ÔøΩ')\n",
        "            if caracteres_problema > 0:\n",
        "                problemas.append(f\"Texto {i+1} tiene {caracteres_problema} caracteres de reemplazo (ÔøΩ)\")\n",
        "\n",
        "            # Buscar emojis\n",
        "            emojis = [c for c in texto if unicodedata.category(c)[0] in ['S', 'So']]\n",
        "            if emojis:\n",
        "                print(f\"  Texto {i+1}: ‚úÖ Tiene {len(emojis)} emoji(s): {''.join(emojis[:3])}\")\n",
        "            else:\n",
        "                print(f\"  Texto {i+1}: üìÑ Sin emojis\")\n",
        "\n",
        "            # Mostrar fragmento\n",
        "            preview = texto[:80] + \"...\" if len(texto) > 80 else texto\n",
        "            print(f\"     '{preview}'\")\n",
        "\n",
        "    # 4. Resumen\n",
        "    if problemas:\n",
        "        print(f\"\\n‚ö†Ô∏è  PROBLEMAS ENCONTRADOS:\")\n",
        "        for problema in problemas:\n",
        "            print(f\"   ‚Ä¢ {problema}\")\n",
        "        return False\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ CALIDAD OK: No se detectaron caracteres perdidos\")\n",
        "        return True\n",
        "\n",
        "verificar_calidad_importacion(df1_raw, \"Dataset 1\")\n",
        "verificar_calidad_importacion(df2_raw, \"Dataset 2\")\n",
        "verificar_calidad_importacion(df3_raw, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvsjkC76PuLm"
      },
      "source": [
        "<font color='lightgreen' size=12>Filtrar datasets</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6X6oJxnAPuLm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 texto sentimiento\n",
            "96   Asisti√≥ a un concierto de jazz y se balance√≥ a...     Alegr√≠a\n",
            "30   Abrazar la belleza de la naturaleza, un moment...    Positivo\n",
            "412  Intent√≥ un truco de magia para impresionar a s...   Verguenza\n",
            "242  Emb√°rcate en una odisea culinaria, saboreando ...     Neutral\n",
            "42   Accidentalmente me gust√≥ la foto antigua de la...   Verguenza\n",
            "                                                  texto sentimiento\n",
            "2468  mira que te voy a patear deja de hacerte el lo...    positivo\n",
            "2002  Risto Mejide es tan sOlo un pobre hombre con √≠...     neutral\n",
            "360   #gelp Son un fracaso total Cowen. Vos y los ap...    negativo\n",
            "481   Ma√±ana viajo muy lejos solo por primera vez, e...    negativo\n",
            "2358  Que esperanzador y digno tener a la ministra @...    positivo\n",
            "                                                   texto sentimiento\n",
            "37272  Estoy impresionado con el nivel de documentaci...    Positivo\n",
            "3358   Por favor, s√© falso. Se parece demasiado a cua...     Neutral\n",
            "23858        Yo cuando mi reuni√≥n con Google no funciona    Negativo\n",
            "12356         @N2K_MyTEAM Me consegu√≠ un par de zapatos.    Positivo\n",
            "17934                  Sabes que tengo lo mejor para ti.    Positivo\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n filtrar dataset\n",
        "def filtrar_dataset(data):\n",
        "    data_filtro = data[['texto', 'sentimiento']]\n",
        "    data_filtro = data_filtro[data_filtro['texto'].str.strip() != \"\"]\n",
        "    print(data_filtro.sample(5))\n",
        "    return data_filtro\n",
        "\n",
        "# Reemplazar nombre columnas Text por texto, Sentiment por sentimiento\n",
        "df1_raw.rename({'Text':'texto', 'Sentiment':'sentimiento'}, axis=1, inplace=True)\n",
        "df1_filtrado = filtrar_dataset(df1_raw)\n",
        "df2_filtrado = filtrar_dataset(df2_raw)\n",
        "df3_filtrado = filtrar_dataset(df3_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmazYt9QBYT"
      },
      "source": [
        "### <font size= 12 color=\"lightgreen\" >Explorando los datasets<font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_sb3UjtYPuLn"
      },
      "outputs": [],
      "source": [
        "# Crear funci√≥n para explorar datasets\n",
        "def explorar_dataset(data):\n",
        "    print('Filas: ' + str(data.shape[0]))\n",
        "    print('Columnas: ' + str(data.shape[1]))\n",
        "    print('\\nColumnas: \\n' + str(data.columns.tolist()))\n",
        "    print('\\nTipo de datos: \\n' + str(data.dtypes))\n",
        "    print('\\nValores nulos: \\n' + str(data.isnull().sum()))\n",
        "    print('\\nMuestra aleatoria (5 registros): \\n' + str(data.sample(5)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-OpMWf0l8DM"
      },
      "source": [
        "#### **Explorando Data1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D0SICtaLs770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 732\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto  sentimiento\n",
            "196  Destrozada por la traici√≥n, la confianza se de...     Traici√≥n\n",
            "383  Gratitud por las peque√±as alegr√≠as que trae ca...     Gratitud\n",
            "158  Con el coraz√≥n entusiasmado, corriendo por cam...        √Ånimo\n",
            "591  Rebosante de alegr√≠a, una taza de risa compart...      Alegr√≠a\n",
            "344  Evitando los fragmentos de sue√±os destrozados,...  Resiliencia\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFfglf1PjDfz"
      },
      "source": [
        "#### **Explorando data2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AvetNKaKfI3X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 732\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          0\n",
            "sentimiento    0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                 texto sentimiento\n",
            "473  La soledad, una compa√±era silenciosa en la noc...     Neutral\n",
            "6    ¬°Compartiendo amor y vibraciones positivas con...        Amor\n",
            "182  Debajo de las luces de la ciudad, la bailarina...    Positivo\n",
            "292  En los Oscar, el actor acepta gentilmente un p...    Gratitud\n",
            "146  Comenz√≥ a aprender bailes de sal√≥n, desliz√°ndo...     Alegr√≠a\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df1_filtrado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pq-p1Ii7NhwV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filas: 74682\n",
            "Columnas: 2\n",
            "\n",
            "Columnas: \n",
            "['texto', 'sentimiento']\n",
            "\n",
            "Tipo de datos: \n",
            "texto          object\n",
            "sentimiento    object\n",
            "dtype: object\n",
            "\n",
            "Valores nulos: \n",
            "texto          41\n",
            "sentimiento     0\n",
            "dtype: int64\n",
            "\n",
            "Muestra aleatoria (5 registros): \n",
            "                                                   texto  sentimiento\n",
            "63171  RhandlerR... ¬°Vaya! No puedo jugar por este er...     Negativo\n",
            "40484       ¬°Mira mi transmisi√≥n desde mi PlayStation 4!  Irrelevante\n",
            "51939  He estado jugando a Red Headed Redemption dura...     Positivo\n",
            "44962      W Esto es rid√≠culo pic.twitter.com/4TNeHzobjS     Negativo\n",
            "24240  Comprar rese√É¬±as negativas de Google - Rese√É¬±a...      Neutral\n"
          ]
        }
      ],
      "source": [
        "explorar_dataset(df3_filtrado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn46SXAhzyW"
      },
      "source": [
        "### <font size=12 color=lightgreen>Limpiar textos</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppTw4PLfmrRx"
      },
      "source": [
        "#### **Funci√≥n para limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U7pg4Upw97Ol"
      },
      "outputs": [],
      "source": [
        "def limpiar_texto_sentimientos(texto):\n",
        "    \"\"\"\n",
        "    Normaliza texto espa√±ol preservando √± y eliminando tildes.\n",
        "    NO convierte a min√∫sculas para preservar intensidad emocional.\n",
        "    \"\"\"\n",
        "    # Verifica si la entrada no es una cadena. Si no lo es, devuelve una cadena vac√≠a.\n",
        "    if not isinstance(texto, str):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Normaliza el texto para separar los caracteres base de sus diacr√≠ticos (ej., tildes).\n",
        "    texto = unicodedata.normalize('NFD', texto)\n",
        "\n",
        "    # 2. Reemplaza temporalmente las '√±' y '√ë' con marcadores especiales para preservarlas\n",
        "    # durante la eliminaci√≥n de diacr√≠ticos.\n",
        "    texto = texto.replace('n\\u0303', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('√±', '@@@N_TILDE@@@')\n",
        "    texto = texto.replace('N\\u0303', '@@@N_TILDE_MAYUS@@@')\n",
        "    texto = texto.replace('√ë', '@@@N_TILDE_MAYUS@@@')\n",
        "\n",
        "    # 3. Elimina los caracteres diacr√≠ticos (como las tildes) del texto.\n",
        "    texto = ''.join(\n",
        "        char for char in texto\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    # Restaura las '√±' y '√ë' utilizando los marcadores temporales.\n",
        "    texto = texto.replace('@@@N_TILDE@@@', '√±')\n",
        "    texto = texto.replace('@@@N_TILDE_MAYUS@@@', '√ë')\n",
        "\n",
        "    # Variable para almacenar el resultado de la limpieza.\n",
        "    resultado = texto\n",
        "    chars = []\n",
        "\n",
        "    # Itera sobre cada caracter en el resultado y a√±ade solo los caracteres imprimibles a una lista.\n",
        "    # Los caracteres no imprimibles (como los de control) son reemplazados por un espacio.\n",
        "    for char in resultado:\n",
        "        if char.isprintable():\n",
        "            chars.append(char)\n",
        "        else:\n",
        "            chars.append(' ')\n",
        "    resultado = ''.join(chars)\n",
        "\n",
        "    # Elimina URLs que terminan en \"...\" (posibles URLs rotas).\n",
        "    resultado = re.sub(r'https?://[^\\s]*\\.\\.\\.', '[URL_ROTA]', resultado)\n",
        "    resultado = re.sub(r'www\\.[^\\s]*\\\\.\\\\.\\\\.', '[URL_ROTA]', resultado)\n",
        "\n",
        "    # Normaliza los espacios m√∫ltiples a uno solo y elimina espacios al inicio y final.\n",
        "    resultado = ' '.join(resultado.split())\n",
        "    resultado = resultado.strip()\n",
        "\n",
        "    # Mostrar resultados estad√≠sticos de la limpieza.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Devuelve el texto preprocesado.\n",
        "    return resultado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z62jGtD-PuLo"
      },
      "source": [
        "#### **An√°lisis proceso de limpieza de textos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gs5CRWmVPuLo"
      },
      "outputs": [],
      "source": [
        "def analizar_limpieza_sentimientos(df_antes, df_despues, nombre):\n",
        "    \"\"\"\n",
        "    An√°lisis espec√≠fico para tu funci√≥n limpiar_texto_para_sentimientos\n",
        "    \"\"\"\n",
        "    print(f\"\\nüîç AN√ÅLISIS ESPEC√çFICO: {nombre}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Cambios en caracteres espec√≠ficos del espa√±ol\n",
        "    cambios_especificos = {\n",
        "        'tildes_eliminadas': 0,\n",
        "        '√±_preservadas': 0,\n",
        "        'urls_eliminadas': 0,\n",
        "        'mayusculas_preservadas': 0\n",
        "    }\n",
        "\n",
        "    # Muestra de 50 textos para an√°lisis detallado\n",
        "    muestra = min(50, len(df_antes))\n",
        "\n",
        "    for i in range(muestra):\n",
        "        if i < len(df_despues):\n",
        "            texto_antes = str(df_antes.iloc[i]['texto'])\n",
        "            texto_despues = str(df_despues.iloc[i]['texto'])\n",
        "\n",
        "            # Contar √± preservadas\n",
        "            if '√±' in texto_antes.lower() and '√±' in texto_despues.lower():\n",
        "                cambios_especificos['√±_preservadas'] += 1\n",
        "\n",
        "            # Contar URLs eliminadas\n",
        "            import re\n",
        "            urls_antes = len(re.findall(r'https?://\\S+', texto_antes))\n",
        "            urls_despues = len(re.findall(r'https?://\\S+', texto_despues))\n",
        "            if urls_antes > urls_despues:\n",
        "                cambios_especificos['urls_eliminadas'] += (urls_antes - urls_despues)\n",
        "\n",
        "            # Verificar may√∫sculas preservadas\n",
        "            mayus_antes = sum(1 for c in texto_antes if c.isupper())\n",
        "            mayus_despues = sum(1 for c in texto_despues if c.isupper())\n",
        "            if mayus_antes > 0 and mayus_despues > 0:\n",
        "                cambios_especificos['mayusculas_preservadas'] += 1\n",
        "\n",
        "    print(\"üìä Cambios espec√≠ficos de tu limpiador:\")\n",
        "    for cambio, cantidad in cambios_especificos.items():\n",
        "        print(f\"   ‚Ä¢ {cambio.replace('_', ' ').title()}: {cantidad} de {muestra} textos\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OJST9GAJPuLo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÅ Dataset 1\n",
            "   Registros: 732\n",
            "   Muestra (3 textos):\n",
            "                                                 texto  \\\n",
            "696  Un entumecimiento impenetrable me protege de l...   \n",
            "222  El complejo rompecabezas de la vida me deja en...   \n",
            "270  En el mosh pit de un concierto de Metallica, l...   \n",
            "\n",
            "                                          Texto_Limpio  \n",
            "696  Un entumecimiento impenetrable me protege de l...  \n",
            "222  El complejo rompecabezas de la vida me deja en...  \n",
            "270  En el mosh pit de un concierto de Metallica, l...  \n",
            "\n",
            "üìÅ Dataset 2\n",
            "   Registros: 2,540\n",
            "   Muestra (3 textos):\n",
            "                                                  texto  \\\n",
            "1164  TENEMOS UN PRESIDENTE QUE ESTA MAS ATENTO DE H...   \n",
            "1280  Buena conferencia de nuestro DT, muy centrado,...   \n",
            "1351  La calma que ha rozado se ha pausado por el karma   \n",
            "\n",
            "                                           Texto_Limpio  \n",
            "1164  TENEMOS UN PRESIDENTE QUE ESTA MAS ATENTO DE H...  \n",
            "1280  Buena conferencia de nuestro DT, muy centrado,...  \n",
            "1351  La calma que ha rozado se ha pausado por el karma  \n",
            "\n",
            "üìÅ Dataset 3\n",
            "   Registros: 74,682\n",
            "   Muestra (3 textos):\n",
            "                                                   texto  \\\n",
            "19816  S√© los tres mismos negros que juegan con World...   \n",
            "2262   @ProSyndicate. ¬°Qu√© l√°stima! Mi ordenador va m...   \n",
            "28032         ¬°Fue una carrera de Mastiff muy divertida!   \n",
            "\n",
            "                                            Texto_Limpio  \n",
            "19816  Se los tres mismos negros que juegan con World...  \n",
            "2262   @ProSyndicate. ¬°Que lastima! Mi ordenador va m...  \n",
            "28032         ¬°Fue una carrera de Mastiff muy divertida!  \n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 1\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 10 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 50 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 2\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 7 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 43 de 50 textos\n",
            "============================================================\n",
            "\n",
            "üîç AN√ÅLISIS ESPEC√çFICO: Dataset 3\n",
            "============================================================\n",
            "üìä Cambios espec√≠ficos de tu limpiador:\n",
            "   ‚Ä¢ Tildes Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ √ë Preservadas: 13 de 50 textos\n",
            "   ‚Ä¢ Urls Eliminadas: 0 de 50 textos\n",
            "   ‚Ä¢ Mayusculas Preservadas: 49 de 50 textos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Lista de dataframes para procesar\n",
        "dataframes = [\n",
        "    (df1_filtrado, \"Dataset 1\"),\n",
        "    (df2_filtrado, \"Dataset 2\"),\n",
        "    (df3_filtrado, \"Dataset 3\")\n",
        "]\n",
        "\n",
        "resultados = {}\n",
        "\n",
        "for df, nombre in dataframes:\n",
        "    # Aplicar limpieza\n",
        "    df['Texto_Limpio'] = df['texto'].apply(limpiar_texto_sentimientos)\n",
        "\n",
        "    # Guardar copia limpia\n",
        "    resultados[nombre] = df.copy()\n",
        "\n",
        "    # Mostrar info\n",
        "    print(f\"\\nüìÅ {nombre}\")\n",
        "    print(f\"   Registros: {len(df):,}\")\n",
        "    print(f\"   Muestra (3 textos):\")\n",
        "    print(df[['texto', 'Texto_Limpio']].sample(3))\n",
        "\n",
        "# Asignar a variables originales\n",
        "df1_clean = resultados[\"Dataset 1\"]\n",
        "df2_clean = resultados[\"Dataset 2\"]\n",
        "df3_clean = resultados[\"Dataset 3\"]\n",
        "\n",
        "analizar_limpieza_sentimientos(df1_filtrado, df1_clean, \"Dataset 1\")\n",
        "analizar_limpieza_sentimientos(df2_filtrado, df2_clean, \"Dataset 2\")\n",
        "analizar_limpieza_sentimientos(df3_filtrado, df3_clean, \"Dataset 3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uj1j4hVnPuLo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>Sumergirse con entusiasmo en un nuevo proyecto.</td>\n",
              "      <td>Entusiasmo</td>\n",
              "      <td>Sumergirse con entusiasmo en un nuevo proyecto.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Disfrutando del brillo dorado de la alegr√≠a, u...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Disfrutando del brillo dorado de la alegria, u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>Contemplaci√≥n reflexiva en medio de las ruinas...</td>\n",
              "      <td>Reflexi√≥n</td>\n",
              "      <td>Contemplacion reflexiva en medio de las ruinas...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "666    Sumergirse con entusiasmo en un nuevo proyecto.  Entusiasmo   \n",
              "209  Disfrutando del brillo dorado de la alegr√≠a, u...     Neutral   \n",
              "164  Contemplaci√≥n reflexiva en medio de las ruinas...   Reflexi√≥n   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "666    Sumergirse con entusiasmo en un nuevo proyecto.  \n",
              "209  Disfrutando del brillo dorado de la alegria, u...  \n",
              "164  Contemplacion reflexiva en medio de las ruinas...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jiA1uCrfPuLo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>Sin la siguiente estrofa, Pobre So√±ador del Tr...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Sin la siguiente estrofa, Pobre So√±ador del Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1668</th>\n",
              "      <td>t amo atsumu siempre vas a ser mi nene mi beb√©...</td>\n",
              "      <td>positivo</td>\n",
              "      <td>t amo atsumu siempre vas a ser mi nene mi bebe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>803</th>\n",
              "      <td>Yo de veras estoy loca, me siento sola otra ve...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Yo de veras estoy loca, me siento sola otra ve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1139  Sin la siguiente estrofa, Pobre So√±ador del Tr...    negativo   \n",
              "1668  t amo atsumu siempre vas a ser mi nene mi beb√©...    positivo   \n",
              "803   Yo de veras estoy loca, me siento sola otra ve...    negativo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "1139  Sin la siguiente estrofa, Pobre So√±ador del Tr...  \n",
              "1668  t amo atsumu siempre vas a ser mi nene mi bebe...  \n",
              "803   Yo de veras estoy loca, me siento sola otra ve...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "uBXLrjxHOWwS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38429</th>\n",
              "      <td>tener</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>tener</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24876</th>\n",
              "      <td>\"No tengo palabras para describir la incre√É¬≠bl...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>\"No tengo palabras para describir la increA bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51608</th>\n",
              "      <td>As√≠ es como se ve la escena inicial de Red Dea...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Asi es como se ve la escena inicial de Red Dea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "38429                                              tener    Negativo   \n",
              "24876  \"No tengo palabras para describir la incre√É¬≠bl...     Neutral   \n",
              "51608  As√≠ es como se ve la escena inicial de Red Dea...     Neutral   \n",
              "\n",
              "                                            Texto_Limpio  \n",
              "38429                                              tener  \n",
              "24876  \"No tengo palabras para describir la increA bl...  \n",
              "51608  Asi es como se ve la escena inicial de Red Dea...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYvX17ceGa1i"
      },
      "source": [
        "### <font size=12 color=lightgreen>Categorizar de sentimientos </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Limpieza de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Sentimientos √∫nicos (sin limpiar): 113\n",
            "Muestra (primeros 10): ['Abrumado', 'Aburrimiento', 'Aceptaci√≥n', 'Admiraci√≥n', 'Adoraci√≥n', 'Agradecido', 'Aislamiento', 'Alegr√≠a', 'Amabilidad', 'Amargura']\n",
            "\n",
            "üìä Sentimientos √∫nicos (limpios): 107\n",
            "Muestra (primeros 10): ['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura']\n"
          ]
        }
      ],
      "source": [
        "# Funci√≥n simple para limpiar (igual que usar√°s despu√©s)\n",
        "def limpiar_sentimiento_simple(sentimiento):\n",
        "    \"\"\"Convierte a min√∫sculas y quita espacios extras.\"\"\"\n",
        "    return ' '.join(str(sentimiento).lower().strip().split())\n",
        "\n",
        "# 1. Obtener sentimientos √∫nicos de ambos datasets\n",
        "sentimientos_unicos = sorted(list(df1_clean['sentimiento'].unique()) + list(df2_clean['sentimiento'].unique()) + list(df3_clean['sentimiento'].unique()))\n",
        "\n",
        "print(f\"üìä Sentimientos √∫nicos (sin limpiar): {len(sentimientos_unicos)}\")\n",
        "print(f\"Muestra (primeros 10): {sentimientos_unicos[:10]}\")\n",
        "\n",
        "# 2. Limpiar la lista de sentimientos √∫nicos\n",
        "sentimientos_unicos_limpios = [limpiar_sentimiento_simple(s) for s in sentimientos_unicos]\n",
        "\n",
        "# 3. Eliminar duplicados que aparezcan despu√©s de limpiar\n",
        "sentimientos_unicos_limpios = sorted(set(sentimientos_unicos_limpios))\n",
        "\n",
        "print(f\"\\nüìä Sentimientos √∫nicos (limpios): {len(sentimientos_unicos_limpios)}\")\n",
        "print(f\"Muestra (primeros 10): {sentimientos_unicos_limpios[:10]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ_i8f3tPuLp"
      },
      "source": [
        "#### **Categor√≠as Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pq_HYQiePuLp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de sentimientos √∫nicos: 107\n",
            "['abrumado', 'aburrimiento', 'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'aislamiento', 'alegr√≠a', 'amabilidad', 'amargura', 'ambivalencia', 'amistad', 'amor', 'angustia', 'anhelo', 'ansiedad', 'anticipaci√≥n', 'apreciaci√≥n', 'aprensivo', 'armon√≠a', 'arrepentimiento', 'asco', 'asombro', 'cautivaci√≥n', 'celebraci√≥n', 'colorido', 'confiado', 'confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'curiosidad', 'decepci√≥n', 'desamor', 'descubrimiento', 'desesperaci√≥n', 'deslumbrar', 'despectivo', 'determinaci√≥n', 'devastado', 'disfrute', 'diversi√≥n', 'dolor', 'elaci√≥n', 'elegancia', 'emoci√≥n', 'empoderamiento', 'emp√°tico', 'encantamiento', 'energ√≠a', 'enojo', 'entumecimiento', 'entusiasmo', 'envidia', 'envidioso', 'esperanza', 'euforia', 'excitaci√≥n', 'felicidad', 'frustraci√≥n', 'frustrado', 'grandeza', 'gratitud', 'inspiraci√≥n', 'inspirado', 'intimidaci√≥n', 'irrelevante', 'juguet√≥n', 'logro', 'l√°stima', 'malo', 'maravilla', 'melancol√≠a', 'mel√≥dico', 'miedo', 'motivaci√≥n', 'negativo', 'neutral', 'obst√°culo', 'odiar', 'optimismo', 'orgullo', 'pena', 'positividad', 'positivo', 'p√©rdida', 'reconfortante', 'reflexi√≥n', 'resentimiento', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfacci√≥n', 'serenidad', 'soledad', 'sorpresa', 'sufrimiento', 'temeroso', 'ternura', 'traici√≥n', 'tristeza', 'triunfo', 'verguenza', '√°nimo', '√©xito', '√©xtasis']\n",
            "Sentimientos positivos: 62\n",
            "Sentimientos negativos: 39\n",
            "Sentimientos neutros: 5\n",
            "\n",
            "‚úÖ Total clasificado: 106/107\n",
            "   - Positivos: 62 (58.5%)\n",
            "   - Negativos: 39 (36.8%)\n",
            "   - Neutros: 5 (4.7%)\n",
            "Total: 106\n",
            "\n",
            "‚ùå Sentimiento no clasificado: irrelevante\n"
          ]
        }
      ],
      "source": [
        "# 1. Definimos las listas de sentimientos seg√∫n su categor√≠a\n",
        "print(f\"Total de sentimientos √∫nicos: {len(sentimientos_unicos_limpios)}\")\n",
        "print(sentimientos_unicos_limpios)\n",
        "\n",
        "# 2. SENTIMIENTOS POSITIVOS COMPLETOS (Bienestar, √©xito, alegr√≠a, admiraci√≥n)\n",
        "positivos = [\n",
        "    'aceptaci√≥n', 'admiraci√≥n', 'adoraci√≥n', 'agradecido', 'alegr√≠a', 'amabilidad', 'amor', 'amistad', 'apreciaci√≥n', 'armon√≠a', 'asombro', 'cautivaci√≥n', 'celebraci√≥n', 'colorido', 'confiado','confianza', 'contentamiento', 'creatividad', 'cumplimiento', 'descubrimiento', 'deslumbrar', 'determinaci√≥n', 'disfrute','diversi√≥n', 'elegancia', 'emoci√≥n', 'emp√°tico', 'empoderamiento',\n",
        "    'encantamiento', 'energ√≠a', 'entusiasmo', 'esperanza', 'euforia', 'excitaci√≥n', 'felicidad', 'grandeza', 'gratitud', 'inspiraci√≥n', 'inspirado', 'intimidaci√≥n', 'juguet√≥n', 'logro','maravilla', 'mel√≥dico', 'motivaci√≥n', 'optimismo', 'orgullo',\n",
        "    'positividad', 'positivo', 'reconfortante', 'resiliencia', 'resplandor', 'reverencia', 'romance', 'satisfacci√≥n', 'serenidad','ternura', 'triunfo', '√°nimo', '√©xito','elaci√≥n','√©xtasis']\n",
        "\n",
        "print(f'Sentimientos positivos: {len(positivos)}'),\n",
        "\n",
        "# 3. SENTIMIENTOS NEGATIVOS COMPLETOS (Dolor, ira, miedo, estr√©s, p√©rdida)\n",
        "negativos = ['abrumado', 'aburrimiento', 'aislamiento', 'amargura', 'angustia', 'anhelo', 'ansiedad', 'aprensivo', 'arrepentimiento', 'asco',  'decepci√≥n', 'desamor', 'desesperaci√≥n', 'despectivo', 'devastado',\n",
        "    'dolor', 'enojo', 'entumecimiento', 'envidia', 'envidioso', 'frustraci√≥n', 'frustrado', 'l√°stima', 'obst√°culo', 'malo', 'melancol√≠a', 'miedo', 'negativo', 'odiar', 'pena', 'p√©rdida', 'reflexi√≥n', 'resentimiento', 'soledad', 'sufrimiento', 'temeroso', 'traici√≥n' , \t'tristeza' , \t'verguenza']\n",
        "\n",
        "print(f'Sentimientos negativos: {len(negativos)}')\n",
        "\n",
        "# 4. SENTIMIENTOS NEUTRALES (Estados ambiguos o contemplativos)\n",
        "neutros =  ['ambivalencia', 'curiosidad', 'neutral','sorpresa','anticipaci√≥n']\n",
        "print(f'Sentimientos neutros: {len(neutros)}')\n",
        "\n",
        "categorias = [positivos, negativos, neutros]\n",
        "\n",
        "# Verificaci√≥n del total\n",
        "total_clasificados = len(positivos) + len(negativos) + len(neutros)\n",
        "print(f'\\n‚úÖ Total clasificado: {total_clasificados}/{len(sentimientos_unicos_limpios)}')\n",
        "print(f'   - Positivos: {len(positivos)} ({len(positivos)/106*100:.1f}%)')\n",
        "print(f'   - Negativos: {len(negativos)} ({len(negativos)/106*100:.1f}%)')\n",
        "print(f'   - Neutros: {len(neutros)} ({len(neutros)/106*100:.1f}%)')\n",
        "print(f'Total: {len(positivos) + len(negativos) + len(neutros)}')\n",
        "print()\n",
        "\n",
        "# Verificar si existen elementos en las listas que no se encuentran en la lista sentimientos_unicos\n",
        "for sentimiento in negativos + positivos + neutros:\n",
        "    if sentimiento not in sentimientos_unicos_limpios:\n",
        "        print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "\n",
        "# for sentimiento in negativos + positivos + neutros:\n",
        "#     if sentimiento not in sentimientos_2:\n",
        "#         print(f\"‚ùå Sentimiento no encontrado en el dataset: {sentimiento}\")\n",
        "# Verificar si todos los sentimientos del dataset est√°n clasificados\n",
        "for sentimiento in sentimientos_unicos_limpios:\n",
        "    if sentimiento not in positivos + negativos + neutros:\n",
        "        print(f\"‚ùå Sentimiento no clasificado: {sentimiento}\")\n",
        "# else:\n",
        "#     print(\"‚úÖ Todos los sentimientos del dataset est√°n clasificados.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12vkocMMPuLp"
      },
      "source": [
        "#### **Funci√≥n para categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hAy-90rDPuLp"
      },
      "outputs": [],
      "source": [
        "def categorizar_sentimiento(sentimiento, categorias):\n",
        "    \"\"\"\n",
        "    Categoriza sentimientos solo si est√°n en las listas definidas.\n",
        "    Devuelve None para sentimientos no clasificados.\n",
        "    \"\"\"\n",
        "    sent = str(sentimiento).strip().lower()\n",
        "\n",
        "    if sent in positivos:\n",
        "        return 'positivo'\n",
        "    elif sent in negativos:\n",
        "        return 'negativo'\n",
        "    elif sent in neutros:\n",
        "        return 'neutral'\n",
        "    else:\n",
        "        # Devolvemos None para posterior filtrado\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XgFiRtKtPuLp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>La euforia inunda cuando la √∫ltima pieza del r...</td>\n",
              "      <td>Euforia</td>\n",
              "      <td>La euforia inunda cuando la ultima pieza del r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Contemplando los misterios de la vida bajo el ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Contemplando los misterios de la vida bajo el ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>La emoci√≥n aumenta a medida que comienza la cu...</td>\n",
              "      <td>Excitaci√≥n</td>\n",
              "      <td>La emocion aumenta a medida que comienza la cu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "452  La euforia inunda cuando la √∫ltima pieza del r...     Euforia   \n",
              "165  Contemplando los misterios de la vida bajo el ...     Neutral   \n",
              "443  La emoci√≥n aumenta a medida que comienza la cu...  Excitaci√≥n   \n",
              "\n",
              "                                          Texto_Limpio  \n",
              "452  La euforia inunda cuando la ultima pieza del r...  \n",
              "165  Contemplando los misterios de la vida bajo el ...  \n",
              "443  La emocion aumenta a medida que comienza la cu...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rKZfkztUPuLp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>¬øQue pasar√≠a si un capitulo de What if tempora...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>¬øQue pasaria si un capitulo de What if tempora...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2074</th>\n",
              "      <td>El sorprendido fui yo jajaja</td>\n",
              "      <td>neutral</td>\n",
              "      <td>El sorprendido fui yo jajaja</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>Quiero renunciar solo para tener mi liquidaci√≥...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Quiero renunciar solo para tener mi liquidacio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "256   ¬øQue pasar√≠a si un capitulo de What if tempora...    negativo   \n",
              "2074                       El sorprendido fui yo jajaja     neutral   \n",
              "138   Quiero renunciar solo para tener mi liquidaci√≥...    negativo   \n",
              "\n",
              "                                           Texto_Limpio  \n",
              "256   ¬øQue pasaria si un capitulo de What if tempora...  \n",
              "2074                       El sorprendido fui yo jajaja  \n",
              "138   Quiero renunciar solo para tener mi liquidacio...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56692</th>\n",
              "      <td>As√≠ que intent√© ense√±arle a mi mam√° c√≥mo funci...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Asi que intente ense√±arle a mi mama como funci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12558</th>\n",
              "      <td>#VALUE!</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>#VALUE!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71253</th>\n",
              "      <td>@GhostRecon Casi todas las asas de las mochila...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>@GhostRecon Casi todas las asas de las mochila...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "56692  As√≠ que intent√© ense√±arle a mi mam√° c√≥mo funci...     Neutral   \n",
              "12558                                            #VALUE!    Negativo   \n",
              "71253  @GhostRecon Casi todas las asas de las mochila...    Negativo   \n",
              "\n",
              "                                            Texto_Limpio  \n",
              "56692  Asi que intente ense√±arle a mi mama como funci...  \n",
              "12558                                            #VALUE!  \n",
              "71253  @GhostRecon Casi todas las asas de las mochila...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT9snuZtPuLq"
      },
      "source": [
        "#### **Categorizar sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DRuHBnaFPuLq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ df1: 732 registros categorizados\n",
            "‚úÖ df2: 2540 registros categorizados\n",
            "‚úÖ df3: 61692 registros categorizados\n"
          ]
        }
      ],
      "source": [
        "df1_clean['Sentimiento_Final'] = df1_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df1_categorized = df1_clean[df1_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df2_clean['Sentimiento_Final'] = df2_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df2_categorized = df2_clean[df2_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "df3_clean['Sentimiento_Final'] = df3_clean['sentimiento'].apply(\n",
        "    lambda x: categorizar_sentimiento(x,categorias)\n",
        ")\n",
        "\n",
        "df3_categorized = df3_clean[df3_clean['Sentimiento_Final'].notna()].copy()\n",
        "\n",
        "print(f\"‚úÖ df1: {len(df1_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df2: {len(df2_categorized)} registros categorizados\")\n",
        "print(f\"‚úÖ df3: {len(df3_categorized)} registros categorizados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2Q8euH7QPuLq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Al reflexionar sobre toda una vida de recuerdo...</td>\n",
              "      <td>Gratitud</td>\n",
              "      <td>Al reflexionar sobre toda una vida de recuerdo...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Al experimentar la emoci√≥n de una carrera de F...</td>\n",
              "      <td>Emoci√≥n</td>\n",
              "      <td>Al experimentar la emocion de una carrera de F...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>Disfrutando de una taza de t√© y contemplando e...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Disfrutando de una taza de te y contemplando e...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 texto sentimiento  \\\n",
              "69   Al reflexionar sobre toda una vida de recuerdo...    Gratitud   \n",
              "61   Al experimentar la emoci√≥n de una carrera de F...     Emoci√≥n   \n",
              "206  Disfrutando de una taza de t√© y contemplando e...    Positivo   \n",
              "\n",
              "                                          Texto_Limpio Sentimiento_Final  \n",
              "69   Al reflexionar sobre toda una vida de recuerdo...          positivo  \n",
              "61   Al experimentar la emocion de una carrera de F...          positivo  \n",
              "206  Disfrutando de una taza de te y contemplando e...          positivo  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "onq_zeNRPuLt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1977</th>\n",
              "      <td>Mir√° el triunfo que nos llevamos en cancha de ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Mira el triunfo que nos llevamos en cancha de ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1891</th>\n",
              "      <td>Medio blda esa idea de Ofe de \"que tengan mied...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Medio blda esa idea de Ofe de \"que tengan mied...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>778</th>\n",
              "      <td>Entre m√°s reservado seas mejor te va a ir en l...</td>\n",
              "      <td>negativo</td>\n",
              "      <td>Entre mas reservado seas mejor te va a ir en l...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  texto sentimiento  \\\n",
              "1977  Mir√° el triunfo que nos llevamos en cancha de ...     neutral   \n",
              "1891  Medio blda esa idea de Ofe de \"que tengan mied...     neutral   \n",
              "778   Entre m√°s reservado seas mejor te va a ir en l...    negativo   \n",
              "\n",
              "                                           Texto_Limpio Sentimiento_Final  \n",
              "1977  Mira el triunfo que nos llevamos en cancha de ...           neutral  \n",
              "1891  Medio blda esa idea de Ofe de \"que tengan mied...           neutral  \n",
              "778   Entre mas reservado seas mejor te va a ir en l...          negativo  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2_clean.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7nhxLa6SPxL4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51984</th>\n",
              "      <td>¬°Quedan pocos! Red Dead Redemption 2 por solo ...</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>¬°Quedan pocos! Red Dead Redemption 2 por solo ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48971</th>\n",
              "      <td>Guau</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Guau</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68082</th>\n",
              "      <td>El mundo: \"La gente sigue muriendo por COVID-1...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>El mundo: \"La gente sigue muriendo por COVID-1...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "51984  ¬°Quedan pocos! Red Dead Redemption 2 por solo ...     Neutral   \n",
              "48971                                               Guau    Positivo   \n",
              "68082  El mundo: \"La gente sigue muriendo por COVID-1...    Negativo   \n",
              "\n",
              "                                            Texto_Limpio Sentimiento_Final  \n",
              "51984  ¬°Quedan pocos! Red Dead Redemption 2 por solo ...           neutral  \n",
              "48971                                               Guau          positivo  \n",
              "68082  El mundo: \"La gente sigue muriendo por COVID-1...          negativo  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3_clean.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfhg_fBXPuLt"
      },
      "source": [
        "### <font color=lightgreen size=12>Limpiar dataset unificado</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEB_qDA3PuLt"
      },
      "source": [
        "#### **Funci√≥n limpieza dataset unificado**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "W19ms-90PuLu"
      },
      "outputs": [],
      "source": [
        "def limpiar_dataset_unificado(data, verbose=True):\n",
        "    \"\"\"\n",
        "    Limpia dataset unificado para an√°lisis de sentimientos.\n",
        "\n",
        "    Proceso:\n",
        "    1. Identifica y elimina CONTRADICCIONES (textos con diferentes sentimientos)\n",
        "    2. Elimina DUPLICADOS exactos (mismo texto, mismo sentimiento)\n",
        "    3. Limpieza final (espacios vac√≠os, NaN)\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame con 'Texto_Limpio' y 'Sentimiento_Final'\n",
        "        verbose: Si True, muestra an√°lisis detallado\n",
        "\n",
        "    Returns:\n",
        "        DataFrame limpio, sin duplicados ni contradicciones\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"üßπ LIMPIANDO DATASET UNIFICADO\")\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Textos √∫nicos iniciales: {data['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "    # Hacer copia para no modificar original\n",
        "    df = data.copy()\n",
        "\n",
        "    # ===== 1. ELIMINAR CONTRADICCIONES (PRIMERO) =====\n",
        "    if verbose:\n",
        "        print(f\"\\n1. üîç BUSCANDO CONTRADICCIONES...\")\n",
        "\n",
        "    # Textos con m√°s de un sentimiento diferente\n",
        "    conteo_sentimientos = df.groupby('Texto_Limpio')['Sentimiento_Final'].nunique()\n",
        "    textos_con_contradiccion = conteo_sentimientos[conteo_sentimientos > 1].index.tolist()\n",
        "\n",
        "    if textos_con_contradiccion:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontradas: {len(textos_con_contradiccion):,} contradicciones\")\n",
        "\n",
        "            # Mostrar algunos ejemplos\n",
        "            print(f\"   ‚Ä¢ Ejemplos (primeros 2):\")\n",
        "            for texto in textos_con_contradiccion[:2]:\n",
        "                sentimientos = df[df['Texto_Limpio'] == texto]['Sentimiento_Final'].unique()\n",
        "                texto_corto = texto[:60] + \"...\" if len(texto) > 60 else texto\n",
        "                print(f\"     - '{texto_corto}'\")\n",
        "                print(f\"       ‚Üí Sentimientos: {', '.join(sentimientos)}\")\n",
        "\n",
        "        # Eliminar TODOS los registros de textos contradictorios\n",
        "        df_sin_contradicciones = df[~df['Texto_Limpio'].isin(textos_con_contradiccion)].copy()\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df) - len(df_sin_contradicciones)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros por contradicciones\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay contradicciones\")\n",
        "        df_sin_contradicciones = df.copy()\n",
        "\n",
        "    # ===== 2. ELIMINAR DUPLICADOS EXACTOS =====\n",
        "    if verbose:\n",
        "        print(f\"\\n2. üîç BUSCANDO DUPLICADOS EXACTOS...\")\n",
        "\n",
        "    # Contar duplicados exactos (mismo texto, mismo sentimiento)\n",
        "    conteo_duplicados = df_sin_contradicciones['Texto_Limpio'].value_counts()\n",
        "    textos_duplicados = conteo_duplicados[conteo_duplicados > 1].index.tolist()\n",
        "\n",
        "    if textos_duplicados:\n",
        "        if verbose:\n",
        "            print(f\"   ‚ö†Ô∏è  Encontrados: {len(textos_duplicados):,} textos duplicados\")\n",
        "\n",
        "            # Calcular cu√°ntos registros se eliminar√°n\n",
        "            total_a_eliminar = sum([conteo_duplicados[t] - 1 for t in textos_duplicados])\n",
        "            print(f\"   ‚Ä¢ Registros a eliminar: {total_a_eliminar:,}\")\n",
        "\n",
        "        # Eliminar duplicados (mantener primera aparici√≥n)\n",
        "        df_sin_duplicados = df_sin_contradicciones.drop_duplicates(\n",
        "            subset=['Texto_Limpio'],\n",
        "            keep='first'\n",
        "        )\n",
        "\n",
        "        if verbose:\n",
        "            eliminados = len(df_sin_contradicciones) - len(df_sin_duplicados)\n",
        "            print(f\"   üóëÔ∏è  Eliminados: {eliminados:,} registros duplicados\")\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(f\"   ‚úÖ No hay duplicados exactos\")\n",
        "        df_sin_duplicados = df_sin_contradicciones.copy()\n",
        "\n",
        "    # ===== 3. LIMPIEZA FINAL =====\n",
        "    if verbose:\n",
        "        print(f\"\\n3. üßπ LIMPIEZA FINAL...\")\n",
        "\n",
        "    df_final = df_sin_duplicados.copy()\n",
        "\n",
        "    # Filtrar solo columnas necesarias\n",
        "    df_final = df_final[['Texto_Limpio', 'Sentimiento_Final']]\n",
        "\n",
        "    # Eliminar textos vac√≠os o solo espacios\n",
        "    textos_vacios_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Texto_Limpio'].str.strip() != \"\"]\n",
        "    textos_vacios_eliminados = textos_vacios_antes - len(df_final)\n",
        "\n",
        "    if verbose and textos_vacios_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Textos vac√≠os eliminados: {textos_vacios_eliminados}\")\n",
        "\n",
        "    # Eliminar sentimientos NaN\n",
        "    sentimientos_nan_antes = len(df_final)\n",
        "    df_final = df_final[df_final['Sentimiento_Final'].notna()]\n",
        "    sentimientos_nan_eliminados = sentimientos_nan_antes - len(df_final)\n",
        "\n",
        "    if verbose and sentimientos_nan_eliminados > 0:\n",
        "        print(f\"   ‚Ä¢ Sentimientos NaN eliminados: {sentimientos_nan_eliminados}\")\n",
        "\n",
        "    # ===== 4. VERIFICACI√ìN Y RESUMEN =====\n",
        "    if verbose:\n",
        "        print(f\"\\n4. ‚úÖ VERIFICACI√ìN FINAL\")\n",
        "        print(f\"   ‚Ä¢ Registros finales: {len(df_final):,}\")\n",
        "        print(f\"   ‚Ä¢ Textos √∫nicos finales: {df_final['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "        # Verificar que cada texto aparece solo una vez\n",
        "        if len(df_final) == df_final['Texto_Limpio'].nunique():\n",
        "            print(f\"   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\")\n",
        "        else:\n",
        "            diferencia = len(df_final) - df_final['Texto_Limpio'].nunique()\n",
        "            print(f\"   ‚ö†Ô∏è  ¬°Problema! Hay {diferencia} duplicados\")\n",
        "\n",
        "        # Resumen\n",
        "        print(f\"\\n\" + \"=\" * 50)\n",
        "        print(\"üìä RESUMEN DE LIMPIEZA\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        total_eliminados = (len(data) - len(df_final))\n",
        "        porcentaje_eliminado = (total_eliminados / len(data)) * 100\n",
        "\n",
        "        print(f\"Registros iniciales: {len(data):,}\")\n",
        "        print(f\"Registros finales: {len(df_final):,}\")\n",
        "        print(f\"Total eliminados: {total_eliminados:,} ({porcentaje_eliminado:.1f}%)\")\n",
        "\n",
        "        # Distribuci√≥n de sentimientos\n",
        "        print(f\"\\nüìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\")\n",
        "        distribucion = df_final['Sentimiento_Final'].value_counts()\n",
        "        for sentimiento, count in distribucion.items():\n",
        "            porcentaje = (count / len(df_final)) * 100\n",
        "            print(f\"   ‚Ä¢ {sentimiento}: {count:,} ({porcentaje:.1f}%)\")\n",
        "\n",
        "    return df_final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "n8a2z5ZNPuLu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6208</th>\n",
              "      <td>Definitivamente es un Walmart. A Amazon le enc...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Definitivamente es un Walmart. A Amazon le enc...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27747</th>\n",
              "      <td>Mi carrera en D&amp;D va viento en popa y est√° rea...</td>\n",
              "      <td>Positivo</td>\n",
              "      <td>Mi carrera en D&amp;D va viento en popa y esta rea...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22271</th>\n",
              "      <td>Los pol√≠ticos SIEMPRE han acusado a los buenos...</td>\n",
              "      <td>Negativo</td>\n",
              "      <td>Los politicos SIEMPRE han acusado a los buenos...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento  \\\n",
              "6208   Definitivamente es un Walmart. A Amazon le enc...    Negativo   \n",
              "27747  Mi carrera en D&D va viento en popa y est√° rea...    Positivo   \n",
              "22271  Los pol√≠ticos SIEMPRE han acusado a los buenos...    Negativo   \n",
              "\n",
              "                                            Texto_Limpio Sentimiento_Final  \n",
              "6208   Definitivamente es un Walmart. A Amazon le enc...          negativo  \n",
              "27747  Mi carrera en D&D va viento en popa y esta rea...          positivo  \n",
              "22271  Los politicos SIEMPRE han acusado a los buenos...          negativo  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1_categorized.sample(3)\n",
        "df2_categorized.sample(3)\n",
        "df3_categorized.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4d4Mra2PuLu"
      },
      "source": [
        "#### **Unificar datataset y limpieza**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CJeTAgAkPuLu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üîó UNIFICANDO DATASETS CATEGORIZADOS\n",
            "======================================================================\n",
            "üì¶ Dataset unificado: (64964, 2)\n",
            "   ‚Ä¢ Registros: 64,964\n",
            "   ‚Ä¢ Textos √∫nicos: 57,745\n",
            "\n",
            "======================================================================\n",
            "üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\n",
            "======================================================================\n",
            "üßπ LIMPIANDO DATASET UNIFICADO\n",
            "--------------------------------------------------\n",
            "Registros iniciales: 64,964\n",
            "Textos √∫nicos iniciales: 57,745\n",
            "\n",
            "1. üîç BUSCANDO CONTRADICCIONES...\n",
            "   ‚ö†Ô∏è  Encontradas: 209 contradicciones\n",
            "   ‚Ä¢ Ejemplos (primeros 2):\n",
            "     - ''\n",
            "       ‚Üí Sentimientos: neutral, positivo, negativo\n",
            "     - '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!...'\n",
            "       ‚Üí Sentimientos: negativo, neutral\n",
            "   üóëÔ∏è  Eliminados: 2,633 registros por contradicciones\n",
            "\n",
            "2. üîç BUSCANDO DUPLICADOS EXACTOS...\n",
            "   ‚ö†Ô∏è  Encontrados: 3,377 textos duplicados\n",
            "   ‚Ä¢ Registros a eliminar: 4,795\n",
            "   üóëÔ∏è  Eliminados: 4,795 registros duplicados\n",
            "\n",
            "3. üßπ LIMPIEZA FINAL...\n",
            "\n",
            "4. ‚úÖ VERIFICACI√ìN FINAL\n",
            "   ‚Ä¢ Registros finales: 57,536\n",
            "   ‚Ä¢ Textos √∫nicos finales: 57,536\n",
            "   üéØ ¬°Dataset 100% limpio! Cada texto aparece solo una vez\n",
            "\n",
            "==================================================\n",
            "üìä RESUMEN DE LIMPIEZA\n",
            "==================================================\n",
            "Registros iniciales: 64,964\n",
            "Registros finales: 57,536\n",
            "Total eliminados: 7,428 (11.4%)\n",
            "\n",
            "üìà DISTRIBUCI√ìN FINAL DE SENTIMIENTOS:\n",
            "   ‚Ä¢ negativo: 21,326 (37.1%)\n",
            "   ‚Ä¢ positivo: 19,220 (33.4%)\n",
            "   ‚Ä¢ neutral: 16,990 (29.5%)\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üîó UNIFICANDO DATASETS CATEGORIZADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Unificar los datasets categorizados\n",
        "df_unificado = pd.concat([df1_categorized[['Texto_Limpio', 'Sentimiento_Final']], df2_categorized[['Texto_Limpio', 'Sentimiento_Final']], df3_categorized[['Texto_Limpio','Sentimiento_Final']]], ignore_index=True)\n",
        "\n",
        "print(f\"üì¶ Dataset unificado: {df_unificado.shape}\")\n",
        "print(f\"   ‚Ä¢ Registros: {len(df_unificado):,}\")\n",
        "print(f\"   ‚Ä¢ Textos √∫nicos: {df_unificado['Texto_Limpio'].nunique():,}\")\n",
        "\n",
        "\n",
        "# %%\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üßπ APLICANDO LIMPIEZA AL DATASET UNIFICADO\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Aplicar limpieza\n",
        "df_final = limpiar_dataset_unificado(df_unificado, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PiaR4I5zPuLu"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto_Limpio</th>\n",
              "      <th>Sentimiento_Final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>57761</th>\n",
              "      <td>Yo no...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35686</th>\n",
              "      <td>¬°Uf! Una vez me pase al lado oscuro y elegi Ex...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44166</th>\n",
              "      <td>30. Despues de practicamente cancelar mi pedid...</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Texto_Limpio Sentimiento_Final\n",
              "57761                                           Yo no...          negativo\n",
              "35686  ¬°Uf! Una vez me pase al lado oscuro y elegi Ex...           neutral\n",
              "44166  30. Despues de practicamente cancelar mi pedid...          negativo"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_unificado.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOG13F7lPuLv"
      },
      "source": [
        " ### <font size=12 color=lightgreen>An√°lisis de Distribuci√≥n y Visualizaci√≥n</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5DwJkdPuLv"
      },
      "source": [
        "#### **An√°lisis de distribuci√≥n de sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2VLH0dQePuLv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\n",
            "============================================================\n",
            "SENTIMIENTO  | CANTIDAD | PORCENTAJE | PROPORCI√ìN\n",
            "--------------------------------------------------\n",
            "Positivo     |    19220 |     33.41% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Negativo     |    21326 |     37.07% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "Neutral      |    16990 |     29.53% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "--------------------------------------------------\n",
            "TOTAL        |    57536 |    100.00% | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#üìä AN√ÅLISIS DE DISTRIBUCI√ìN DEL DATASET FINAL\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìà AN√ÅLISIS DE DISTRIBUCI√ìN - DATASET FINAL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Calcular conteos y porcentajes\n",
        "conteos = df_final['Sentimiento_Final'].value_counts()\n",
        "total_registros = len(df_final)\n",
        "porcentajes = (conteos / total_registros * 100).round(2)\n",
        "\n",
        "# 2. Mostrar tabla detallada\n",
        "print(f\"{'SENTIMIENTO':<12} | {'CANTIDAD':>8} | {'PORCENTAJE':>10} | {'PROPORCI√ìN'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for sentimiento in ['positivo', 'negativo', 'neutral']:\n",
        "    if sentimiento in conteos:\n",
        "        count = conteos[sentimiento]\n",
        "        porcentaje = porcentajes[sentimiento]\n",
        "        # Crear barra visual\n",
        "        barra = '‚ñà' * int(count / total_registros * 40)  # Escala a 40 caracteres\n",
        "        print(f\"{sentimiento.capitalize():<12} | {count:>8} | {porcentaje:>9}% | {barra}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'TOTAL':<12} | {total_registros:>8} | {'100.00':>9}% | {'‚ñà' * 40}\")\n",
        "print(\"-\" * 58)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6Bpu2ZPuLv"
      },
      "source": [
        "#### **Visualizaci√≥n de la distribuci√≥n de Sentimientos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "INsd0XvNPuLv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "domain": {
                    "x": [
                      0,
                      1
                    ],
                    "y": [
                      0,
                      1
                    ]
                  },
                  "hovertemplate": "label=%{label}<br>value=%{value}<extra></extra>",
                  "insidetextfont": {
                    "color": "white",
                    "size": 14
                  },
                  "labels": [
                    "negativo",
                    "positivo",
                    "neutral"
                  ],
                  "legendgroup": "",
                  "name": "",
                  "showlegend": true,
                  "textinfo": "label+percent",
                  "textposition": "inside",
                  "type": "pie",
                  "values": {
                    "bdata": "TlMUS15C",
                    "dtype": "i2"
                  }
                }
              ],
              "layout": {
                "height": 500,
                "legend": {
                  "tracegroupgap": 0
                },
                "margin": {
                  "t": 60
                },
                "showlegend": false,
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: 57536 registros</span>",
                  "x": 0.5
                },
                "width": 500
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Grafica de pastel con Plotly\n",
        "\n",
        "valores = df_final['Sentimiento_Final'].value_counts().reset_index()\n",
        "valores.columns = ['sentimientos', 'Cantidad']\n",
        "fig1 = px.pie(\n",
        "    names = valores.sentimientos,\n",
        "    values = valores.Cantidad,\n",
        ")\n",
        "\n",
        "fig1.update_traces(textposition='inside', textinfo='label+percent',  insidetextfont=dict(color = 'white', size=14)\n",
        ")\n",
        "\n",
        "fig1.update_layout(\n",
        "    title_text=f'<b>Distribuci√≥n de Sentimientos</b><br><span style=\"font-size:14px\">Dataset Final: {total_registros} registros</span>',\n",
        "    title_x=0.5,\n",
        "    width=500,\n",
        "    height=500,\n",
        "    showlegend=False,\n",
        ")\n",
        "\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMplULMaPuLv"
      },
      "source": [
        "### <font size=12 color=lightgreen> Exportar dataset </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwSlmvXSPuLv"
      },
      "source": [
        "#### **Definir ruta de exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "esUzQFjnPuLv"
      },
      "outputs": [],
      "source": [
        "# Ruta actual\n",
        "ruta_actual = Path.cwd()\n",
        "\n",
        "# Buscar data-science\n",
        "if ruta_actual.name == 'notebooks':\n",
        "    # Si estamos en notebooks/, ir a ../datasets\n",
        "    carpeta_datasets = ruta_actual.parent / 'datasets'\n",
        "else:\n",
        "    # Buscar data-science en directorios padres\n",
        "    for directorio_padre in ruta_actual.parents:\n",
        "        if (directorio_padre / 'data-science').exists():\n",
        "            carpeta_datasets = directorio_padre / 'data-science' / 'datasets'\n",
        "            break\n",
        "    else:\n",
        "        # Si no encuentra, usar directorio actual/datasets\n",
        "        carpeta_datasets = ruta_actual / 'datasets'\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "carpeta_datasets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Ruta completa del archivo\n",
        "archivo_final = carpeta_datasets / 'dataset.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9kZOcK7PuLv"
      },
      "source": [
        "#### **Exportar dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WSBwUlWgPuLw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset.csv\n",
            "üìä Registros: 57,536\n"
          ]
        }
      ],
      "source": [
        "# Renombrar columnas para formato final\n",
        "df_exportar = df_final.rename({\n",
        "    'Texto_Limpio': 'texto',\n",
        "    'Sentimiento_Final': 'sentimiento'\n",
        "}, axis=1)\n",
        "\n",
        "\n",
        "metadata = {\n",
        "    \"total_registros\": len(df_exportar),\n",
        "    \"distribucion\": dict(df_exportar['sentimiento'].value_counts()),\n",
        "    \"fecha_creacion\": datetime.now().isoformat(),\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"fuentes\": [\n",
        "        \"sentimentdataset_es.csv\",\n",
        "        \"sentiment_analysis_dataset.csv\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exportar\n",
        "df_exportar.to_csv(archivo_final, index=False, encoding='utf-8-sig')\n",
        "print(f\"‚úÖ Dataset exportado: {archivo_final}\")\n",
        "print(f\"üìä Registros: {len(df_exportar):,}\")\n",
        "\n",
        "# Crear copia para trabajo posterior\n",
        "df = df_exportar.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxLqWrOWPuLw"
      },
      "source": [
        "#### **Verificar exportaci√≥n**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "YB9ZY3b3PuLw"
      },
      "outputs": [],
      "source": [
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    Y verificaci√≥n de integridad mejorada\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            # Probar con 5 filas primero\n",
        "            df_test = pd.read_csv(ruta, encoding=enc, nrows=5)\n",
        "\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                # üîç VERIFICACI√ìN DE INTEGRIDAD MEJORADA\n",
        "                print(\"üîç Verificaci√≥n de integridad:\")\n",
        "                print(f\"   ‚Ä¢ Valores nulos totales: {df.isnull().sum().sum()}\")\n",
        "                print(f\"   ‚Ä¢ Textos vac√≠os: {(df['texto'].str.strip() == '').sum()}\")\n",
        "\n",
        "                # Verificar que todos los sentimientos sean v√°lidos\n",
        "                sentimientos_validos = ['positivo', 'negativo', 'neutral']\n",
        "                sentimientos_invalidos = df[~df['sentimiento'].isin(sentimientos_validos)]\n",
        "\n",
        "                if len(sentimientos_invalidos) > 0:\n",
        "                    print(f\"   ‚ö†Ô∏è  Sentimientos inv√°lidos: {len(sentimientos_invalidos)}\")\n",
        "                    print(f\"      Valores √∫nicos inv√°lidos: {sentimientos_invalidos['sentimiento'].unique()}\")\n",
        "                else:\n",
        "                    print(f\"   ‚úÖ Todos los sentimientos son v√°lidos\")\n",
        "\n",
        "                # Verificar unicidad\n",
        "                textos_unicos = df['texto'].nunique()\n",
        "                if len(df) == textos_unicos:\n",
        "                    print(f\"   ‚úÖ 100% textos √∫nicos: {textos_unicos:,} textos √∫nicos\")\n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  Duplicados: {len(df) - textos_unicos:,} textos duplicados\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PwJXRfMxPuLw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 57,536 registros (encoding: utf-8-sig)\n",
            "üîç Verificaci√≥n de integridad:\n",
            "   ‚Ä¢ Valores nulos totales: 0\n",
            "   ‚Ä¢ Textos vac√≠os: 0\n",
            "   ‚úÖ Todos los sentimientos son v√°lidos\n",
            "   ‚úÖ 100% textos √∫nicos: 57,536 textos √∫nicos\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                           texto sentimiento\n",
            "    ¬°Acabo de adoptar a un lindo amigo peludo!??    positivo\n",
            "¬°Acabo de terminar un entrenamiento increible!??    positivo\n"
          ]
        }
      ],
      "source": [
        "# Uso simple - as√≠ deber√≠a funcionar\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eBDe0CPbl8ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ CSV cargado: 57,536 registros (encoding: utf-8-sig)\n",
            "üìù Columnas: ['texto', 'sentimiento']\n",
            "üìä Muestra (2 filas):\n",
            "                                           texto sentimiento\n",
            "    ¬°Acabo de adoptar a un lindo amigo peludo!??    positivo\n",
            "¬°Acabo de terminar un entrenamiento increible!??    positivo\n"
          ]
        }
      ],
      "source": [
        "# Verificar que el archivo se pueda leer\n",
        "def verificar_csv_simple(ruta_archivo, mostrar_muestra=True):\n",
        "    \"\"\"\n",
        "    Verificaci√≥n simplificada con detecci√≥n de encoding\n",
        "    \"\"\"\n",
        "    ruta = Path(ruta_archivo)\n",
        "\n",
        "    if not ruta.exists():\n",
        "        print(f\"‚ùå Archivo no encontrado: {ruta}\")\n",
        "        return None\n",
        "\n",
        "    # Detectar encoding\n",
        "    encodings = ['utf-8-sig', 'utf-8', 'latin1', 'cp1252']\n",
        "\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=enc, nrows=5)  # Probar con 5 filas\n",
        "            # Si llegamos aqu√≠, el encoding funciona\n",
        "            try:\n",
        "                # Ahora cargar completo\n",
        "                df = pd.read_csv(ruta, encoding=enc)\n",
        "                print(f\"‚úÖ CSV cargado: {len(df):,} registros (encoding: {enc})\")\n",
        "\n",
        "                if mostrar_muestra:\n",
        "                    print(f\"üìù Columnas: {list(df.columns)}\")\n",
        "                    print(f\"üìä Muestra (2 filas):\")\n",
        "                    print(df.head(2).to_string(index=False))\n",
        "\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error cargando con encoding {enc}: {type(e).__name__}\")\n",
        "                continue\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "\n",
        "    print(\"‚ùå No se pudo cargar con ning√∫n encoding com√∫n\")\n",
        "    return None\n",
        "\n",
        "# Uso simple\n",
        "df_check = verificar_csv_simple(archivo_final, mostrar_muestra=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL-DDylhPuLw"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Resumen ejecutivo </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQcqcJa0PuLx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìã RESUMEN EJECUTIVO - PREPROCESAMIENTO COMPLETADO\n",
            "============================================================\n",
            "‚úÖ Dataset final: 57536 registros\n",
            "‚úÖ Distribuci√≥n balanceada: Positivo 33.41%, Negativo 37.07%, Neutral 29.53%\n",
            "‚úÖ Archivo exportado: c:\\Users\\marely\\OneDrive\\Documentos\\Oracle_ONE\\Hackaton\\SentimentAPI-Project\\sentiment-api\\data-science\\datasets\\dataset.csv\n",
            "‚úÖ Calidad: 0 textos vac√≠os, 0 valores nulos\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"üìã RESUMEN EJECUTIVO - HACKATHON SENTIMENT API\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"‚úÖ Dataset final: {len(df_exportar):,} registros\")\n",
        "print(f\"‚úÖ Distribuci√≥n balanceada: {porcentajes['positivo']}% üëç | {porcentajes['negativo']}% üëé | {porcentajes['neutral']}% üòê\")\n",
        "print(f\"‚úÖ Calidad del dataset:\")\n",
        "print(f\"   ‚Ä¢ 0 contradicciones (cada texto tiene √∫nico sentimiento)\")\n",
        "print(f\"   ‚Ä¢ 0 duplicados (100% textos √∫nicos)\")\n",
        "print(f\"   ‚Ä¢ 0 valores nulos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLOhkA9DobZ"
      },
      "source": [
        "---\n",
        "### <font size=12 color=lightgreen>Observaciones</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkc_BmZ2BKOR"
      },
      "source": [
        "### 1. **<font color='lightgreen'>Origen de los datos</font>**\n",
        "\n",
        "Con el objetivo de mejorar la capacidad de generalizaci√≥n del modelo, se trabaj√≥ con dos datasets independientes obtenidos desde Kaggle.\n",
        "Si bien ambos conjuntos de datos abordan el an√°lisis de sentimiento en espa√±ol, presentan diferencias en estructura, calidad ling√º√≠stica y formato de origen. Su integraci√≥n permiti√≥ ampliar la diversidad de expresiones textuales, reduciendo el sesgo hacia un √∫nico estilo de redacci√≥n y fortaleciendo la robustez del pipeline de preparaci√≥n de datos en escenarios similares a producci√≥n.\n",
        "\n",
        "#### **Fuentes de datos (Kaggle):**\n",
        "\n",
        "- https://www.kaggle.com/datasets/engineercolsoquas/spanish-sentiment-analysis-dataset\n",
        "\n",
        "- https://www.kaggle.com/datasets/kashishparmar02/social-media-sentiments-analysis-dataset\n",
        "\n",
        "- https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-62cItaKB6X5"
      },
      "source": [
        "---\n",
        "### 2. **<font color='lightgreen'> Informe de Desaf√≠os T√©cnicos y Soluciones</font>**\n",
        "\n",
        "#### **Dataset** 1 ‚Äì Inconsistencias en el idioma\n",
        "\n",
        "- Problema: El dataset original presentaba traducciones incompletas, combinando registros en espa√±ol con fragmentos en su idioma original, adem√°s de traducciones literales de baja calidad. Esta situaci√≥n afectaba la coherencia sem√°ntica del texto y pod√≠a introducir ruido en el an√°lisis de sentimiento.\n",
        "\n",
        "- Soluci√≥n aplicada: Se utiliz√≥ la herramienta de Traducci√≥n de Microsoft Excel como apoyo para identificar registros no traducidos. No obstante, la correcci√≥n se realiz√≥ de forma manual y supervisada, revisando y ajustando cada registro individualmente con el fin de preservar el significado original del texto y evitar distorsiones sem√°nticas. Posteriormente, se realiz√≥ una revisi√≥n manual (sanity check) para asegurar la consistencia ling√º√≠stica del dataset completo.\n",
        "\n",
        "- Impacto en el an√°lisis: La normalizaci√≥n del idioma permiti√≥ obtener un corpus coherente en espa√±ol, reduciendo ambig√ºedades y mejorando la calidad de los datos de entrada para la etapa de clasificaci√≥n de sentimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXEO0PzKAM7U"
      },
      "source": [
        "\n",
        "**Dataset 2 ‚Äì Problemas de codificaci√≥n de caracteres (encoding)**\n",
        "\n",
        "- Problema:\n",
        "El segundo dataset se encontraba en formato Excel y presentaba errores de codificaci√≥n al ser abierto, evidenciados por la aparici√≥n de caracteres especiales incorrectos (mojibake), lo que imped√≠a un procesamiento adecuado del texto.\n",
        "\n",
        "- Soluci√≥n aplicada:\n",
        "Como primer paso, el archivo fue exportado a formato CSV. Posteriormente, se realiz√≥ la ingesta mediante Power Query, donde se configur√≥ expl√≠citamente la codificaci√≥n Unicode (UTF-8), corrigiendo la estructura de caracteres antes de su integraci√≥n al pipeline de preparaci√≥n de datos.\n",
        "\n",
        "- Impacto en el an√°lisis:\n",
        "La correcci√≥n del encoding asegur√≥ la correcta interpretaci√≥n de caracteres propios del idioma espa√±ol, evitando p√©rdidas de informaci√≥n y mejorando la calidad del texto procesado.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCHVmQyrOnlI"
      },
      "source": [
        "### 3. **<font color='lightgreen'>Normalizaci√≥n y Limpieza de Texto</font>**\n",
        "- Se aplic√≥ una funci√≥n de preprocesamiento (limpiar_texto_sentimiento) que incluy√≥:\n",
        "\n",
        "- Preservaci√≥n de may√∫sculas/min√∫sculas (para mantener intensidad emocional).\n",
        "\n",
        "- Eliminaci√≥n de tildes (pero conservaci√≥n de √±/√ë).\n",
        "\n",
        "- Limpieza de URLs, menciones y caracteres no imprimibles.\n",
        "\n",
        "- Normalizaci√≥n de espacios y saltos de l√≠nea.\n",
        "\n",
        "**Nota: Se decidi√≥ no convertir todo a min√∫sculas para conservar pistas contextuales (ej. ‚Äú¬°GENIAL!‚Äù vs. ‚Äúgenial‚Äù), relevantes para modelos basados en intensidad emocional.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K2ezd_nPuLy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 57536 entries, 0 to 64963\n",
            "Data columns (total 2 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   texto        57536 non-null  object\n",
            " 1   sentimiento  57536 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzFpQ4smRcug"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Machine Learning</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6MSbMjXPuLy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¬°Acabo de adoptar a un lindo amigo peludo!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>¬°Acabo de terminar un entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>¬°Adoracion desbordante por un lindo cachorro r...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>¬°A√±o nuevo, nuevos objetivos de fitness!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>¬°Celebrando el cumplea√±os de un amigo esta noc...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64959</th>\n",
              "      <td>Acabo de darme cuenta de que la particion de W...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64960</th>\n",
              "      <td>Acabo de darme cuenta de que la particion de l...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64961</th>\n",
              "      <td>Acabo de darme cuenta de que la particion de W...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64962</th>\n",
              "      <td>Acabo de darme cuenta de que entre la particio...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64963</th>\n",
              "      <td>Al igual que la particion de Windows de mi Mac...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57536 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento\n",
              "0           ¬°Acabo de adoptar a un lindo amigo peludo!??    positivo\n",
              "1       ¬°Acabo de terminar un entrenamiento increible!??    positivo\n",
              "2      ¬°Adoracion desbordante por un lindo cachorro r...    positivo\n",
              "3             ¬°A√±o nuevo, nuevos objetivos de fitness!??    positivo\n",
              "4      ¬°Celebrando el cumplea√±os de un amigo esta noc...    positivo\n",
              "...                                                  ...         ...\n",
              "64959  Acabo de darme cuenta de que la particion de W...    positivo\n",
              "64960  Acabo de darme cuenta de que la particion de l...    positivo\n",
              "64961  Acabo de darme cuenta de que la particion de W...    positivo\n",
              "64962  Acabo de darme cuenta de que entre la particio...    positivo\n",
              "64963  Al igual que la particion de Windows de mi Mac...    positivo\n",
              "\n",
              "[57536 rows x 2 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Cdy77Lknl9pd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\marely\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Limpieza de texto mejorada aplicada\n",
            "\n",
            "Muestra de textos limpios:\n",
            "                                                   texto sentimiento\n",
            "56937  no encontraron asbesto laboratorios? asociaron...    negativo\n",
            "16457  palabras no pueden explicar mucho odio combate...    negativo\n",
            "51340  aun orgulloso ser parte de... obtener mas info...    negativo\n",
            "46365  tiempo jugando red dead redemption pic.twitter...    positivo\n",
            "45138  hola todos, solo pregunta, estarian mas acuerd...    positivo\n"
          ]
        }
      ],
      "source": [
        "# Descargar stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def limpiar_texto_mejorado(texto):\n",
        "    \"\"\"\n",
        "    Limpieza de texto m√°s conservadora que preserva palabras  de negaci√≥n\n",
        "    y modificadores de intensidad.\n",
        "    \"\"\"\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Eliminar caracteres especiales PERO preservar puntuaci√≥n emocional\n",
        "    texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±0-9\\s!?.,\\-]', '', texto)\n",
        "\n",
        "    # Stopwords espa√±olas\n",
        "    stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "    # PALABRAS CR√çTICAS A MANTENER (expandida vs. original)\n",
        "    palabras_criticas = {\n",
        "        # Negaciones\n",
        "        'no', 'ni', 'sin', 'nunca', 'jamas', 'tampoco', 'nada', 'nadie',\n",
        "        # Intensificadores\n",
        "        'muy', 'mucho', 'poco', 'mas', 'menos', 'demasiado', 'bastante',\n",
        "        # Modales\n",
        "        'pero', 'aunque', 'sino', 'si',\n",
        "        # Adjetivos de sentimiento\n",
        "        'malo', 'mala', 'mal', 'bien', 'bueno', 'buena', 'mejor', 'peor',\n",
        "        'horrible', 'terrible', 'excelente', 'pesimo', 'p√©simo',\n",
        "        # Verbos de sentimiento\n",
        "        'odio', 'amo', 'encanta', 'disgusta', 'molesta',\n",
        "        # Otros\n",
        "        'contra', 'hacia'\n",
        "    }\n",
        "\n",
        "    # Remover stopwords EXCEPTO las cr√≠ticas\n",
        "    stop_words = stop_words - palabras_criticas\n",
        "\n",
        "    palabras = texto.split()\n",
        "    palabras_filtradas = [palabra for palabra in palabras if palabra not in stop_words]\n",
        "\n",
        "    return ' '.join(palabras_filtradas)\n",
        "\n",
        "# Aplicar limpieza mejorada\n",
        "df['texto'] = df['texto'].apply(limpiar_texto_mejorado)\n",
        "\n",
        "print(\"‚úÖ Limpieza de texto mejorada aplicada\")\n",
        "print(f\"\\nMuestra de textos limpios:\")\n",
        "print(df[['texto', 'sentimiento']].sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3SJfTa-EPuLy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acabo adoptar lindo amigo peludo!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acabo terminar entrenamiento increible!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adoracion desbordante lindo cachorro rescatado!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a√±o nuevo, nuevos objetivos fitness!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>celebrando cumplea√±os amigo noche!??</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64959</th>\n",
              "      <td>acabo darme cuenta particion windows mac 6 a√±o...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64960</th>\n",
              "      <td>acabo darme cuenta particion ventana mac 6 a√±o...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64961</th>\n",
              "      <td>acabo darme cuenta particion windows mac retra...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64962</th>\n",
              "      <td>acabo darme cuenta particion windows mac tener...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64963</th>\n",
              "      <td>igual particion windows mac retraso 6 a√±os con...</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57536 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   texto sentimiento\n",
              "0                    acabo adoptar lindo amigo peludo!??    positivo\n",
              "1              acabo terminar entrenamiento increible!??    positivo\n",
              "2      adoracion desbordante lindo cachorro rescatado!??    positivo\n",
              "3                 a√±o nuevo, nuevos objetivos fitness!??    positivo\n",
              "4                   celebrando cumplea√±os amigo noche!??    positivo\n",
              "...                                                  ...         ...\n",
              "64959  acabo darme cuenta particion windows mac 6 a√±o...    positivo\n",
              "64960  acabo darme cuenta particion ventana mac 6 a√±o...    positivo\n",
              "64961  acabo darme cuenta particion windows mac retra...    positivo\n",
              "64962  acabo darme cuenta particion windows mac tener...    positivo\n",
              "64963  igual particion windows mac retraso 6 a√±os con...    positivo\n",
              "\n",
              "[57536 rows x 2 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LH5NgVcQKEx"
      },
      "source": [
        " ### <font size=12 color=lightgreen> Balanceo del Dataset, TF-IDF, Modelo, M√©tricas y Serializaci√≥n </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AGMacHrPuLy"
      },
      "source": [
        "### Instalaci√≥n de `imblearn`\n",
        "\n",
        "Primero, necesitamos instalar la librer√≠a `imblearn`, que proporciona herramientas para manejar datasets desbalanceados, incluyendo la t√©cnica SMOTE para sobremuestreo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "NpuPPs85PuLy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imblearn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.0)\n",
            "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (0.1.5)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\marely\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
            "Librer√≠a 'imblearn' instalada exitosamente.\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('pip install imblearn')\n",
        "print(\"Librer√≠a 'imblearn' instalada exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx2DlzvEPuLz"
      },
      "source": [
        "### Separaci√≥n de Caracter√≠sticas y Target\n",
        "\n",
        "Ahora, separaremos las caracter√≠sticas (el texto limpio) y la variable objetivo (el sentimiento) de nuestro DataFrame `df`. Tambi√©n mostraremos la distribuci√≥n inicial de las clases para ver el desbalanceo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "uFz0LAY_PuLz"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "djlXVfUUl9pe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribuci√≥n de clases:\n",
            "sentimiento\n",
            "negativo    21326\n",
            "positivo    19220\n",
            "neutral     16990\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Train: 46028 | Test: 11508\n",
            "\n",
            "‚úÖ Vectorizaci√≥n completada\n",
            "   Dimensiones: (46028, 10000)\n",
            "   Vocabulario: 10000 t√©rminos\n"
          ]
        }
      ],
      "source": [
        "# Separar X e y\n",
        "X = df['texto']\n",
        "y = df['sentimiento']\n",
        "\n",
        "print(\"Distribuci√≥n de clases:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Divisi√≥n train/test\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain: {len(X_train_unbalanced)} | Test: {len(X_test)}\")\n",
        "\n",
        "# üÜï TF-IDF MEJORADO\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,      # ‚¨Ü Aumentado de 5000\n",
        "    ngram_range=(1, 3),      # ‚¨Ü Trigramas (antes solo bigramas)\n",
        "    min_df=2,                # üÜï Nuevo\n",
        "    max_df=0.95,             # üÜï Nuevo\n",
        "    sublinear_tf=True        # üÜï Nuevo\n",
        ")\n",
        "\n",
        "X_train_tfidf_unbalanced = vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\n‚úÖ Vectorizaci√≥n completada\")\n",
        "print(f\"   Dimensiones: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"   Vocabulario: {len(vectorizer.get_feature_names_out())} t√©rminos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIbtwkkQhx0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Divisi√≥n de Datos (Entrenamiento y Prueba) y Vectorizaci√≥n TF-IDF</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbfr-opZPuLz"
      },
      "source": [
        "\n",
        "\n",
        "Es crucial dividir el dataset en conjuntos de entrenamiento y prueba *antes* de aplicar SMOTE para evitar la fuga de datos (data leakage). Luego, transformaremos los textos en vectores num√©ricos usando `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FoyoVnuNPuLz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tama√±o del conjunto de entrenamiento (desbalanceado): 46028 muestras\n",
            "Tama√±o del conjunto de prueba: 11508 muestras\n",
            "Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\n",
            "sentimiento\n",
            "negativo    17060\n",
            "positivo    15376\n",
            "neutral     13592\n",
            "Name: count, dtype: int64\n",
            "Distribuci√≥n de clases en el conjunto de prueba:\n",
            "sentimiento\n",
            "negativo    4266\n",
            "positivo    3844\n",
            "neutral     3398\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\n",
            "Forma de X_train_tfidf_unbalanced: (46028, 5000)\n",
            "Forma de X_test_tfidf: (11508, 5000)\n"
          ]
        }
      ],
      "source": [
        "# Dividir el dataset en conjuntos de entrenamiento y prueba ANTES de aplicar SMOTE\n",
        "X_train_unbalanced, X_test, y_train_unbalanced, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"\\nTama√±o del conjunto de entrenamiento (desbalanceado): {len(X_train_unbalanced)} muestras\")\n",
        "print(f\"Tama√±o del conjunto de prueba: {len(X_test)} muestras\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de entrenamiento (desbalanceado):\\n{y_train_unbalanced.value_counts()}\")\n",
        "print(f\"Distribuci√≥n de clases en el conjunto de prueba:\\n{y_test.value_counts()}\")\n",
        "\n",
        "# Inicializar TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(1,2)) # Limitando las caracter√≠sticas para eficiencia\n",
        "\n",
        "# Ajustar y transformar X_train_unbalanced, y transformar X_test\n",
        "X_train_tfidf_unbalanced = tfidf_vectorizer.fit_transform(X_train_unbalanced)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(\"\\nVectorizaci√≥n TF-IDF completada en la divisi√≥n desbalanceada.\")\n",
        "print(f\"Forma de X_train_tfidf_unbalanced: {X_train_tfidf_unbalanced.shape}\")\n",
        "print(f\"Forma de X_test_tfidf: {X_test_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpTP-d7RHYa"
      },
      "source": [
        "### <font size=12 color=lightgreen> Balanceo del Conjunto de Entrenamiento con SMOTE</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI_FmuXRPuLz"
      },
      "source": [
        "Ahora aplicaremos SMOTE solo al conjunto de entrenamiento vectorizado (`X_train_tfidf_unbalanced`) para balancear las clases, generando muestras sint√©ticas para las clases minoritarias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DHm0iiw1PuLz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SMOTE aplicado\n",
            "\n",
            "Distribuci√≥n despu√©s de SMOTE:\n",
            "sentimiento\n",
            "neutral     17060\n",
            "positivo    17060\n",
            "negativo    17060\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Nuevas dimensiones: (51180, 5000)\n"
          ]
        }
      ],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf_unbalanced, y_train_unbalanced)\n",
        "\n",
        "print(\"‚úÖ SMOTE aplicado\")\n",
        "print(f\"\\nDistribuci√≥n despu√©s de SMOTE:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(f\"\\nNuevas dimensiones: {X_train_tfidf.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5mkvXaQlFi"
      },
      "source": [
        "### <font size=12 color=lightgreen> Entrenamiento del Modelo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_cggSuxPuLz"
      },
      "source": [
        "\n",
        "# Entrenamiento de M√∫ltiples Modelos\n",
        "\n",
        "Entrenaremos 3 modelos y compararemos:\n",
        "1. **Logistic Regression** (baseline mejorado)\n",
        "2. **SVM** (Support Vector Machine)\n",
        "3. **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4cR6qbPuLz",
        "outputId": "03a3f76d-7c06-4d83-b8af-149723dc4ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/3] Entrenando Logistic Regression...\n",
            "‚úÖ Logistic Regression entrenado\n",
            "\n",
            "[2/3] Entrenando SVM...\n",
            "‚úÖ SVM entrenado\n",
            "\n",
            "[3/3] Entrenando Random Forest...\n",
            "‚úÖ Random Forest entrenado\n",
            "\n",
            "============================================================\n",
            "‚úÖ TODOS LOS MODELOS ENTRENADOS\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 1. Logistic Regression (mejorado)\n",
        "print(\"[1/3] Entrenando Logistic Regression...\")\n",
        "model_lr = LogisticRegression(\n",
        "    max_iter=2000,\n",
        "    random_state=42,\n",
        "    C=1.0,\n",
        "    solver='lbfgs',\n",
        "    multi_class='multinomial'\n",
        ")\n",
        "model_lr.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ Logistic Regression entrenado\")\n",
        "\n",
        "# 2. SVM\n",
        "print(\"\\n[2/3] Entrenando SVM...\")\n",
        "model_svm = SVC(\n",
        "    kernel='linear',\n",
        "    C=1.0,\n",
        "    probability=True,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "model_svm.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ SVM entrenado\")\n",
        "\n",
        "# 3. Random Forest\n",
        "print(\"\\n[3/3] Entrenando Random Forest...\")\n",
        "model_rf = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "model_rf.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ Random Forest entrenado\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ TODOS LOS MODELOS ENTRENADOS\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWq-wLkyQmaI"
      },
      "source": [
        "### <font size=12 color=lightgreen>Evaluaci√≥n de Modelos:</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNhozE5IPuLz"
      },
      "source": [
        "Evaluaremos el rendimiento del modelo en el conjunto de prueba utilizando m√©tricas clave como accuracy, precision, recall y F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "NYZ2qppwlC0z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUACI√ìN: Logistic Regression (Mejorado)\n",
            "============================================================\n",
            "\n",
            "üìä Accuracy: 0.7219 (72.19%)\n",
            "\n",
            "üìã Reporte de Clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo     0.7671    0.7604    0.7637      4266\n",
            "     neutral     0.6649    0.6854    0.6750      3398\n",
            "    positivo     0.7243    0.7115    0.7178      3844\n",
            "\n",
            "    accuracy                         0.7219     11508\n",
            "   macro avg     0.7188    0.7191    0.7189     11508\n",
            "weighted avg     0.7226    0.7219    0.7222     11508\n",
            "\n",
            "\n",
            "üî¢ Matriz de Confusi√≥n:\n",
            "[[3244  566  456]\n",
            " [ 484 2329  585]\n",
            " [ 501  608 2735]]\n",
            "\n",
            "üíØ Probabilidad promedio (correctas): 0.7285 (72.85%)\n",
            "\n",
            "============================================================\n",
            "EVALUACI√ìN: SVM\n",
            "============================================================\n",
            "\n",
            "üìä Accuracy: 0.7348 (73.48%)\n",
            "\n",
            "üìã Reporte de Clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo     0.7737    0.7724    0.7730      4266\n",
            "     neutral     0.6853    0.7010    0.6930      3398\n",
            "    positivo     0.7365    0.7229    0.7297      3844\n",
            "\n",
            "    accuracy                         0.7348     11508\n",
            "   macro avg     0.7318    0.7321    0.7319     11508\n",
            "weighted avg     0.7352    0.7348    0.7349     11508\n",
            "\n",
            "\n",
            "üî¢ Matriz de Confusi√≥n:\n",
            "[[3295  532  439]\n",
            " [ 461 2382  555]\n",
            " [ 503  562 2779]]\n",
            "\n",
            "üíØ Probabilidad promedio (correctas): 0.7784 (77.84%)\n",
            "\n",
            "============================================================\n",
            "EVALUACI√ìN: Random Forest\n",
            "============================================================\n",
            "\n",
            "üìä Accuracy: 0.7868 (78.68%)\n",
            "\n",
            "üìã Reporte de Clasificaci√≥n:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo     0.7985    0.8256    0.8118      4266\n",
            "     neutral     0.7974    0.7310    0.7628      3398\n",
            "    positivo     0.7657    0.7932    0.7792      3844\n",
            "\n",
            "    accuracy                         0.7868     11508\n",
            "   macro avg     0.7872    0.7833    0.7846     11508\n",
            "weighted avg     0.7872    0.7868    0.7864     11508\n",
            "\n",
            "\n",
            "üî¢ Matriz de Confusi√≥n:\n",
            "[[3522  291  453]\n",
            " [ 434 2484  480]\n",
            " [ 455  340 3049]]\n",
            "\n",
            "üíØ Probabilidad promedio (correctas): 0.6719 (67.19%)\n"
          ]
        }
      ],
      "source": [
        "def evaluar_modelo(model, X_test, y_test, nombre):\n",
        "    \"\"\"Evaluaci√≥n detallada de un modelo\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUACI√ìN: {nombre}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nüìä Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nüìã Reporte de Clasificaci√≥n:\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    print(f\"\\nüî¢ Matriz de Confusi√≥n:\")\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    # Probabilidad promedio\n",
        "    predicciones_correctas = y_pred == y_test\n",
        "    probabilidades_correctas = []\n",
        "\n",
        "    for i, correcto in enumerate(predicciones_correctas):\n",
        "        if correcto:\n",
        "            clase_predicha = y_pred[i]\n",
        "            clase_idx = list(model.classes_).index(clase_predicha)\n",
        "            probabilidades_correctas.append(y_pred_proba[i][clase_idx])\n",
        "\n",
        "    if probabilidades_correctas:\n",
        "        prob_promedio = np.mean(probabilidades_correctas)\n",
        "        print(f\"\\nüíØ Probabilidad promedio (correctas): {prob_promedio:.4f} ({prob_promedio*100:.2f}%)\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "acc_lr = evaluar_modelo(model_lr, X_test_tfidf, y_test, \"Logistic Regression (Mejorado)\")\n",
        "acc_svm = evaluar_modelo(model_svm, X_test_tfidf, y_test, \"SVM\")\n",
        "acc_rf = evaluar_modelo(model_rf, X_test_tfidf, y_test, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye01V19FQn7Z"
      },
      "source": [
        "### <font size=12 color=lightgreen> Serializaci√≥n del Modelo y Vectorizadors</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r68b_Sx6PuL0"
      },
      "source": [
        "\n",
        "\n",
        "Guardaremos el modelo entrenado y el objeto `TfidfVectorizer` utilizando `joblib` para poder reutilizarlos m√°s tarde en la API de predicci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "meOQ2yohPuL0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[56], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m mejor_modelo \u001b[38;5;241m=\u001b[39m model_svm\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Serializar el Modelo y el Vectorizador\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmejor_modelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/modelo_sentimientos.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(tfidf_vectorizer, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModelo y vectorizador guardados exitosamente en \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/modelo_sentimientos.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m y \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/vectorizador.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\marely\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\numpy_pickle.py:599\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol)\u001b[0m\n\u001b[0;32m    597\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 599\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    600\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/modelo_sentimientos.pkl'"
          ]
        }
      ],
      "source": [
        "# Based on evaluation, SVM was the best model, so we'll use it for serialization.\n",
        "mejor_modelo = model_svm\n",
        "\n",
        "# Serializar el Modelo y el Vectorizador\n",
        "joblib.dump(mejor_modelo, '/content/modelo_sentimientos.pkl')\n",
        "joblib.dump(tfidf_vectorizer, '/content/vectorizador.pkl')\n",
        "\n",
        "print(\"\\nModelo y vectorizador guardados exitosamente en '/content/modelo_sentimientos.pkl' y '/content/vectorizador.pkl'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx1ScQ4um7vg"
      },
      "outputs": [],
      "source": [
        "# Tabla comparativa\n",
        "comparacion = pd.DataFrame({\n",
        "    'Modelo': ['Logistic Regression', 'SVM', 'Random Forest'],\n",
        "    'Accuracy': [acc_lr, acc_svm, acc_rf]\n",
        "})\n",
        "\n",
        "comparacion['Accuracy %'] = comparacion['Accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "comparacion['Mejora vs. Original'] = comparacion['Accuracy'].apply(lambda x: f\"+{(x - 0.79)*100:.2f}%\")\n",
        "comparacion = comparacion.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üìä COMPARACI√ìN DE MODELOS\")\n",
        "print(\"=\"*70)\n",
        "print(comparacion.to_string(index=False))\n",
        "print(\"\\nüî∏ Modelo original (baseline): 79.00%\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "mejor_accuracy = comparacion['Accuracy'].max()\n",
        "if mejor_accuracy >= 0.83:\n",
        "    print(\"\\n‚úÖ META DE FASE 1 ALCANZADA (83-85%)\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è Casi alcanzado (falta {(0.83 - mejor_accuracy)*100:.2f}%)\")\n",
        "\n",
        "comparacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKTLn4ylPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Pruebas con Casos Espec√≠ficos</font>\n",
        "\n",
        "Validar que ahora clasifica correctamente los casos problem√°ticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q-eYggXPuL0"
      },
      "outputs": [],
      "source": [
        "# Seleccionar el mejor modelo\n",
        "modelos_dict = {\n",
        "    'Logistic Regression': model_lr,\n",
        "    'SVM': model_svm,\n",
        "    'Random Forest': model_rf\n",
        "}\n",
        "\n",
        "nombre_mejor = comparacion.iloc[0]['Modelo']\n",
        "mejor_modelo = modelos_dict[nombre_mejor]\n",
        "\n",
        "print(f\"üèÜ Mejor modelo: {nombre_mejor}\")\n",
        "print(f\"üìä Accuracy: {comparacion.iloc[0]['Accuracy %']}\")\n",
        "\n",
        "# Casos de prueba\n",
        "casos_prueba = [\n",
        "    (\"mala atenci√≥n\", \"negativo\"),\n",
        "    (\"mal comportamiento de los empleado\", \"negativo\"),\n",
        "    (\"la empresa esta perdida en lo que hace\", \"negativo\"),\n",
        "    (\"p√©simo servicio\", \"negativo\"),\n",
        "    (\"nunca vuelvo\", \"negativo\"),\n",
        "    (\"excelente servicio\", \"positivo\"),\n",
        "    (\"me encant√≥\", \"positivo\"),\n",
        "    (\"muy buena atenci√≥n\", \"positivo\"),\n",
        "    (\"es normal, nada especial\", \"neutral\"),\n",
        "    (\"est√° bien\", \"neutral\"),\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PRUEBAS CON CASOS ESPEC√çFICOS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "aciertos = 0\n",
        "\n",
        "for texto, esperado in casos_prueba:\n",
        "    # Preprocesar\n",
        "    texto_limpio = limpiar_texto_mejorado(texto)\n",
        "\n",
        "    # Vectorizar y predecir\n",
        "    texto_vectorizado = tfidf_vectorizer.transform([texto_limpio])\n",
        "    prediccion = mejor_modelo.predict(texto_vectorizado)[0]\n",
        "    probabilidades = mejor_modelo.predict_proba(texto_vectorizado)[0]\n",
        "\n",
        "    clase_idx = list(mejor_modelo.classes_).index(prediccion)\n",
        "    prob_prediccion = probabilidades[clase_idx]\n",
        "\n",
        "    es_correcto = prediccion == esperado\n",
        "    if es_correcto:\n",
        "        aciertos += 1\n",
        "        emoji = \"‚úÖ\"\n",
        "    else:\n",
        "        emoji = \"‚ùå\"\n",
        "\n",
        "    print(f\"\\n{emoji} '{texto}'\")\n",
        "    print(f\"   Esperado: {esperado} | Predicho: {prediccion} | Confianza: {prob_prediccion*100:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"RESULTADO: {aciertos}/{len(casos_prueba)} correctos ({aciertos/len(casos_prueba)*100:.1f}%\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYeFtgokPuL0"
      },
      "source": [
        "### <font size=12 color=lightgreen>Exportaci√≥n del modelo</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1xQz3UgPuL0"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Creamos un Pipeline manual uniendo las dos piezas\n",
        "pipeline_para_produccion = Pipeline([\n",
        "    ('vectorizer', tfidf_vectorizer), # Primero transforma el texto a n√∫meros\n",
        "    ('classifier', model)             # Luego predice con esos n√∫meros\n",
        "])\n",
        "\n",
        "# Probamos que funcione antes de exportar\n",
        "test_text = [\"Este es un ejemplo de prueba para ver si funciona el pipeline\"]\n",
        "prediccion = pipeline_para_produccion.predict(test_text)\n",
        "print(f\"Prueba del pipeline: {prediccion}\")\n",
        "\n",
        "# EXPORTAR EL ARCHIVO FINAL\n",
        "# Este es el archivo que debes subir a la carpeta de tu microservicio\n",
        "joblib.dump(pipeline_para_produccion, 'modelo_entrenado.joblib')\n",
        "\n",
        "print(\"‚úÖ Archivo 'modelo_entrenado.joblib' creado exitosamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEPArdRuz5sC"
      },
      "source": [
        "********************************************************************************************************************************************************************************************************************"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
