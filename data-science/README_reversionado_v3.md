# SentimentAPI ‚Äî Data Science  
**MVP Hackathon ONE | Equipo Data Science ‚Äî Procesamiento, Clasificaci√≥n y Modelo ML**  

> ‚úÖ README listo para **GitHub**. Guardalo como `README.md` para renderizado autom√°tico.

---

## üìå Notebooks
- `Procesamiento_y_Clasificacion_de_Datos_SentimentAPI.ipynb`
- `Modelo_SentimentAPI.ipynb`

---

## üë• Equipo y roles

| Rol | Integrante |
|---|---|
| L√≠der de Integraci√≥n (Java/DS) | Eduardo |
| Especialista NLP | Marely |
| Cient√≠fico/a de ML | Alex |
| Data QA & Documentation | Agustin |

---

## 1. Descripci√≥n general
**SentimentAPI** es un MVP que clasifica el **sentimiento** de textos de feedback (rese√±as, comentarios, encuestas o publicaciones) y devuelve una predicci√≥n consumible por aplicaciones (Back-end Java u otros clientes) en formato **JSON**, incluyendo una **probabilidad** asociada.

---

## 2. Objetivos del equipo de Data Science
- Preparar y documentar un dataset limpio y etiquetado (**positivo / neutral / negativo**) para entrenamiento supervisado.
- Implementar un pipeline reproducible de **procesamiento de texto** y **categorizaci√≥n**.
- Entrenar un modelo base de NLP + ML (**TF‚ÄëIDF + SVM calibrado**) y exportarlo como artefacto (**joblib**).
- Proveer evidencia de calidad (**QA**), resultados de pruebas y ejemplos reales para la demo.

---

## 3. Arquitectura y flujo (integraci√≥n con Back-end)
1. El Back-end (Java) env√≠a un JSON con el campo `text` al microservicio de sentimientos en Python (FastAPI).
2. El servicio aplica vectorizaci√≥n **TF‚ÄëIDF** y un modelo entrenado (**SVM calibrado**), retornando `prevision` y `probabilidad`.

### 3.1 Diagrama de arquitectura (en el repo)
Ubicaci√≥n sugerida:
- `docs/images/architecture_microservice.png`

Inserci√≥n en Markdown:
```md
![Microservicio de Sentimientos ‚Äî Flujo & Arquitectura](docs/images/architecture_microservice.png)
```

---

## 4. Dataset oficial (√∫nico en uso)
‚úÖ **Dataset en uso:** `dataset_listo_para_ML_esp.csv`  
**Columnas:** `texto`, `sentimiento` (clases: `positivo`, `neutral`, `negativo`)

**Resumen r√°pido:**
- **Registros:** **3453**
- **Valores nulos:** **0** en `texto` | **0** en `sentimiento`
- **Textos vac√≠os:** **0**
- **Duplicados por texto:** **0 (0.00%)**

**Distribuci√≥n de clases:**
| Clase | Cantidad | % |
|---|---:|---:|
| `positivo` | 1198 | 34.7% |
| `neutral` | 1142 | 33.1% |
| `negativo` | 1113 | 32.2% |

> Nota: las etiquetas vienen en **min√∫scula**. Si la API espera capitalizaci√≥n, aplicar `.title()` al construir el response.

---

## 5. Procesamiento y clasificaci√≥n de datos (ETL)
El notebook de procesamiento transforma fuentes crudas en el dataset final.

**Pipeline (alto nivel):**
- **Carga y selecci√≥n** de columnas relevantes.
- **Normalizaci√≥n/Limpieza** (URLs, menciones, emojis, s√≠mbolos, espacios m√∫ltiples, etc.).
- **Categorizaci√≥n** a 3 clases (`positivo / neutral / negativo`).
- **Exportaci√≥n** del dataset final.

### 5.1 Evidencia visual del proceso (capturas del equipo)
```md
![Del caos al modelo ‚Äî proceso](docs/images/process_overview_team.png)
![An√°lisis de limpieza ‚Äî eliminaciones](docs/images/cleaning_analysis_team.png)
![Distribuci√≥n de sentimientos ‚Äî dataset final](docs/images/sentiment_distribution_team.png)
```

---

## 6. QA y Testing (Calidad y Reproducibilidad)

### 6.1 Checks autom√°ticos sobre dataset oficial
| Chequeo | Resultado |
|---|---|
| Registros totales | **3453** |
| Nulos en `texto` | **0** |
| Vac√≠os en `texto` | **0** |
| Nulos en `sentimiento` | **0** |
| Duplicados por texto | **0 (0.00%)** |
| Espacios dobles (`\s{2,}`) | **0 (0.00%)** |
| Filas con may√∫sculas | **3115 (90.21%)** |
| Filas con caracteres no-ASCII | **992 (28.73%)** |
| Filas con URLs | **71 (2.06%)** |
| Filas con `#` o `@` | **404 (11.70%)** |

### 6.2 Longitud de textos (en palabras)
- min: **1**
- p25: **11**
- mediana: **17**
- media: **21.41**
- p75: **29**
- max: **585**

---

## 7. Decisiones de QA (para reproducibilidad)
- **Dataset √∫nico y trazable:** se define `dataset_listo_para_ML_esp.csv` como **√∫nica fuente oficial** para entrenamiento e inferencia.
- **Consistencia de etiquetas:** se valida que `sentimiento` ‚àà {positivo, neutral, negativo} (sin clases fuera de dominio).
- **Integridad:** se valida ausencia de nulos/vac√≠os en campos cr√≠ticos (`texto`, `sentimiento`).
- **Trazabilidad de cambios:** ante actualizaciones de dataset, se requiere re‚Äëentrenar el modelo y regenerar evidencias (m√©tricas + gr√°ficos).
- **Riesgos conocidos:** presencia de URLs/hashtags/menciones (dominio redes) y outliers de longitud; se documenta para futuras mejoras.

---

## 8. Testing ‚Äî Machine Learning (Modelo)
**Modelo productivo (seg√∫n notebook):**
- **Vectorizaci√≥n:** `TfidfVectorizer(max_features=5000, ngram_range=(1,3))`
- **Clasificador:** `LinearSVC(C=1.0)` + `CalibratedClassifierCV` (para obtener probabilidades)
- **Balanceo (experimento):** SMOTE aplicado al set de entrenamiento (comparado contra versi√≥n ‚ÄúVieja Confiable‚Äù sin balanceo)

**M√©tricas reportadas por el equipo (capturas de ejecuci√≥n):**
- **Accuracy final:** **82.8%**  
- Tabla por clase (promedio): precisi√≥n y F1 (ver imagen ‚ÄúDel caos al modelo‚Äù).

> Nota: si cambia el dataset o el pipeline, se debe re‚Äëejecutar el notebook y actualizar estas m√©tricas.

---

## 9. Ejemplos para demostraci√≥n (inferencia)
| Input (`text`) | Predicci√≥n | Probabilidad |
|---|---|---|
| "la euforia del lanzamiento exitoso de un producto" | positivo | 0.53 |
| "decepcion con el servicio en un restaurante local" | neutral | 0.71 |
| "amarga experiencia en el departamento de atencion..." | negativo | 0.39 |

---

## 10. Contrato de integraci√≥n (API)

### Request
```json
{ "text": "..." }
```

### Response OK
```json
{ "prevision": "Positivo", "probabilidad": 0.87 }
```

### Response Error
```json
{ "error": "El campo \"text\" es obligatorio..." }
```

---

## 11. Requisitos y ejecuci√≥n
- **Python 3.10+**
- **Librer√≠as principales:** `pandas`, `numpy`, `scikit-learn`, `joblib`, `fastapi`, `uvicorn`
- **Si se usa SMOTE:** `imbalanced-learn`

**Pasos recomendados**
1. Ejecutar `Procesamiento_y_Clasificacion_de_Datos_SentimentAPI.ipynb` para generar/validar el dataset.
2. Ejecutar `Modelo_SentimentAPI.ipynb` para entrenar y exportar el modelo (`modelo_entrenado.joblib`).
3. Levantar la API con FastAPI y consultar el modelo serializado.

---

## 12. Evidencia (gr√°ficos)
Estructura sugerida:
```text
docs/images/
  architecture_microservice.png
  process_overview_team.png
  cleaning_analysis_team.png
  sentiment_distribution_team.png
  class_distribution_v2.png
  duplicates_summary_v2.png
  text_length_words_hist_v2.png
  top_words_pos_v2.png
  top_words_neu_v2.png
  top_words_neg_v2.png
  confusion_matrix_v2.png
```

Inserci√≥n (ejemplo):
```md
![Distribuci√≥n de clases](docs/images/class_distribution_v2.png)
![Duplicados](docs/images/duplicates_summary_v2.png)
![Longitud de textos](docs/images/text_length_words_hist_v2.png)
![Top positivo](docs/images/top_words_pos_v2.png)
![Top neutral](docs/images/top_words_neu_v2.png)
![Top negativo](docs/images/top_words_neg_v2.png)
![Matriz de confusi√≥n](docs/images/confusion_matrix_v2.png)
```

---

## 13. Troubleshooting (errores t√≠picos)
| Problema | Causa com√∫n | Soluci√≥n r√°pida |
|---|---|---|
| `UnicodeDecodeError` / caracteres raros | Encoding inconsistente | Re‚Äëexportar a CSV y forzar UTF‚Äë8/Latin‚Äë1. |
| `FileNotFoundError` en notebooks | Rutas relativas fuera del root | Ejecutar desde el root del repo o usar carpeta `data/`. |
| Columnas no coinciden (`KeyError`) | Cambi√≥ el nombre de columnas | Verificar columnas del CSV y actualizar variables. |
| M√©tricas no coinciden | Modelo viejo con dataset nuevo | Re‚Äëentrenar y regenerar evidencia. |

---

### ‚úÖ Estado del MVP
- ETL documentado ‚úÖ  
- Dataset oficial integrado ‚úÖ  
- QA base documentado ‚úÖ  
- Contrato de API definido ‚úÖ  
- Evidencia visual y m√©tricas ‚úÖ  

_√öltima actualizaci√≥n: 2026-01-21_
